\documentclass[12pt,twoside]{article}
\usepackage{jmlda}
\newcommand{\hdir}{.}
\setcounter{page}{1853}

%\NOREVIEWERNOTES
\title
    %[Об эффективном распараллеливании алгоритмов для дискретных перечислительных задач] % Краткое название; не нужно, если полное название влезает в~колонтитул
    {Об эффективном распараллеливании алгоритмов для~дискретных перечислительных задач}
\author
    %[Дюкова~Е.\,В., Никифоров~А.\,Г.] % список авторов для колонтитула; не нужен, если основной список влезает в колонтитул
    {Е.\,В. Дюкова, А.\,Г. Никифоров} % основной список авторов, выводимый в оглавление
    [Е.\,В. Дюкова$^1$, А.\,Г. Никифоров$^2$] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\thanks
	{Работа частично поддержана грантами РФФИ \No\,13-01-00787-a и \No\,14-07-00819-a и грантом Президента РФ НШ-4908.2014.1.}
\email
	{edjukova@mail.ru, ankifor@gmail.com}
\organization
    {$^1$ВЦ РАН им. А.\,А.~Дородницына, Москва, Россия\par
$^2$МГУ им. М.\,В.~Ломоносова, Москва, Россия}
\abstract
    {
	Разработана новая статическая схема распараллеливания асимптотически оп\-ти\-мальных алгоритмов для задачи дуализации.
	Данная задача относится к числу труд\-но\-ре\-ша\-емых перечислительных задач.
	Предлагаемая схема основана на предварительной ста\-ти\-сти\-че\-ской обработке входных данных с целью установления вида распределения
слу\-чай\-ной
величины, определяющей объемы подзадач.
	Статья является развитием ранней работы авторов, в которой при получении указанных оценок использовалась менее эффективная методика, учитывающая только размер задачи.
	Выявлены условия, при которых обеспечиваются достаточно равномерная загрузка процессоров и ускорение, близкое к~максимальному.
	
	\bigskip
\noindent
	\textbf{Ключевые слова}:
	\emph {перечислительная задача; дуализация; неприводимое покрытие булевой матрицы; трансверсаль гиперграфа; асимптотически оптимальный алгоритм; параллельные вычисления; балансировка нагрузки; сильная масштабируемость}
	}
	
\titleEng
    {On efficient parallelizing of the algorithms for~discrete~enumeration~problems}
\authorEng
    {E.\,V. Djukova$^1$ and A.\,G. Nikiforov$^2$}
\organizationEng
     {$^1$Dorodnicyn Computing Centre of the~Russian Academy of~Sciences,
Moscow, Russia\par
$^2$M.\,V.~Lomonosov Moscow State University, Moscow, Russia}
\abstractEng
    {		
	\noindent	
	\textbf{Background}:
		Approach to construction of efficient parallel algorithms for discrete enumeration problems is introduced in the previous works of the authors.
		This approach is based on statistical estimations for computational tasks size.
		The approach is demonstrated on dualization, which is an intractable problem and consists in enumeration of irreducible coverings of a given boolean matrix.
		The main disadvantage of formerly suggested parallel schemes for asympotically optimal dualization algorithms is time-costly tasks size estimation method which considers only the problem size.
		
	\noindent
	\textbf{Methods}:
		A new parallel scheme has been developed
for asymptotically optimal dualization algorithms, reducing time costs on statistical data collection.
		Statistical data are obtained via processing of a given matrix submatrices.
		
	\noindent
	\textbf{Results}:
		Task distribution is performed according to schedule calculated
in advance.
		For this purpose, a distribution of random variable, used for tasks size estimation, is fitted and the processor load level is optimized.
		A parallel scheme is applied to an asymptotically optimal algorithm RUNC-M.
		
	\noindent
	\textbf{Concluding Remarks}:
		A new parallel scheme works not worse than the formerly suggested ones, demonstrates an almost maximal speedup and makes it possible to dualize matrices of big size.
		However, this scheme is efficient only if the number of processors is significantly smaller than the number of matrix columns.	
	
    \noindent
    \textbf{Keywords}:
	\emph{enumeration; dualization; irreducible covering of a boolean matrix; hypergraph transversal; asymptotically optimal algorithm; parallel computations; load balancing; strong scaling}
	}
	
	
\begin{document}
\maketitle
\renewcommand{\baselinestretch}{1.10}
%\linenumbers
%===========================================
\section{Введение}
Одной из фундаментальных задач дискретной математики является дуализация.
Ниже приведена ее матричная формулировка.

Дана булева матрица $L$ размера $m{\times}n$.
Набор $H$, состоящий из различных столбцов матрицы $L$, называется неприводимым покрытием, если он удовлетворяет двум условиям:
(1) в подматрице $L^H$ матрицы $L$, образованной столбцами набора $H$, не содержится строки вида $(0,0,\dots,0)$;
(2) подматрица $L^H$ содержит каждую из строк вида $(1,0,0,\dots,0)$, $(0,1,0,\dots,0)$, \dots, $(0,0,0,\dots,1)$.
Если набор столбцов $H$ удовлетворяет условию (1), то он называется покрытием.
Если набор столбцов $H$ удовлетворяет условию (2), то он называется совместимым.
Требуется построить множество $P(L)$ всех неприводимых покрытий матрицы $L$.

Дуализация имеет и другие эквивалентные формулировки.
Приведем основные из них.
\begin{enumerate}
\item
	Дана конъюнктивная нормальная форма, реализующая монотонную булеву функцию~$F$.
	Требуется построить сокращенную дизъюнктивную нормальную форму функции~$F$.
\item
	Дан гиперграф $G$.
	Требуется перечислить все минимальные трансверсали гиперграфа~$G$
	(двойственной задачей является задача перечисления всех минимальных вершинных покрытий гиперграфа $G$).
\end{enumerate}

Дуализация возникает во многих областях дискретной математики (комбинаторике, теории гиперграфов, целочисленном программировании), в теории игр, в теории баз данных, в теории машинного обучения и~т.\,д.

Асимптотические оценки типичных значений числа решений дуализации \cite{Djukova1977} показывают, что, как правило, это число растет экспоненциально с ростом размера входных данных.
Поэтому дуализация относится к числу труднорешаемых перечислительных задач.
Существует несколько подходов к оценке эффективности алгоритмов для перечислительных задач \cite{Djukova1977, Papadimitriou1988, Khachiyan1996}.

Говорят, что алгоритм работает с (квази)полиномиальной задержкой, если на
каждом шаге строится ровно одно решение и сложность шага ограничивается (квази)полиномом от размера входных данных (для дуализации в матричной формулировке~--- это размер матрицы $L$).
Алгоритмы дуализации с (квази)полиномиальной задержкой удалось построить только для некоторых частных случаев (например, когда в каждой строке исходной матрицы не более двух единиц \cite{Khachiyan1996}).
Таким образом, статус дуализации в плане полиномиальной разрешимости неизвестен.

В \cite{Djukova1977, Djukova1982} предложен подход к построению асимптотически оптимальных алгоритмов дуализации.
В дальнейшем этот подход получил развитие в \cite{DjukovaZhu1997, DjukovaZhu2000, Djukova2004, DjukovaInyakin2008}.
На каждом шаге асимптотически оптимального алгоритма строится набор столбцов матрицы, удовлетворяющий условию совместимости (2).
В отличие от алгоритма дуализации с  полиномиальной задержкой асимптотически оптимальный алгоритм может делать полиномиальные <<лишние>> шаги, причем доля таких шагов стремится к нулю для почти всех матриц $L$ размера $m{\times}n$ при $m, n \to \infty$.
На <<лишнем>> шаге либо строится  набор столбцов матрицы, не являющийся покрытием, либо строится  набор столбцов, найденный ранее.
Проверка на повторяемость построенного набора столбцов осуществляется за полиномиальное время от размеров матрицы.

Асимптотически оптимальные алгоритмы являются лидерами по скорости счета среди других известных алгоритмов дуализации.
В \cite{MurakamiUno2014, DjukovaProk2014} показано, что наиболее быстро среди асимптотически оптимальных алгоритмов работают алгоритмы  RUNC"~M и PUNC \cite{DjukovaProk2014}, не делающие <<повторных>> шагов.

В силу того что число решений дуализации, как правило, растет экспоненциально
с~рос\-том размеров входных данных, актуальным является использование параллельных вычислений.
Существуют простые и очевидные схемы распараллеливания асимптотически оптимальных алгоритмов дуализации, основным недостатком которых является неравномерная загрузка процессоров, что приводит и к недостаточному ускорению времени работы параллельного алгоритма по сравнению с его последовательной версией.
Схема распараллеливания определяется способом выбора вычислительных подзадач и способом распределения этих подзадач между процессорами.

Следует отметить, что за рубежом при создании параллельных алгоритмов дуализации первостепенное внимание уделяется теоретическим оценкам их сложности в зависимости от числа используемых процессоров \cite{Khachiyan2005, Khachiyan2007},
причем, как правило, строятся алгоритмы, ориентированные на частные случаи, например, когда число единиц в каждой строке исходной матрицы ограничено некоторой небольшой константой.

В \cite{Nikiforov2014} предложен подход к построению эффективных в практическом плане параллельных асимптотически оптимальных алгоритмов дуализации.
Опишем разработанную в \cite{Nikiforov2014} В"~схему распараллеливания.

Пусть $H$~--- неприводимое покрытие матрицы $L$, состоящее из столбцов с номерами $j_1,\dots, j_r$, где $j_1<\dots<j_r$.
Тогда $H$ назовем $j_1$"~неприводимым покрытием.
Подзадача с номером $j,\,j\in\{1,\dots,n\},$ состоит в построении множества $P_j(L)$ всех $j$"~неприводимых покрытий матрицы $L$.
Объемы подзадач определяются величинами $\nu_j(L)=|P_j(L)| \big/ |P(L)|,\,j\in\{1,\dots,n\}$.

В"~схема имеет статический характер: распределение подзадач происходит по заранее составленному <<расписанию>>.
Статистическая обработка экспериментов показывает, что случайная величина,
использующаяся для оценки  $\nu_j(L), j\in \{1,\dots,n\}$, подчиняется
бе\-та"~би\-но\-ми\-аль\-но\-му закону, параметры которого вычисляются при помощи метода максимального правдоподобия по выборке из случайных матриц размера $m{\times}n$.
Для составления <<расписания>> решается задача оптимизации уровня загрузки процессоров.

В"~схема демонстрирует, как правило, достаточно равномерную загрузку
процессоров и~высокое ускорение времени работы при увеличении числа процессоров.
Однако вычисление оценок для  $\nu_j(L)$ в этой схеме требует многократного решения задачи дуализации для случайных матриц,  имеющих одинаковый размер с матрицей $L$, и эти оценки недостаточно точны.

Основным результатом данной работы является разработка S"~схемы распараллеливания асимптотически оптимальных алгоритмов дуализации.
Эта схема отличается от В"~схемы методом получения оценок для $\nu_j(L),\,j\in\{1,\dots, n\}$, который является менее трудоемким и учитывает не только размеры матрицы.
Метод основан на обработке случайных подматриц данной матрицы, подматрицы имеют размер $r{\times}n$, где $r$ является параметром и не превосходит $m$.
Выявлено, что при параметре $r$, равном $m/2$, полученные оценки являются достаточно точными с точки зрения критерия Хи-квадрат.
Работа S"~схемы продемонстрирована на примере алгоритма RUNC"~M \cite{DjukovaProk2014}, который является модификацией асимптотически оптимального алгоритма ОПТ \cite{DjukovaInyakin2008}.

При тестировании S"~схемы исследуется ее сильная масштабируемость (зависимость основ\-ных показателей работы параллельного алгоритма от числа процессоров при фиксированном размере задачи).
Показано, что S"~схема демонстрирует такие же показатели сильной масштабируемости, как B"~схема, и в то же время позволяет обрабатывать матрицы еще б\'{о}льших размеров за счет более быстрого вычисления оценок для объемов подзадач.

\section{Описание асимптотически оптимального алгоритма дуализации RUNC"~M}

В данном разделе приводится описание асимптотически оптимального алгоритма дуализации RUNC"~M \cite{DjukovaProk2014}.
Подробно описана структура дерева решений, которое строит данный алгоритм.

Обозначим через $M_{mn}$ множество булевых матриц размера $m{\times}n$, а через $J_u$ множество $\{1,2,\dots,u\}$.
Пусть $L=(a_{ij})\in M_{mn}$.
В данном разделе будем отождествлять набор столбцов (строк) матрицы $L$ с набором их номеров.

Будем говорить, что столбец $j$ (столбец с~номером $j$) покрывает строку~$i$
(строку с~номером $i$) матрицы $L$, если $a_{ij}=1$.

Строка $i$ матрицы $L$ является опорной для пары $(H, j),\,j\in H$, если $a_{ij}=1$ и $a_{ij}=0\; \forall u\in H \setminus \{j\}$.
Множество всех опорных строк для $(H, j)$ обозначим через $S(H,j)$.
Очевидно, набор~$H$ является совместимым тогда и только тогда, когда $S(H,j)\neq \emptyset\  \forall j \in H$.

Говорят, что столбец $j$ матрицы $L$ совместим с совместимым набором $H$, если набор $H\cup\{j\}$ совместимый.
Очевидно, столбец $j$ не совместим с совместимым набором $H$ тогда и только тогда, когда $\exists u \in H$ такой, что столбец $j$ покрывает все строки из $S(H,u)$.

Асимптотически оптимальный алгоритм дуализации RUNC"~M перечисляет с полиномиальной
задержкой $O(qmn), q=\min\{m,n\}$, некоторое подмножество совместимых наборов столбцов матрицы $L$, содержащее множество $P(L)$.
Алгоритм строит дерево решений, совершая его обход в глубину.
Построение одной висячей вершины~--- это шаг алгоритма.

Вершина $(H,R,C)$ дерева решений описывается совместимым набором столбцов $H$, набором строк $R$ и набором столбцов $C$.
В висячей вершине имеет место один из двух случаев:
(1) $R=\emptyset$;
(2) $R\neq \emptyset, C=\emptyset$.
В~первом случае $H$~--- неприводимое покрытие.
Во втором случае висячая вершина соответствует <<лишнему>> шагу.
Корню дерева соответствует $(H=\emptyset, R=J_m, C=J_n)$.
Пусть построена внутренняя (не висячая) вершина $(H,R,C)$, тогда переход к следующей построенной вершине будет осуществляться путем добавления к $H$ столбца из $C$ и удаления некоторых строк и столбцов из $R$ и $C$ соответственно.

Пусть построена внутренняя вершина $(H_0,R_0,C_0 )$.
Тогда при построении следующей вершины к $H_0$ добавляется первый
по порядку столбец из $C_0^{\min}=\{j\in C_0 | a_{ij}=1\}$, где $i\in R_0$~--- номер строки с наименьшей суммой $\sum_{j\in C_0} a_{ij}$ (если таких строк несколько, то выбирается строка с наименьшим номером среди них).

%link
Для того чтобы схемы распараллеливания, описанные далее, были применимы к алгоритму RUNC"~M, требуется его немного модифицировать: на первом ярусе дерева решений, или когда глубина рекурсии равна нулю, вместо множества $C_0^{\min}$ берется множество $C_0=J_n$.

\begin{algorithm}[h]
	\caption{BuildSubtreeRUNCM}
	\label{alg:RUNCM}
	\begin{algorithmic}[1]
		\REQUIRE $L,H_0,R_0,C_0$;
		\ENSURE $\emptyset$;
		\STATE $C_0^{\min}=\{j\in C_0 | a_{ij}=1\}$, где $i\in R_0$~--- номер строки с наименьшей суммой $\sum_{j\in C_0} a_{ij}$
		\FORALL{$j \in C_0^{\min}$}
			\STATE $R   \leftarrow R_0$
			\STATE $C_0 \leftarrow C_0 \setminus \{j\}$
			\STATE $C   \leftarrow C_0$
			\STATE $H   \leftarrow H_0 \cup \{j\}$
			\STATE Удалить из $R$ строки, покрытые столбцом $j$
			\IF{$R = \emptyset$}
				\STATE Сохранить набор $H$, который является неприводимым покрытием
			\ELSE
				\STATE Удалить из $C$ не совместимые с набором $H$ столбцы
				\STATE BuildSubtreeRUNCM$(L,H,R,C)$
			\ENDIF
		\ENDFOR	
	\end{algorithmic}
\end{algorithm}

Опишем рекурсивную процедуру BuildSubtreeRUNCM$(L,H,R,C)$ (cм. Алгоритм \ref{alg:RUNCM}) построения поддерева решений.
Для запуска алгоритма эту функцию следует вызывать с~параметрами $H=\emptyset, R=J_m, C=J_n$.
Отметим, что все аргументы процедуры передаются по значению или копируются.

Настоящая реализация алгоритма RUNC"~M написана на языке \verb!C++! с интенсивным использованием побитовых операций.
Кроме того, для некоторых частей алгоритма используется динамический выбор функций для минимизации числа операций (например, этот прием используется при удалении несовместимых строк).

%===========================================
\section{Оценки для объемов подзадач, используемые в S"~схеме}

В данном разделе описаны способы оценки объемов подзадач или величин $\nu_j(L)=|P_j(L)| \big/ |P(L)|,\,j\in J_n$, используемые соответственно в В"~схеме \cite{Nikiforov2014} и S"~схеме.

В В"~схеме на пространстве равновероятных элементарных событий
$\Omega=\{(L,H) \cond L\hm\in M_{mn},H\in P(L)\}$ вводится случайная величина $\eta(L,H)$, равная $j$, если $H\in P_j(L), j\in J_n$.
При помощи критерия Хи"~квадрат проверяется гипотеза о виде распределения~$H_0:
f(j) =\psi_{\alpha\beta}(j)$, где $f(j)$~--- вероятность события
$\eta(L,H)=j$, а $\psi_{\alpha\beta}(j)$~--- функция вероятности
бе\-та"~би\-но\-ми\-аль\-но\-го распределения с параметрами $\alpha$ и~$\beta$,
которые оцениваются при помощи метода максимального правдоподобия.
В"~схема использует величины $\psi_{\alpha\beta}(j)$ в качестве приближенного значения искомой величины $\nu_j(L), j\in J_n$.
Эта схема обладает двумя основ\-ны\-ми недостатками: оценка для $\nu_j(L)$ одна и та же для всех матриц данного размера, и для ее вычисления требуется многократно решить задачу дуализации для случайных матриц из $M_{mn}$.

Теперь опишем S"~схему.

Пусть $L\in M_{mn}$ и $r\leq m$.
Через $W_m^r$ обозначим множество всех подмножеств мощ\-ности $r$ множества $J_m$.
Пусть $w\in W_m^r$, тогда через $L^w$ обозначим подматрицу матрицы $L$, составленную из строк матрицы $L$ с номерами из $w$.

Пусть $\Omega_r = \{ (L^w,H) \cond w\in W_m^r, H\in P(L)\}$~--- пространство равновероятных элементарных событий.
На указанном пространстве определим случайную величину $\eta_r(L^w,H)$, которая равна $j, j\in J_n,$ если $H\in P_j(L)$.
Через $f_r(j)$ обозначим вероятность события $\eta_r(L^w,H)=j$.

Предлагается использовать величину  $f_r(j)$ в качестве приближенного значения искомой величины $\nu_j(L), j\in J_n$.
Встает вопрос, при каких $r$ указанные оценки являются достаточно точными.
С одной стороны, число $r$ должно быть как можно меньшим, чтобы время получения оценок было относительно невелико.
С другой стороны, оценки должны быть достоверными.

\begin{table}\small
    \caption{Значения пар $(Z_r(\vec{x}), \gamma_r^*(\vec{x}))$ для критерия Хи"~квадрат}
    \label{tab:z_r}
    \centering\medskip
    \begin{tabular}{|c|l|l|l|l|}
		\headline
		$r \setminus m{\times}n$
		& \multicolumn{1}{c|}{$30{\times}120$}
		& \multicolumn{1}{c|}{$40{\times}120$}
		& \multicolumn{1}{c|}{$50{\times}100$}
		& \multicolumn{1}{c|}{$70{\times}70$} \\
		\headline
		$10$ & $(159, <10^{-4})$ & $(167, <10^{-4})$ & $(235, <10^{-4})$ & $(382, <10^{-4})$ \\
		$13$ & $(99, <10^{-4}) $ & $(132, <10^{-4})$ & $(157, <10^{-4})$ & $(234, <10^{-4})$ \\
		$15$ & $(77, 0{,}0134)$ & $(112, <10^{-4})$ & $(117, <10^{-4})$ & $(187, <10^{-4})$ \\
		$18$ & $(74, 0{,}028) $ & $(90, 0{,}0002)$ & $(96, <10^{-4}) $ & $(147, <10^{-4})$ \\
		$20$ & $(60, 0{,}0815)$ & $(63, 0{,}0546)$ & $(89, <10^{-4}) $ & $(131, <10^{-4})$ \\
		$25$ & $(54, 0{,}315) $ & $(60, 0{,}0876)$ & $(50, 0{,}1382)$ & $(85, <10^{-4}) $ \\
		$30$ & \multicolumn{1}{c|}{---} & \multicolumn{1}{c|}{---} & \multicolumn{1}{c|}{---} & $(68, 0{,}0001)$ \\
		$35$ & \multicolumn{1}{c|}{---} &\multicolumn{1}{c|}{---} & \multicolumn{1}{c|}{---} & $(54, 0{,}0478)$ \\
		\hline
    \end{tabular}
\end{table}

Пусть $\vec{x}=(x_1,…,x_N)$~--- выборка из распределения $f_r(j)$.
Для проверки статистической гипотезы $H_0: f_r(j)=\nu_j (L)$ о виде распределения случайной величины $\eta_r(L^w,H)$ предлагается использовать критерий Хи"~квадрат со статистикой
\[
Z_r(\vec{x})= N \sum\limits_{j=1}^{n}{\frac{\left( f^*(j)-\nu_j(L)\right)^2}{\nu_j(L)}},
\]
где $f^*(j)$~--- доля элементов выборки $\vec{x}=(x_1,…,x_N)$, равных $j$.

Достигнутым уровнем значимости критерия Хи"~квадрат называется величина
$\gamma_r^*(\vec{x})=1-\chi_{n-1}^2 (Z_r(\vec{x}))$, где $\chi_{n-1}^2$~--- функция распределения Хи-квадрат с $(n-1)$ степенями
свободы.
Близость значения $\gamma_r^*(\vec{x})$ к $0$ говорит о том, что гипотезу $H_0$ вероятнее всего следует отклонить.



Для получения выборки $\vec{x}=(x_1,\dots,x_N)$ из распределения $f_r(j)$ построим $t$ случайных подматриц $L^w$ матрицы $L$ размера $r{\times}n$.
Выберем $N$ пар $(L^w,H),H\in P(L^w)$, и из значений случайной величины $\eta_r(L^w,H)$ сформируем выборку.


Проведем эксперимент.
Для каждой из конфигураций $30{\times}150$, $40{\times}120$, $50{\times}100$
и~$70{\times}70$ выберем по $20$ случайных матриц.
Для каждой матрицы сформируем выборку $\vec{x}=(x_1,…,x_N)$ из распределения $f_r(j)$, где $N=1000$.
В табл. \ref{tab:z_r} приведены медианные значений статистики $Z_r(\vec{x})$ и достигаемых уровней значимости $\gamma_r^*(\vec{x})$.
На рис. \ref{fig:nu_j} приведены графики величин $\nu_j(L)$ и $f_r^*(j)$.
\begin{figure}[h]
\begin{center}
	\subfloat{\includegraphics[width=0.5\textwidth, trim = 0 0 100 0]{\hdir/nu_j_plot}}
\end{center}
	\caption{Графики $\nu_j(L)$ и $f_r^*(r)$ как величин, зависящих от $j$, при $m=30$, $n=120$ и~$r=15$}
	\label{fig:nu_j}
\end{figure}

Согласно табл. \ref{tab:z_r} минимальное значение $r$, при котором достигнутый
уровень зна\-чи\-мости $\gamma_r^*(\vec{x})$ не является пренебрежимо малым, равняется $m / 2$. На примере конфигурации $30{\times}150$ можно заметить, что при $r=15$ имеет место  <<фазовый переход>>: при пересечении этой точки функция $Z_r(\vec{x})$ начинает стабилизироваться.
Это говорит о том, что дальнейшее увеличение $r$ не принесет существенного выигрыша в приближении $\nu_j(L)$.
%===========================================
\section{Распределение вычислительных заданий между процессорами}

Пусть $L\in M_{mn}$ и пусть дано $p\leq n$ процессоров.
Пусть $j$-я подзадача обработывается процессором с номером $N_j$.
Вектор $\vec{N^p}=(N_1,\dots,N_n)$ назовем расписанием.
Уровнем загрузки $k$"~го процессора назовем величину
\[
	\sigma_k(\vec{N^p}) = \sum\limits_{j\in J_n: N_j=k}{\nu_j(L)}.
\]
Для эффективного распределения вычислительных заданий между процессорами, требуется решить задачу минимизации уровня загрузки процессоров
\begin{equation}\label{eq:sigmamin}
	\sigma(\vec{N^p}) = \max_{k \in J_p} {\sigma_k(\vec{N^p})} \to \min_{\vec{N^p}}.
\end{equation}


%link
Ниже приведено описание процедуры \ref{alg:distribute}, которая ищет
приближенное решение задачи~\ref{eq:sigmamin} при помощи жадного алгоритма.
На вход этой процедуры подается число процессоров $p$, число столбцов $n$ матрицы $L$ и вектор $\vec{\widetilde{\nu}} = (\widetilde{\nu}_1, \dots, \widetilde{\nu}_n)$, состоящий из оценок для величин~$\nu_j(L)$.
Способы получения оценок $\widetilde{\nu}_j$ описаны ранее в этой работе.

\begin{algorithm}[h]
	\caption{DistributeTasks}
	\label{alg:distribute}
	\begin{algorithmic}[1]
		\REQUIRE $p, n, \vec{\widetilde{\nu}}$;
		\ENSURE $\vec{N^p}$;
		\FORALL{$k \in \{1,\dots, p\}$}
			\STATE $\sigma_k \leftarrow 0$
		\ENDFOR
		\FOR{$j \in \{1,\dots, n\}$}
			\STATE $k_0 \leftarrow \argmin_{k\in J_p}{\sigma_k}$
			\STATE $N_j \leftarrow k_0$
			\STATE $\sigma_k \leftarrow \sigma_k + \widetilde{\nu}_j$
		\ENDFOR
	\end{algorithmic}
\end{algorithm}


%===========================================
\section{Тестирование S"~схемы распараллеливания}

В данном разделе даны описания среды тестирования и~исследуемых показателей
работы параллельных алгоритмов, приведены результаты сравнения S"~схе\-мы
и~В"~схе\-мы и~результаты дополнительного тестирования S"~схемы на больших матрицах.

Тестирование проводилось на суперкомпьютере IBM Blue Gene/P, располагающегося
в~МГУ им. М.\,В.~Ломоносова в здании факультета Вычислительной математики
и~кибернетики и являющегося массивно"~парал\-лельной вычислительной системой.
Каждый вычислительный узел включает в себя четырехъядерный процессор PowerPC
450 (850~МГц), 2~ГБ общей памяти и сетевые интерфейсы.
При запуске вычислительных заданий использовался режим виртуальных
вычислительных узлов (VN (virtual network) режим).
В~этом режиме на каждом вычислительном узле запущено четыре MPI
(message passing interface) процесса, которые делят между собой доступные ресурсы.


\begin{table}[t]\small
    \caption{Сравнение схем распараллеливания при $m=65$ и $n=80$}
    \label{tab:comparison6580}
    \centering\medskip
    \tabcolsep=12pt
    \begin{tabular}{|c|c|c|c|c|c|c|}
\hline
 & \multicolumn{3}{c|}{B"~схема} & \multicolumn{3}{c|}{S"~схема} \\
		\cline{2-7}
\multicolumn{1}{|c|}{\raisebox{6pt}[0pt][0pt]{$p$}} & $T(p) $ & $\sigma(p)$ & $s(p) $ & $T(p) $ & $\sigma(p)$ & $s(p) $ \\
		\hline
		$\hphantom{9}1 $ & $17{,}40\hphantom{9}$ & $1{,}000    $ & $1{,}000$ & $18{,}35\hphantom{9}$ & $1{,}000    $ & $1{,}000$ \\
		$\hphantom{9}2 $ & $9{,}01$& $0{,}500$ & $0{,}514$ & $9{,}40 $ & $0{,}500    $ & $0{,}502$ \\
		$\hphantom{9}4 $ & $5{,}30$ & $0{,}250    $ & $0{,}291$ & $4{,}92 $ & $0{,}250    $ & $0{,}261$ \\
		$\hphantom{9}8 $ & $2{,}71$ & $0{,}125    $ & $0{,}147$ & $2{,}52 $ & $0{,}125    $ & $0{,}135$ \\
		$16$ & $1{,}55$ & $0{,}079    $ & $0{,}090$ & $1{,}62 $ & $0{,}084    $ & $0{,}087$ \\
		$32$ & $1{,}55$ & $0{,}079    $ & $0{,}090$ & $1{,}61 $ & $0{,}089    $ & $0{,}087$ \\
		$64$ & $1{,}55$ & $0{,}079    $ & $0{,}090$ & $1{,}61 $ & $0{,}089    $ & $0{,}087$ \\
		\hline
    \end{tabular}
\end{table}

\begin{table}[t]\small %[t]
    \caption{Сравнение схем распараллеливания при $m=80$ и $n=65$}
    \label{tab:comparison8065}
    \centering\medskip
    \tabcolsep=12pt
    \begin{tabular}{|c|c|c|c|c|c|c|}
\hline
		\, & \multicolumn{3}{c|}{B"~схема} & \multicolumn{3}{c|}{S"~схема} \\
		\cline{2-7}
\multicolumn{1}{|c|}{\raisebox{6pt}[0pt][0pt]{$p$}} & $T(p) $ & $\sigma(p)$ & $s(p) $ & $T(p) $ & $\sigma(p)$ & $s(p) $ \\
\hline
		$1 $ & $26{,}1$ & $1{,}000$ & $1{,}000$ & $26{,}2$\hphantom{99} & $1{,}000$ & $1{,}000$ \\
		$2 $ & $13{,}7$ & $0{,}500$ & $0{,}514$ & $13{,}8$\hphantom{99} & $0{,}500$ & $0{,}507$ \\
		$4 $ & \hphantom{99}$7{,}17$ & $0{,}250$ & $0{,}271$ & $7{,}01$ & $0{,}250$ & $0{,}255$ \\
		$8 $ & \hphantom{99}$3{,}87$ & $0{,}125$ & $0{,}140$& $3{,}79$ & $0{,}126$& $0{,}137$ \\
		$16\hphantom{9}$ & \hphantom{99}$2{,}83$& $0{,}102$ & $0{,}114$& $3{,}13$ & $0{,}086$ & $0{,}123$ \\
		$32\hphantom{9}$ &\hphantom{99}$2{,}83$ & $0{,}102$ & $0{,}114$ & $3{,}13$ & $0{,}092$ & $0{,}123$\\
		$64\hphantom{9}$ & \hphantom{99}$2{,}83$& $0{,}102$ & $0{,}114$& $3{,}13$ & $0{,}092$ & $0{,}123$ \\
		\hline
    \end{tabular}
\end{table}



Через $p$ обозначим число процессоров, через $T_k(p)$~--– время
(в секундах) работы $k$"~го процессора параллельного
алгоритма при использовании $p$ процессоров.
Пусть $T(p)=\max_k T_k(p)$ и $T_\Sigma(p)=\sum_k T_k(p)$.
Достигнутым уровнем загрузки $k$"~го процессора назовем величину
$s_k(p)=T_k(p) \big/ T_\Sigma(p)$.
Исследуются три показателя:
\begin{enumerate}[(1)]
\item
	ускорение алгоритма $S(p)=T(1)/T(p)$ ;
\item
	равномерность загрузки процессоров $E(p)=S(p)/p$;
\item
	достигнутый уровень загрузки $s(p)=\max_k s_k(p)$.
\end{enumerate}


Ускорение, соответствующее линейной функции $S(p)=p$ при $p\geq 1$, является практически максимальным.
Близость функции $E(p)$ к единице свидетельствует о равномерной загрузке процессоров.
Показатель $s(p)$ является аналогом показателя уровня загрузки процессоров $\sigma(\vec{N^p})$, определенного ранее в этой работе.

Поскольку используемые в В"~схеме оценки для $\nu_j(L)$ одинаковы для всех матриц данного размера, далее эти оценки считаются известными во время работы параллельного алгоритма.
В S"~схеме, напротив, оценки для объемов подзадач подсчитываются во время работы параллельного алгоритма.

Сравнение В"~схемы и S"~схемы проводится на матрицах размера $65{\times}80$, $80{\times}65$ и $80{\times}80$.
Матрицы б\'{о}льших конфигураций при сравнении не рассматриваются ввиду трудоемкости получения оценок для В"~схемы.
Результаты представлены в табл. \ref{tab:comparison6580}--\ref{tab:comparison8080}.
На рис. \ref{fig:scheme_comparison} представлены графики функций $S(p)$ и $E(p)$ при $m=n=80$.

Из указанных таблиц и графиков следует, что обе схемы демонстрируют практически одинаковое ускорение $S(p)$ и равномерность загрузки $E(p)$.
При этом достигнутый уровень загрузки $s(p)$ у S"~схемы наиболее низкий
и~$s(p)\approx \sigma(p)$, что свидетельствует о~качественной балансировке нагрузки.

\begin{table}[t]\small
    \caption{Сравнение схем распараллеливания при $m=80$ и~$n=80$}
    \label{tab:comparison8080}
    \centering\medskip
    \tabcolsep=12pt
    \begin{tabular}{|c|c|c|c|c|c|c|}
\hline
		\, & \multicolumn{3}{c|}{B"~схема} & \multicolumn{3}{c|}{S"~схема} \\
		\cline{2-7}
\multicolumn{1}{|c|}{\raisebox{6pt}[0pt][0pt]{$p$}}& $T(p) $ & $\sigma(p)$ & $s(p) $ & $T(p) $ & $\sigma(p)$ & $s(p) $ \\
		\hline
		$1 $ & $34{,}4$\hphantom{99} & $1{,}000$ & $1{,}000$ & $36{,}5$\hphantom{99} & $1{,}000$ & $1{,}000$\\
		$2 $ & $17{,}3$\hphantom{99} & $0{,}500$ & $0{,}502$ & $18{,}8$\hphantom{99} & $0{,}500$ & $0{,}508$\\
		$4 $ & $10{,}1$\hphantom{99} & $0{,}250$ & $0{,}286$ & $9{,}94$ & $0{,}250$ & $0{,}257$ \\
		$8 $ & $5{,}10$ & $0{,}125$ & $0{,}147$ & $5{,}35$ & $0{,}125$ & $0{,}137$ \\
		$16\hphantom{9}$ & $3{,}03$ & $0{,}078$ & $0{,}091$& $3{,}33$ & $0{,}074$ & $0{,}085$ \\
		$32$\hphantom{9} & $3{,}03$ & $0{,}078$& $0{,}091$ & $3{,}32$ & $0{,}076$ & $0{,}085$ \\
		$64$\hphantom{9} & $3{,}03$& $0{,}078$& $0{,}091$ & $3{,}32$& $0{,}076$ & $0{,}085$\\
		\hline
    \end{tabular}
\end{table}

\begin{figure}[h]
	\subfloat[График $S(p)$ при $m=80$ и $n=80$]{\includegraphics[width=0.48\textwidth]{\hdir/b_s_schemes_s_plots}}
	\hfill
	\subfloat[График $E(p)$ при $m=80$ и $n=80$]{\includegraphics[width=0.48\textwidth]{\hdir/b_s_schemes_e_plots}}
	\caption{Сравнение схем распараллеливания}
	\label{fig:scheme_comparison}
\end{figure}



Для каждого из размеров матриц можно указать число $p^*$ такое, что при $p\leq p^*$ обе схемы эффективны: $S(p)\approx p$ и $E(p)\approx 1$.
Например, при $m=n=80$ число $p^*$ равно $16$.
При $p>p^*$ значения $T(p)$ <<стабилизируются>>.
Это связано с тем, что распараллеливание происходит на первом ярусе дерева решений, которое строит алгоритм RUNC"~M.
При таком подходе объемы подзадач сильно различаются, поэтому их принципиально невозможно равномерно распределить между большим числом процессоров.

Вычисление оценок для объемов подзадач, используемых в S"~схеме, гораздо менее трудоемкое, чем в В"~схеме.
Поэтому S"~схема применима и для больших матриц.
Это демонстрируется на матрицах размера $m{\times}n$, где $m\in \{30,40\}$ и $n\in \{100,150,200\}$.
Значение параметра $r$ полагалось равным $m/2$.

В табл. \ref{tab:s_scheme_time} приведено время работы $T(p)$ параллельного алгоритма дуализации, основанного на S"~схеме, при различных $m$, $n$ и $p$.
На рис. \ref{fig:s_scheme1} приведены графики $S(p)$ и $E(p)$.
На рис. \ref{fig:s_scheme2} приведена столбчатая диаграмма для достигнутых уровней загрузки $s_k(p), k\in J_p$ при $p=16$ и~32.

\begin{table}[t]\small
    \caption{Время работы $T(p)$ для S"~схемы}
    \label{tab:s_scheme_time}
    \centering\medskip
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\headline
		$m{\times}n \setminus p$ & $1$ & $2$ & $4$ & $8$ & $16$ & $32$ & $64$ & $128$ \\
		\hline
		$30{\times}100$ & \hphantom{99}$3{,}95$ & \hphantom{99}$2{,}03$ & \hphantom{99}$1{,}05$ & \hphantom{9}$0{,}59$ & \hphantom{9}$0{,}37$ & \hphantom{9}$0{,}32$ & \hphantom{9}$0{,}32$ & \hphantom{9}$0{,}32$ \\
		$30{\times}150$ & \hphantom{9}$39{,}1$\hphantom{9} & \hphantom{9}$20{,}0$\hphantom{9} & \hphantom{9}$10{,}4$\hphantom{9} & \hphantom{9}$5{,}21$ & \hphantom{9}$3{,}46$ & \hphantom{9}$2{,}32$ & \hphantom{9}$2{,}33$ & \hphantom{9}$2{,}32$ \\
		$30{\times}200$ & $231$\hphantom{,99} & $116$\hphantom{,99} & \hphantom{9}$61{,}5$\hphantom{9} & $32{,}2$\hphantom{9} & $18{,}8$\hphantom{9} & $13{,}8$\hphantom{9} & $13{,}8$\hphantom{9} & $13{,}8$\hphantom{9} \\
		$40{\times}100$ & \hphantom{9}$11{,}5$\hphantom{9} & \hphantom{99}$5{,}83$ & \hphantom{99}$3{,}05$ & \hphantom{9}$1{,}53$ & \hphantom{9}$0{,}96$ & \hphantom{9}$0{,}95$ & \hphantom{9}$0{,}95$ & \hphantom{9}$0{,}95$ \\
		$40{\times}150$ & $133$\hphantom{,99} & \hphantom{9}$67{,}1$\hphantom{9} & \hphantom{9}$34{,}8$\hphantom{9} & $19{,}1$\hphantom{9} & $10{,}9$\hphantom{9} & \hphantom{9}$9{,}44$ & \hphantom{9}$9{,}43$ & \hphantom{9}$9{,}43$ \\
		$40{\times}200$ & $654$\hphantom{,99} & $328$\hphantom{,99} & $177$\hphantom{,99} & $90{,}5$\hphantom{9} & $61{,}8$\hphantom{9} & $40{,}4$\hphantom{9} & $36{,}8$\hphantom{9} & $36{,}8$\hphantom{9} \\
		\hline
    \end{tabular}
    \vspace*{12pt}
\end{table}



\begin{figure}[h]
	\subfloat[График $S(p)$ при $m=40$]{\includegraphics[width=0.48\textwidth]{\hdir/s_scheme_s_plot}}
	\hfill
	\subfloat[График $E(p)$ при $m=40$]{\includegraphics[width=0.48\textwidth]{\hdir/s_scheme_e_plot}}
	\caption{Сильная масштабируемость S"~схемы}
	\label{fig:s_scheme1}
\vspace*{12pt}
\end{figure}

\begin{figure}[h]
	\subfloat[График $s_k(16)$ при $m=40$]{\includegraphics[width=0.48\textwidth]{\hdir/s_scheme_bars16}}
	\;
	\subfloat[График $s_k(32)$ при $m=40$]{\includegraphics[width=0.48\textwidth]{\hdir/s_scheme_bars32}}
	\caption{Достигнутый уровень загрузки в S"~схеме}
	\label{fig:s_scheme2}
\vspace*{12pt}
\end{figure}

S"~схема демонстрирует практически линейное ускорение и высокий уровень загрузки при $p\leq p^*$.
Например, $p^*=32$ при $m=40$ и $n=200$.
Согласно рис. \ref{fig:s_scheme2} для матрицы $40{\times}200$ достигнутый
уровень загрузки при $p=32$ для некоторых процессоров значительно превышает
среднее значение этого показателя,
что может быть результатом недостаточного качества оценки $f_r^*(j)$ или неоптимальности построенного жадным алгоритмом расписания.

%===========================================
\section{Заключение}


В данной работе развит предложенный в \cite{Nikiforov2014} подход к построению параллельных алгоритмов для дискретных перечислительных задач. Подход основан на статистических оценках объемов вычислительных подзадач.
Распределение вычислительных подзадач осуществляется согласно заранее составленному расписанию.
Для составления указанного расписания определяется вид распределения случайной величины, использующейся для оценки объемов подзадач, и оптимизируется уровень загрузки процессоров.
В рамках рассматриваемого подхода разработана новая менее трудоемкая схема распараллеливания асимптотически оптимальных алгоритмов дуализации.

Работа схемы продемонстрирована на примере распараллеливания алгоритма RUNC-M \cite{DjukovaProk2014}, который в настоящее время является лидером по скорости счета среди алгоритмов дуализации.
Предлагаемый подход к построению параллельных алгоритмов дуализации обеспечивает высокую точность оценок для объемов подзадач, что при определенных условиях приводит и к высоким показателям эффективности параллельного алгоритма.
Однако рассматриваемый подход не эффективен при  большом числе процессоров, поскольку вычислительные подзадачи имеют существенно разные размеры (распараллеливание происходит на первом ярусе дерева решений, которое строит асимптотически оптимальный алгоритм дуализации).

%===========================================

\renewcommand{\bibname}{Литература}

\bigskip

{\baselineskip=16.5pt

\begin{thebibliography}{11}

\medskip

\bibitem{Djukova1977} %1
    \BibAuthor{Дюкова~Е.\,В.}
{Об асимптотически оптимальном алгоритме построения тупиковых тестов}~//
{Докл. АН СССР}, 1977. Т. 223. №\,4. С.~527--530.
\bibitem{Papadimitriou1988}        %2
    \BibAuthor{Johnson~D.\,S., Yannakis~M., Papadimitriou~C.\,H.}
{On generating all maximal independent sets}~//
{Inform. Processing Lett.}, 1988. Vol.~27. P.~119--123.
\bibitem{Khachiyan1996} %3
    \BibAuthor{Khachiyan~L., Fredman~M.}
{On the complexity of dualization of monotone disjunctive normal forms}~//
{J.~Algorithms}, 1996. Vol.~21, No.\,3. P.~618--628.
\bibitem{Djukova1982} %4
    \BibAuthor{Дюкова~Е.\,В.}
{Асимптотически оптимальные тестовые алгоритмы в задачах распознавания}~//
{Пробл. кибернетики}, 1982. Т.~1. №\,39. С.~165--199.	
\bibitem{DjukovaZhu1997} %5
    \BibAuthor{Djukovа~E.\,V., Zhuravlev~Y.\,I.}
{Discrete methods of information analysis in recognition and algorithm synthesis}~//
{Pattern Recogn. Image Anal.}, 1997. Vol.~7. No.\,2. P.~192--207.	
\bibitem{DjukovaZhu2000} %6
    \BibAuthor{Дюкова~Е.\,В., Журавлев~Ю.\,И.}
{Дискретный анализ признаковых описаний в задачах распознавания большой размерности}~//
{Ж. вычисл. матем. и матем. физ.}, 2000. Т.~40. №\,8. С.~1264--1278.	
\bibitem{Djukova2004} %7
    \BibAuthor{Дюкова~Е.\,В.}
{О сложности реализации дискретных (логических) процедур распознавания}~//
{Ж. вычисл. матем. и матем. физ.}, 2004. Т.~44. №\,3. С.~551--561.
\bibitem{DjukovaInyakin2008} %8
    \BibAuthor{Дюкова~Е.\,В., Инякин~А.\,С.}
{Асимптотически оптимальное построение тупиковых покрытий целочисленной матрицы} //
{Математические вопросы кибернетики}, 2008. Т.~17. С.~235--246.
\bibitem{MurakamiUno2014} %9
    \BibAuthor{Murakami~K., Uno~T.}
{Efficient algorithms for dualizing large-scale hypergraphs}~//
{Discrete Appl. Math.}, 2014. Vol.~170. P.~83--94.
\bibitem{DjukovaProk2014} %10
    \BibAuthor{Дюкова~Е.\,В., Прокофьев~П.\,А.}
{Построение и исследование новых асимптотически оптимальных алгоритмов дуализации}~//
{Машинное обучение и анализ данных}, 2014. Т.~1. №\,8. С.~1048--1067.	
\bibitem{Khachiyan2005} %11
    \BibAuthor{Khachiyan~L., Boros~E., Elbassioni~K., Gurvich~V.}
{A new algorithm for the hypergraph transversal proble}~//
Computing and combinatorics~/
Ed. L.~Wang.~--- Lecture notes in computer science ser.~--- Springer,
2005. Vol.~3595. P.~767--776.
\bibitem{Khachiyan2007} %12
    \BibAuthor{Khachiyan~L., Boros~E., Gurvich~V., Elbassioni~K.}
{Computing many maximal independent sets for hypergraphs in parallel}~//
{Parallel Processing Lett.}, 2007. Vol.~17, No.\,2. P.~141--152.

\bibitem{Nikiforov2014}   %13
    \BibAuthor{Дюкова~Е.\,В., Никифоров~А.\,Г., Прокофьев~П.\,А.}
{Статистически эффективная схема распараллеливания алгоритмов дуализации}~//
{Машинное обучение и анализ данных}, 2014. Т.~1. №\,7. С.~846--853.
\end{thebibliography}

}


%===========================================
\renewcommand{\bibname}{References}

\bigskip

{%\baselineskip=16.5pt
\begin{thebibliography}{99}

\medskip

\bibitem{Djukova1977}
{Djukova,~E.\,V.} 1977.
On an asympotically optimal algorithm for constructing irredundant tests.
  \BibJournal{Dokl. Akad. Nauk SSSR} 223(4):527--530.
\bibitem{Papadimitriou1988}
{Johnson,~D.\,S., M.~Yannakis, and C.\,H.~Papadimitriou.} 1988.
On generating all maximal independent sets.
    \BibJournal{Inform. Processing Lett.} 27:119--123.
\bibitem{Khachiyan1996}
{Khachiyan~L., and M.~Fredman.} 1996.
{On the complexity of dualization of monotone disjunctive normal forms.}
    \BibJournal{J.~Algorithms} 21(3):618--628.
\bibitem{Djukova1982}
{Djukova,~E.\,V.} 1982.
{Asimptoticheski optimal'nye testovye algoritmy v~zadachakh raspoznavaniya}.
\BibJournal{Problemy Kibernetiki} 1(39):165--199.	
\bibitem{DjukovaZhu1997}
{Djukovа,~E.\,V., and Y.\,I.~Zhuravlev.} 1997.
{Discrete methods of information analysis in recognition and algorithm synthesis.}
    \BibJournal{Pattern Recogn. Image Anal.} 7(2):192--207.	
\bibitem{DjukovaZhu2000}
{Djukova,~E.\,V., and Y.\,I.~Zhuravlev.} 2000.
{Diskretnyy analiz priznakovykh opisaniy v zadachakh raspoznavaniya bol'shoy razmernosti}.
    \BibJournal{J.~Vychisl. Matem. i~Matem. Fiz.} 40(8):1264--1278.	
\bibitem{Djukova2004}
{Djukova,~E.\,V.}
{O slozhnosti realizatsii diskretnykh (logicheskikh) protsedur raspoznavaniya.}
    \BibJournal{J.~Vychisl. Matem. i~Matem. Fiz.} 44(3):551--561.
\bibitem{DjukovaInyakin2008}
{Djukova,~E.\,V., and A.\,S.~Inyakin.} 2008.
{Asymptoticheski optimal'noe postroenie tupikovykh pokrytiy tselochislennoy matritsy}.
     \BibJournal{Matematicheskie Vorposy Kibernetiki} 17:235--246.
\bibitem{MurakamiUno2014}
{Murakami,~K., and T.~Uno.} 2014.
{Efficient algorithms for dualizing large-scale hypergraphs}.
    \BibJournal{Discrete Appl. Math.} 170:83--94.
\bibitem{DjukovaProk2014}
{Djukova,~E.\,V., and P.\,A.~Prokofyev.} 2014.
{Construction and investigation of new asymptotically optimal
algorithms for dualization}.
    \BibJournal{Machine Learning Data Anal.} 1(8):1048--1067.	
\bibitem{Khachiyan2005}
{Khachiyan,~L., E.~Boros, K.~Elbassioni, and V.~Gurvich.} 2005.
{A new algorithm for the hypergraph transversal proble}.
    \BibTitle{Computing and combinatorics}. Ed.\ L.~Wang.
Lecture notes in computer science ser. Springer. 3595:767--776.
\bibitem{Khachiyan2007}
{Khachiyan,~L., E.~Boros, V.~Gurvich, and K.~Elbassioni.} 2007.
{Computing many maximal independent sets for hypergraphs in parallel.}
    \BibJournal{Parallel Processing Lett.} 17(2):141--152.
\bibitem{Nikiforov2014} %13
{Djukova,~E.\,V., A.\,G.~Nikiforov, and P.\,A.~Prokofyev.} 2014.
{Statistically efficient parallel scheme for dualization algorithms.}
 \BibJournal{Machine Learning Data Anal.} 1(7):846--853.
\end{thebibliography}

}

% Решение Программного Комитета:
%\ACCEPTNOTE
%\AMENDNOTE
%\REJECTNOTE
\end{document}

