\documentclass[12pt,twoside]{article}
\newcommand{\hdir}{.}
\usepackage{jmlda}
% \NOREVIEWERNOTES
\title
    {Relevance tagging machine}
\author
    {D.\,A. Molchanov, D.\,A. Kondrashkin, D.\,P. Vetrov}
    [D.\,A. Molchanov$^1$, D.\,A. Kondrashkin$^2$, and D.\,P.~Vetrov$^2$]
\email
    {$^1$dmolch111@gmail.com; $^2$kondra2lp@gmail.com; vetrovd@yandex.ru}
\organization
    {$^1$M.\,V.~Lomonosov Moscow State University, Moscow, Russia\par
 $^{2}$National Research University Higher School of Economics, Moscow, Russia}
\thanks{This research is funded by RFBR grant \#15-31-20596mol-a-ved,
Microsoft Research, research initiative: Computer vision collaborative
research in Russia, Skoltech SDP Initiative, applications A1 and
A2.}
\abstract
    {\noindent In many classification or regression problems, there may be a lot of irrelevant features.
Bayesian automatic relevance determination (ARD)
is a popular approach to feature selection.
However, the application area of this approach has been limited.
In this paper, this approach is utilized in a more general case and
it is applied to a binary classification problem with binary features.
Also, a~new binary classification model and a learning algorithm that can purge unwanted features from the model
have been developed.

    \bigskip
\noindent
    \textbf{Keywords}: \emph{binary classification; feature selection;
automatic relevance determination; sparse bayesian learning;
variational lower bounds}}
\titleRus
    % [Образец оформления статьи для публикации] % Краткое название; не нужно, если полное название влезает в~колонтитул
    {Машина релевантных тегов}
\authorRus
    % [Автор~И.\,О. и др.] % список авторов для колонтитула; не нужен, если основной список влезает в колонтитул
    {Д.\,А. Молчанов, Д.\,А. Кондрашкин, Д.\,П. Ветров} % основной список авторов, выводимый в оглавление
    [Д.\,А. Молчанов$^1$, Д.\,А. Кондрашкин$^2$, Д.\,П. Ветров$^2$] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\organizationRus
    {$^1$Московский государтсвенный университет им. М.\,В.~Ломоносова,
Москва, Россия\par
$^{2}$Национальный исследовательский университет <<Высшая школа экономики>>,
Москва, Россия}
\abstractRus
    {При решении многих задач классификации или регрессии зачастую приходится сталкиваться с большим количеством нерелевантных признаков.
Одним из известных способов решения задачи отбора признаков является метод, основанный на Байесовском подходе к~выбору модели.
Этот метод получил широкое распространение, однако область его применения была ограничена.
В~данной работе этот метод применяется
для более широкого класса моделей и исследуется на примере задачи бинарной классификации с бинарными признаками.
Также предложена новая модель для бинарной классификации данных и метод обучения этой модели, позволяющий автоматически убирать нерелевантные признаки.

\bigskip

\noindent
\textbf{Ключевые слова}: \emph {бинарная классификация;
отбор признаков; автоматическое определение релевантности;
вариационные нижние оценки}}
\begin{document}
\English
\maketitle
%\linenumbers
\section{Introduction}
\noindent
Feature selection is an important challenge that arises in most machine learning problems.
There are different approaches to this task.
One of them is to use predictive models that can automatically choose the most relevant features during the training procedure.
For example, it can be done with LASSO (Least Absolute Shrinkage and
Selection Operator) regression or other models that use L1"~regularization to ensure sparsity.
Bayesian ARD \cite{ard} is another approach to developing such models.
As an example, consider the Relevance Vector Machine (RVM), \cite{tipping}.
In case of regression, the RVM is a linear model with an ARD prior;
$\vec x$ is an object; $t$ is its target; $\vec w$ is a vector of model parameters or weights;
 and $\vec \phi(\vec x)$ is a vector of generalized features.
The model definition is shown below:
\begin{equation*}
%\label{rvmNotations}
\vec w=(w_1, \dots, w_M)^{\mathrm{T}} \in \RR^M;\ \
\vec \phi(\vec x)=(\phi_1(\vec x), \dots, \phi_M(\vec x))^{\mathrm{T}} \in \RR^M,\ \
t\in\RR;
\end{equation*}
\begin{equation}
  \label{rvm2}
  y(\vec x) = \vec w^{\mathrm{T}} \vec \phi(\vec x);
\end{equation}
\begin{equation}
  \label{rvm1}
  p(t\cond \vec x, \vec w, \beta) = \Normal(t\cond y(\vec x), \beta^{-1});
\end{equation}
\begin{equation}
  \label{rvm3}
  p(\vec w \cond \vec \alpha) = \prod_{i=1}^M \Normal(w_i\cond 0, \alpha_i^{-1})
\end{equation}
 and the following
expression is the marginal likelihood function, also known as evidence \cite{evidence}:
\begin{equation*}
  \label{rvm4}
  p(\vec t\cond \vec X, \vec \alpha, \beta) = \int p(\vec t\cond \vec X, \vec w, \beta)
                                                   p(\vec w\cond \vec \alpha)
\,                                                   d\vec w\,.
\end{equation*}

Equation \eqref{rvm1} defines the likelihood function for an object~$\vec x$.
Here,~$\beta$ is the noise precision,~$\beta = \sigma^{-2}$,
and $y(\vec x)$~is the mean of the target function given by
a linear model defined in~\eqref{rvm2}.
Expression \eqref{rvm3} describes the prior over the weight parameters~$\vec w$ (ARD prior).
When the evidence of the model is maximized with respect to hyperparameters~$\vec \alpha$, some of them go to infinity.
The corresponding weight parameters will then have posterior distributions
that are concentrated at zero; so, the corresponding basis functions~$\phi_i(\vec x)$ are pruned out of the model.
This effect is known as ARD effect and is explained and discussed
in~\cite{ard, tipping} and \cite[p.~349--353]{bishop}.

However, this effect is usually studied on models with Gaussian prior.
The present authors propose to extend this approach and use another family of distributions.
In this paper,  a binary classification problem with binary features
is considered as an example.
A~new probabilistic model has been developed
for this task and beta prior distribution has been used to reproduce ARD effect.

\section{Model of Relevance Tagging Machine}
%Model definition, Bayesian approach, evidence maximization.
\paragraph{Probabilistic model}
\noindent
Consider a binary classification problem of objects that have binary features (tags).
Let~$(\vec x_i, t_i)_{i=1}^n$~be the training set, where $\vec x_i$~is the
 object described by a binary vector,
$\vec x_i = (x_{i1}, \dots, x_{id})^{\mathrm{T}}$,
$d$~denotes the number of tags, and $t_i \in \{0, 1\}$~is the class label.
In this notation,~$x_{ij} = 1$ if object $\vec x_i$~has tag~$j$ and $x_{ij} = 0$ otherwise.

Under the assumption that all tags affect the class label independently, we define the probabilistic model of relevance tagging machine (RTM):
\begin{align*}
%  \label{rtmModel1}
  \Prob(t = 1\cond x_j = 1) &= q_j;
\\
%  \label{rtmModel2}
  \Prob(t = 1\cond \vec x, \vec q) &= \prod_{j = 1}^d q_j^{x_j} \times
                                       \left(
                                         \prod_{j = 1}^d q_j^{x_j} +
                                         \prod_{j = 1}^d (1 - q_j)^{x_j}
                                       \right)^{-1}
\end{align*}
where
$\vec q = (q_1, \dots, q_d)^{\mathrm{T}}$
are the model parameters, which are responsible for the tags' influence on the class label.

\paragraph{Bayesian Automatic Relevance Determination approach}
\noindent
Similarly to the RVM, follow a traditional Bayesian ARD approach to feature selection.
The basic idea is to treat parameters~$\vec q$ as random variables and place independent priors over them.
As the domain of~$q_j$ is~$[0, 1]$, it is natural to use beta distribution over~$q_j$.
Also, as both classes are meant to be of the same importance, symmetrical distribution is used:
\begin{equation*}
%  \label{rtmPrior}
  q_j \sim \mathrm{Beta}(\alpha_j+1, \alpha_j+1),\; \alpha_j \in [0, +\infty).
\end{equation*}
Here,~$\alpha_j = 0$ corresponds to the uniform distribution over~$q_j$, so that there is no regularization of~$q_j$.
Contrary, if~$\alpha_j$ tends to plus infinity, the variance of~$q_j$ tends to zero and that implies~$q_j = 0.5$.
It means that the~$j$th tag is removed from the model:
\begin{multline*}
\Prob(t\cond \vec x, \vec q =
    (q_1, \dots, q_{j-1}, q_j=0.5, q_{j+1}, \dots, q_d)^{\mathrm{T}})  \\
{}=
\Prob(t\cond \vec x, \vec q =
    (q_1, \dots, q_{j-1}, q_{j+1}, \dots, q_d)^{\mathrm{T}}) =
    \Prob(t\cond \vec x, \vec q^{\backslash j}).
\end{multline*}

Note that the case~$\alpha_j \in (-1, 0)$ is not
considered because in this case, maximum a posteriori (MAP) estimate of~$\vec q$ would be more contrast (i.e. closer to $0$ or $1$) than maximum likelihood (ML) estimate.
In case of the problem under investigation,
it is unreasonable to believe that a tag is actually more relevant than it seems to be.

The posterior is written using Bayes' theorem:
\begin{equation}
  \label{rtmBayes}
  \Prob(\vec q\cond \vec X, \vec t, \vec \alpha) =
    \frac{\Prob(\vec t\cond \vec X, \vec q) p(\vec q\cond \vec \alpha)}
         {\int \Prob(\vec t\cond \vec X, \vec q) p(\vec q\cond \vec \alpha) d\vec q}\,.
\end{equation}

\paragraph{Evidence maximization}
\noindent
The denominator in Eq.~\eqref{rtmBayes} is called the \emph{evidence} \cite{evidence} of the model.
In general, a~simple model has higher evidence than the
 complex one if they have the same prediction accuracy \cite[p.~349--352]{bishop}.
In the presented case, evidence maximization is expected
to set~$\alpha_j = +\infty$ for the majority of irrelevant features:
\[
E(\vec \alpha) = \int \Prob(\vec t\cond \vec X, \vec q)
p(\vec q\cond \vec \alpha) \,d\vec q \to \max_{\vec \alpha}\,.
\]

However, in the described model, likelihood and prior are not the
conjugate distributions; so, the evidence is intractable.
It also cannot be efficiently estimated numerically, because numerical computation of multidimensional integrals is a very difficult and time"=consuming task.
Therefore, one needs some kind of approximation in order to maximize the evidence.
In this paper, an approach that uses variational lower bounds for optimization
is described.

\section{Variational lower bounds for evidence maximization}
\begin{Definition}
A variational lower bound on a function~
$f(\vec w)$,\;
$\vec w \in M \subseteq \RR^n$,
is a function~
$g(\vec w, \vec \xi),\; \vec w \in M,\; \vec \xi \in M$,
with the following properties:
\begin{align*}
  g(\vec w, \vec w) &= f(\vec w)\; \forall \vec w \in M;\\
  g(\vec w, \vec \xi) &\leq f(\vec w) \; \forall \vec w \in M,\; \forall \vec \xi \in M,
\end{align*}
$\vec \xi$~is called a variational parameter.
\end{Definition}

Consider an optimization problem~$f(\vec w) \to \max_{\vec w}$.
If $g(\vec w, \vec \xi)$~is a variational lower bound on~$f(\vec w)$, then this optimization problem can be solved in such coordinatewise optimization procedure:
\begin{equation*}
    \vec w^{k+1}   = \argmax_{\vec w} g(\vec w, \vec \xi^k);\quad
    \vec \xi^{k+1} = \vec w^{k+1}.
\end{equation*}

This optimization procedure is known as bound optimization algorithm or bound optimizer.
Many popular optimization methods in machine learning and pattern recognition are
the special cases of this algorithm.
For instance, EM (expectation--maximization)
algorithm and its extensions, generalized iterative scaling algorithm for maximum entropy models,
nonnegative matrix factorization algorithm, and concave-convex procedure
are the common examples of bound optimizers \cite{boalgo}.

In  general case, this lower bound may not be exact for any point~$\vec w$ and variational parameters may be from a different space.
In that case, the result of a similar optimization procedure
\begin{equation}
  \label{optProc}
    \vec \xi^{k+1} = \argmax_{\vec \xi} g(\vec w^k, \vec \xi);\quad
    \vec w^{k+1}   = \argmax_{\vec w}   g(\vec w,   \vec \xi^{k+1})
\end{equation}
 can be treated as an approximate solution of the original optimization task.

This approach is widely used in various optimization problems.
The best feature of it is that there is no need to compute the original function~$f(\vec w)$.
For example, a similar approach is used in \cite{JJ} where it is applied to Bayesian logistic regression.

In case of RTM, this approach is applied to evidence maximization.
A~variational lower bound has been obtained on the evidence integrand and
its integral has been used as a set of evidence lower bounds which can be used in an optimization procedure shown in \eqref{optProc}.

%The shape of this lower bound is shown on Figures (\ref{varBoundSingle}-\ref{varBoundMulti}).

\begin{Theorem}
\label{th1}
Function~
$\tilde E(\vec \alpha, \vec H)$
is a lower bound on RTM evidence for all~
$\vec H \in (0, 1)^{n{\times}d}$,\;
$\vec \alpha \in [0, +\infty)^d:$
\begin{align*}
E(\vec \alpha) \geq
  \tilde{E}(\vec \alpha, \vec H)
  &= \int \prod_{i = 1}^n L_i(\vec q, \vec \eta_i)
      \prod_{j = 1}^d p(q_j\cond \alpha_j) \,d\vec q ={} \\ {}&={}
  \left(
    \prod_{i = 1}^n c_i(\vec \eta_i)
  \right)
  \prod_{j = 1}^d \int \exp
    \left(
      \sum_{i:j \in Q_i} \tilde c_{ij}(\vec \eta_i)
        \left(
          \frac{1 - q_j}{q_j}
        \right)
        ^{|Q_i|(2t_i-1)}
    \right)
    p(q_j\cond \alpha_j)\, dq_j
\end{align*}
\[
\forall \vec H \in (0, 1)^{n{\times}d},\;
\forall \vec \alpha \in [0, +\infty)^d,
\]
where
\begin{align*}
Q_i &= \{j | x_{ij} = 1\}; \\
c_i(\vec \eta_i) &=
  \frac{\prod\limits_{j \in Q_i} \eta_{ij}^{t_i}(1 - \eta_{ij})^{1 - t_i}}
       {\prod\limits_{j \in Q_i} \eta_{ij} + \prod\limits_{j \in Q_i}(1 - \eta_{ij})}
  \exp
  \left(
    \frac{\prod\limits_{j\in Q_i} \eta_{ij}^{1 - t_i} (1 - \eta_{ij})^{t_i}}
         {\prod\limits_{j\in Q_i} \eta_{ij} + \prod\limits_{j \in Q_i}(1 - \eta_{ij})}
  \right);\\
\tilde c_{ij}(\vec \eta_i) &=
  -\frac{\prod\limits_{j \in Q_i} \eta_{ij}^{t_i} (1 - \eta_{ij})^{1 - t_i}}
        {\prod\limits_{j \in Q_i} \eta_{ij} + \prod\limits_{j \in Q_i}(1 - \eta_{ij})}
  \left(
    \frac{\eta_{ij}}
         {1 - \eta_{ij}}
  \right)
  ^{|Q_i|(2t_i - 1)} |Q_i|^{-1};
\end{align*}
and $\vec H$~is the matrix of variational parameters and its $i$th
row is equal to~$\vec \eta_i^{\mathrm{T}}$.


\end{Theorem}

The proof of Theorem~1 is provided in Appendix~A.

The shapes of the evidence integrand and its lower bounds are shown in
Figs.~\ref{varBoundSingle} and \ref{varBoundMulti}.
Note that although the evidence lower bound can be computed as a product of~$d$~one"=dimensional integrals, these integrals still have to be computed numerically.
Also, note that although the number of variational parameters is $nd$, usually most of them are inessential and do not affect the value of this lower bound.
A variational parameter $\eta_{ij}$ is essential if and only if $x_{ij} = 1$.
Therefore, there are only $n\tau$ essential variational parameters
where $\tau$ is the average number of tags per object.

The evidence lower bound is optimized in an EM"~like algorithm:
\begin{enumerate*}
  \item E"~step:
    $\vec H^{\mathrm{new}} = \argmax_{\vec H} \log \tilde E(\vec \alpha^{\mathrm{old}}, \vec H)$; and
  \item M"~step:
    $\vec \alpha^{\mathrm{new}} = \argmax_{\vec \alpha} \log
\tilde E(\vec \alpha, \vec H^{\mathrm{new}})$.\\
  These two steps are repeated until convergence.
\end{enumerate*}

\begin{figure}
\centering
\includegraphics[width=0.49\linewidth]{\hdir/101t0.eps}\hfill
\includegraphics[width=0.49\linewidth]{\hdir/011t0.eps}\\
(\textit{a})\hfil\hfil(\textit{b})\hfil\\
\caption{Evidence integrand variational lower bounds for a single object for different values of variational parameters $\mathbf{\eta}$:
(\textit{a})~$t = 0,\; \vec x = (1,0,1)^{\mathrm{T}}$ and $q_1 = 0.8$; and
(\textit{b})~$t = 0,\; \vec x = (0,1,1)^{\mathrm{T}}$ and $q_2 = 0.2$}
\label{varBoundSingle}
\end{figure}

\begin{figure}
\center{
\includegraphics[width=0.5\textwidth]{\hdir/alldata2d.eps}
}
\caption{Evidence integrand lower bounds for the whole dataset}
\label{varBoundMulti}
\end{figure}

On E"~step, hyperparameters~$\vec \alpha$ are fixed and variational parameters~$\vec H$ are tuned to obtain the most accurate lower bound.
On M"~step, the best lower bound from the E"~step is optimized with respect to hyperparameters~$\vec \alpha$.
The L"~BFGS"~B method \cite{lbfgsb} was used to handle optimization problems on both steps of algorithm.
This method is called RTM"~EM.

Let $k_E$ and $k_M$ be the number of iterations of L-BFGS-B on E-step and
M-step, respectively.
The complexity of one iteration is then equal to $O(n\tau k_E + dk_M)$ operations of numerical integration.

Complexity of RTM"~EM is too high; so,  a simplification is suggested.
In RTM"~EM, on E"~step of EM algorithm, an attempt to obtain the best possible value of variational parameters
was made.
Instead of that, a~variational lower bound on the evidence integrand
was used that is exact at its point of maximum.
E"~step will then look like this:
         \begin{equation*}
  \vec \eta_i^{\mathrm{new}} = \vec q^{\mathrm{MAP}} =
  \argmax_{\vec q} \Prob(\vec t \cond \vec X,\vec q) p(\vec q \cond \vec \alpha^{\mathrm{old}})
  \; \forall i.
\end{equation*}

Note that all objects share the same set of variational parameters;
so, there are only $d$ of them:
$\vec \eta_i = \vec \eta_k$~for all~$i, k = 1, \dots, n$.
This method was named RTM"~MAP"~EM.
Its complexity is $O(dk_M)$ operations of numerical integration.

It was experimentally shown that RTM"~MAP"~EM also purges irrelevant (both noisy and correlated) tags and has comparable accuracy with RTM"~EM algorithm.
Also, both EM"~based methods remove the majority of irrelevant tags on early steps.
It means that only several steps of EM"~algorithm are needed for feature selection.
Further optimization will just tune the remaining hyperparameters.

The complete algorithm of RTM"~MAP"~EM is provided in Appendix~B.

\section{Experiments}
\paragraph{Synthetic data}
\noindent
The ability of the presented methods
 to remove irrelevant features on a synthetic dataset was studied
and compared to two classic feature selection models~--- RVM, where a similar idea is applied to linear regression, and L1"~regularized logistic regression.
There were 500 objects and 50 features.
The data consisted of genuine tags that were used to generate the class label, and two types of irrelevant tags: random tags and tags that were correlated to some of the genuine tags.
Relevance determination accuracy is shown in Table \ref{synthetic}.

\begin{table}[t]\small
  \caption{Relevance determination performance on synthetic data}
  \label{synthetic}
  \centering\medskip
   \begin{tabular}{lrrrr}
    \headline
    Noise & RTM"~MAP"~EM & RTM"~EM & RVM & L1"~LR \\
    \hline
    \multicolumn{5}{c}{Percentage of removed irrelevant tags} \\
\hline
    Random & $99.64\%$ & $99.46\%$ & $99.10\%$ & $85.63\%$ \\
    Correlated & $84.44\%$ & $88.90\%$ & $84.65\%$ & $100.00\%$ \\
    \hline
    \multicolumn{5}{c}{Percentage of removed genuine tags} \\
\hline
    Random & $4.50\%$ & $4.68\%$ & $2.63\%$ & $3.54\%$ \\
    Correlated & $2.50\%$ & $4.34\%$ & $1.04\%$ & $2.50\%$ \\
    \hline
  \end{tabular}
\end{table}

Both EM"~based methods successfully remove nearly all random features and most correlated features.
The RTM"~MAP"~EM, RTM"~EM, and RVM give comparable results and detect random features better than L1"~regularized logistic regression
(L1--LR).
However, L1--LR provided the best results in removing correlated tags.

\paragraph{Sentiment analysis}
\noindent
Also, the methods were tested on a real task: sentiment analysis problem \cite{kaggle}.
In this problem, objects are sentences and the task is to classify them into positive
and negative ones.
A bag of words representation was used
(each tag represents a word;
$x_{ij} = 1$ if object~$\vec x_i$ contains the~$j$th word from the dictionary).
There were $1000$~train objects, $411$~test objects, and $1869$~features.
There were $11$~tags per objects in average.
Test set classification accuracy is shown in Table \ref{sentimentRes}.

The present method (RTM"~MAP"~EM) was compared to different
state"=of"=the"=art classifiers like the RVM,
L1"~LR, Random Forest (RF), gradient boosting over decision stumps (GBDT), and SVM.

\begin{table}[t]\small
  \caption{Prediction performance on sentiment analysis dataset}
  \label{sentimentRes}
  \centering\medskip

    \tabcolsep=33pt
  \begin{tabular}{cc}
\hline
Method& Prediction accuracy\\
\hline
    RTM"~MAP"~EM & 0.9659\\
RVM & 0.9586\\
L1"~LR & 0.9708\\
RF & 0.9416\\
GBDT & 0.9683\\
SVM &0.9683\\
    \hline
  \end{tabular}
\end{table}

\vspace{0.4em}
The present method provides prediction accuracy that is comparable to
classical methods.
It also provides a way to sort features with respect to their importance:
RTM"~MAP"~EM chose about $70$~tags to be relevant and removed everything else;
L1"~LR chose about $120$~tags; and the RVM chose about $230$~tags.
A histogram of weights of most relevant words for these methods is shown in Figs.~\ref{hist1}--\ref{hist3}.

\begin{figure}[h]
\includegraphics[width=0.49\textwidth]{\hdir/hist_map_pos.eps}
\includegraphics[width=0.49\textwidth]{\hdir/hist_map_neg.eps}
\caption{$q_j-0.5$ for most relevant tags according to RTM"~MAP"~EM}
\label{hist1}
\end{figure}

\begin{figure}[h]
\includegraphics[width=0.49\textwidth]{\hdir/hist_lr_pos.eps}
\includegraphics[width=0.49\textwidth]{\hdir/hist_lr_neg.eps}
\caption{Weights of linear model tuned by L1-LR}
\label{hist2}
\end{figure}

\begin{figure}[h]
\includegraphics[width=0.49\textwidth]{\hdir/hist_rvm_pos.eps}
\includegraphics[width=0.49\textwidth]{\hdir/hist_rvm_neg.eps}
\caption{Weights of linear model tuned by RVM}
\label{hist3}
\end{figure}

The RVM chose a lot of rare words to represent the negative class
(words ``crappy,'' ``shitty,'' ``lousy,'' ``blame,'' ``afraid,''
``piece,'' and ``idiot'' have less than seven occurrences in the dataset)
and the words from the positive class does not look relevant at all.
The RVM failed to solve the relevance determination problem on this dataset.

The words chosen by RTM"~MAP"~EM and logistic regression are quite intuitive in case of this problem.
Most of them are very emotional.
Top-20 words chosen by logistic regression are almost the
same as top-20 words, chosen by the  present method.
However, the present model provided a more sparse solution with comparable prediction performance.
Therefore, the present method proved to be better at relevance determination than logistic regression and the RVM on this dataset.

\section{Concluding Remarks}
\noindent
Most of previous work on Bayesian ARD approach consider only Gaussian prior.
The authors demonstrate that other appropriate priors may also work well.
It means that Bayesian ARD approach might be more broad than it was considered before and is not limited to the
usage of Gaussian prior.
Also,  a~method to solve a binary classification problem with binary features
is suggested and an experimental comparison which shows that
the present model is comparable to the state"=of"=the"=art methods of classification and feature selection
is provided.
The experiments show that the present
model provides better feature selection results than
the classic feature selection models like RVM and L1-LR.

\newpage
{\small
\begin{flushright}
\textbf{Appendix A}
\end{flushright}

\noindent
{\normalsize\textbf{Proof of Theorem \ref{th1}}}

\medskip

\noindent
Derive a variational lower bound on the likelihood function for a single object~$\vec x$.
Let~$Q$~be the set of its tags:
$Q = \{j | x_j = 1\}$.
After some transformations and a change of variables,
a~convex function is obtained  and its tangent is used
as its variational lower bound:

\begin{equation*}
\Prob(t \cond \vec x, \vec q) =
  \frac{\prod\limits_{j \in Q} q_j^t (1 - q_j)^{1 - t}}
       {\prod\limits_{j \in Q} q_j + \prod\limits_{j \in Q} (1 - q_j)} =
  \left(
    1 +
    \prod_{j \in Q}
      \left(
        \frac{1-q_j}{q_j}
      \right)
      ^{2t - 1}
  \right)^{-1}
\end{equation*}
as  $t \in \{0, 1\}$;
\begin{equation*}
  s_j :=
    \left(
      \frac{1 - q_j}{q_j}
    \right)^{|Q|(2t-1)}\,;
\end{equation*}
so,
\begin{equation}
  \label{varBoundDerive}
  \log \Prob(t \cond \vec x,\vec q) =
  -\log
    \left(
      1 +
      \left(
        \prod_{j \in Q} s_j
      \right)^{1 / |Q|}
    \right).
\end{equation}

As $s_j > 0$, the geometric mean~
$\left(
  \prod\limits_{j \in Q} s_j
 \right)^{1 / |Q|}$
is concave with respect to~$\vec s$ \cite[p.~74]{boyd}.
As $f(x) = -\log x$~is convex and nonincreasing, the whole expression on the right part of \eqref{varBoundDerive} is convex with respect to~$\vec s$ \cite[p.~84]{boyd}.
Therefore, its tangent is its variational lower bound and after making inverse change of variables and taking the exponent,
one obtains a variational lower bound on
$\Prob(t \cond \vec x,\vec q)$.

The variational lower bound on the likelihood of an object~$\vec x_i$ from the training set looks as follows:
\begin{equation*}
  \Prob(t_i \cond \vec x_i, \vec q) \geq
  L_i(\vec q, \vec \eta_i) =
  c_i(\vec \eta_i) \exp
    \left(
      \sum_{j \in Q_i}
        \tilde c_{ij}(\vec \eta_i)
          \left(
            \frac{1 - q_j}{q_j}
          \right)^{|Q_i|(2t_i - 1)}
    \right)
\end{equation*}
where
\begin{align*}
Q_i &= \{j | x_{ij} = 1\}; \\
c_i(\vec \eta_i) &=
  \frac{\prod\limits_{j \in Q_i} \eta_{ij}^{t_i}(1 - \eta_{ij})^{1 - t_i}}
       {\prod\limits_{j \in Q_i} \eta_{ij} + \prod\limits_{j \in Q_i}(1 - \eta_{ij})}
  \exp
  \left(
    \frac{\prod\limits_{j\in Q_i} \eta_{ij}^{1 - t_i} (1 - \eta_{ij})^{t_i}}
         {\prod\limits_{j\in Q_i} \eta_{ij} + \prod\limits_{j \in Q_i}(1 - \eta_{ij})}
  \right);\\
\tilde c_{ij}(\vec \eta_i) &=
  -\frac{\prod\limits_{j \in Q_i} \eta_{ij}^{t_i} (1 - \eta_{ij})^{1 - t_i}}
        {\prod\limits_{j \in Q_i} \eta_{ij} + \prod\limits_{j \in Q_i}(1 - \eta_{ij})}
  \left(
    \frac{\eta_{ij}}
         {1 - \eta_{ij}}
  \right)
  ^{|Q_i|(2t_i - 1)} |Q_i|^{-1}.
\end{align*}

The following equation concludes the proof:
              \begin{equation*}
%\label{proofEnd}
E(\vec \alpha) = \int \Prob(\vec t\cond \vec X, \vec q) p(\vec q\cond \vec \alpha) \,d\vec q \geq
\int \prod_{i = 1}^n L_i(\vec q, \vec \eta_i) \prod_{j = 1}^n p(q_j \cond \alpha)\, d\vec q = \tilde E(\vec \alpha, \vec H)\,.
\end{equation*}

Note that each object has its own set of variational parameters.
As $\vec \eta_{ij}$~is dummy if $q_j \not \in Q_i$, there are $\sum_{i, j} x_{ij}$~essential variational parameters.
}

\newpage

{\small
\begin{flushright}
\textbf{Appendix B}
\end{flushright}

\noindent
{\normalsize\textbf{RTM"~MAP"~EM algorithm}}

%\medskip

\begin{algorithm}[H]
\caption{RTM"~MAP"~EM}
\label{rtmMAP}
\begin{algorithmic}[1]
 \REQUIRE{
 training set $(\vec X, \vec t)$;
 maximum number of iterations $T$;
 tolerance $\epsilon$}
 \ENSURE{tuned vector of hyperparameters $\vec \alpha$}
 \STATE{$\vec \alpha^0 \leftarrow (1, \dots, 1)^{\mathrm{T}}$}
 \COMMENT{Initial value of hyperparameters}
 \STATE{$\vec \eta^0 \leftarrow
           \argmax_{\vec q}
             \sum_{i = 1}^n \log \Prob(t_i \cond \vec x_i,\vec q)
             + \log \Prob(\vec q \cond \vec \alpha^0)$}
 \COMMENT{$\vec \eta = \vec q^{\mathrm{MAP}}$}
 \FOR{$k = 0$ to $T$}
    \STATE{}\COMMENT{E"~step:}
    \STATE{$\vec \eta^{k} \leftarrow
              \argmax_{\vec q}
                \sum_{i = 1}^n \log \Prob(t_i \cond \vec x_i,\vec q)
                + \log \Prob(\vec q \cond \vec \alpha^{k - 1})$}
    \COMMENT{$\vec \eta = \vec q^{\mathrm{MAP}}$}
    \STATE{$\vec H^k \leftarrow (\vec \eta^k, \dots, \vec \eta^k)^T$}
    \STATE{}\COMMENT{M"~step:}
    \STATE{$\vec \alpha^k \leftarrow \argmax_{\vec \alpha} \log \tilde E(\vec \alpha, \vec H^k)$}
    \IF{$\|\vec \alpha^k - \vec \alpha^{k - 1}\|^2 < \epsilon$}
        \STATE{$\mathbf{break}$}
    \ENDIF
\ENDFOR
 \STATE{$\vec \alpha \leftarrow \vec \alpha^k$}
 \RETURN{$\vec \alpha$}
\end{algorithmic}
\end{algorithm}
Some notes about implementation:
\begin{itemize}
%\item All integrals are computed using a simple adaptive integrator from QUADPACK Fortran 77 library \cite{quadpack}
\item $q_j$ and $\eta_{ij}$ are bound to $[0.1, 0.9]$ for all $i, j$. Otherwise, computations tend to be unstable;
\item $k_E=k_M=10$ in all experiments;
\item $\alpha_j$ is bound to $[0, 1000]$ for all $j$. If $\alpha_j\ge 900$, it is considered to be infinite: $\alpha_j:=+\infty$; and
\item there seems to be no need to wait till full convergence; for RTM"~MAP"~EM, $T=20$ was enough in both experiments.
\end{itemize}
}

\newpage
\begin{thebibliography}{1}
%\bibitem{author09anyscience}
%    \BibAuthor{Author\;N.}
%    \BibTitle{Paper title}~//
%    \BibJournal{10-th Int'l. Conf. on Anyscience}, 2009.  Vol.\,11, No.\,1.  Pp.\,111--122.



\bibitem{ard} %1
{MacKay,\;D., and R.\;Neal.}  1994.
{Automatic relevance determination for neural networks}.
Cambridge University. Technical Report.

\bibitem{tipping} %2
{Tipping,\;M.\,E.} 2001.
{Sparse Bayesian learning and the relevance vector machine}.
  \BibJournal{J.~Machine Learning Res.}  1:211--244.

\bibitem{evidence} %3
{MacKay,\;D.} 1992.
{Bayesian interpolation}.
  \BibJournal{Neural Computation} 4:415--447.

\bibitem{bishop} %4
{Bishop,\;C.\,M.} 2006.
\BibTitle{Pattern recognition and machine learning.}
  New York, NY: Springer. 738~p.

\bibitem{boalgo} %5
{Salakhutdinov,\;R., S.\;Roweis, and Z.\;Ghahramani}. 2002.
{On the convergence of bound optimization algorithms}.
  \BibJournal{19th Conference on Uncertainty in Artificial Intelligence
Proceedings}.  10:509--516.

\bibitem{JJ} %6
{Jaakkola,\;T.\,S., and M.\,I.\;Jordan.} 2000.
Bayesian logistic regression: A~variational approach.
  \BibJournal{Stat. Comput.} 10:25--37.



\bibitem{boyd} %7
{Boyd,\;S., and L.\;Vandenberghe.} 2004.
\BibTitle{Convex optimization}.
  Cambridge: Cambridge University Press. 716~p.

\bibitem{lbfgsb} %8
{Byrd,\;R., P.\;Lu, and J.\;Nocedal.} 1995.
{A~limited memory algorithm for bound constrained optimization}.
  \BibJournal{SIAM J.~Sci. Stat. Comput.} 16(5):1190--1208.

\bibitem{kaggle} %9
  Kaggle in Class.
2011.  UMICH SI650~--- Sentiment Classification.
Available at: \BibUrl{http://inclass.kaggle.com/c/si650winter11/data}
(accessed December~29, 2015).

\end{thebibliography}

\Russian
\begin{thebibliography}{1}
\renewcommand{\bibname}{Литература}
%\bibitem{author09anyscience}
%    \BibAuthor{Author\;N.}
%    \BibTitle{Paper title}~//
%    \BibJournal{10-th Int'l. Conf. on Anyscience}, 2009.  Vol.\,11, No.\,1.  Pp.\,111--122.



\bibitem{ard}       %1
  \BibAuthor{MacKay\;D., Neal\;R.}
{Automatic relevance determination for neural networks}~//
Cambridge University, 1994. Technical Report.

\bibitem{tipping} %2
  \BibAuthor{Tipping\;M.\,E.}
{Sparse Bayesian learning and the relevance vector machine}~//
{J.~Machine Learning Res.}, 2001.  No.\,1. P.~211--244.

\bibitem{evidence} %3
  \BibAuthor{MacKay\;D.}
{Bayesian interpolation}~//
{Neural Computation}, 1992.  No\,4. P.~415--447.

\bibitem{bishop} %4
  \BibAuthor{Bishop\;C.\,M.}
  Pattern recognition and machine learning.~---
  New York, NY, USA: Springer, 2006. 738~p.

\bibitem{boalgo} %5
  \BibAuthor{Salakhutdinov R., Roweis~S., Ghahramani~Z.}
{On the convergence of bound optimization algorithms}~//
{19th Conference on Uncertainty in Artificial Intelligence
Proceedings}, 2002.  No.\,10. P.~509--516.

\bibitem{JJ} %6
  \BibAuthor{Jaakkola\;T.\,S., Jordan\;M.\,I.}
{Bayesian logistic regression: A variational approach}~//
{Stat. Comput.}, 2000.  No.\,10. P.~25--37.



\bibitem{boyd} %7
  \BibAuthor{Boyd\;S., Vandenberghe\;L.}
  Convex optimization.~---
  Cambridge: Cambridge University Press, 2004. 716~p.

\bibitem{lbfgsb} %8
  \BibAuthor{Byrd\;R., Lu\;P., Nocedal\;J.}
{A~limited memory algorithm for bound constrained optimization}~//
  \BibJournal{SIAM J.~Sci. Stat. Comput.}, 1995.  Vol.~16, No.\,5.  P.~1190--1208.

\bibitem{kaggle} %9
  Kaggle in Class. UMICH SI650~--- Sentiment Classification. 2011.
  \BibUrl{http://inclass.kaggle.com/c/si650winter11/data}.
\end{thebibliography}

% Решение Программного Комитета:
%\ACCEPTNOTE
%\AMENDNOTE
%\REJECTNOTE
\end{document}
