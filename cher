\documentclass[12pt, twoside]{article}
\usepackage{jmlda}
\setcounter{page}{1893}
%\usepackage{lineno}
%\usepackage{subcaption}
\def\UrlBreaks{\do\/\do-}

\newcommand{\hdir}{.}

\graphicspath{ {\hdir/fig/} }

%\NOREVIEWERNOTES
\title
    [Прогнозирование нестационарных временных рядов при несимметричных функциях потерь]
	{Прогнозирование нестационарных временных рядов при несимметричных функциях потерь}
\author
	{В.\,Ю.\, Черных, М.\,М.\, Стенина}
	[В.\,Ю.\, Черных$^1$, М.\,М.\, Стенина$^{1, 2}$]
\thanks
    {Работа выполнена при финансовой поддержке РФФИ, проект~\No\,14-07-31046. }
\email
    {vladimir.chernykh@phystech.edu, mmedvednikova@gmail.com}
\organization
    {$^1$Московский физико-технический институт, Долгопрудный, Россия\par
$^2$Высшая школа экономики, Москва, Россия}
\abstract
    {Рассматривается задача прогнозирования временн\'{ы}х
рядов при несимметричных функциях потерь. Предлагается двухэтапный
алгоритм прогнозирования ARIMA\;+\;Hist. На первом этапе используется
авторегрессионное интегрированное скользящее среднее ARIMA с сезонной
компонентой в случае необходимости. Параметры модели подбираются согласно
методологии Бокса--Дженкинса. На втором этапе проводится анализ регрессионных
остатков и находится оптимальная добавка к прогнозу, полученному на первом шаге,
минимизирующая математическое ожидание потерь. Для оценки ожидаемых потерь
используется свертка функции потерь с гистограммой регрессионных остатков.
Работа предлагаемого двухэтапного алгоритма иллюстрируется на временн\'{ы}х
рядах с различными элементами нестационарности (тренд, сезонность) и~для
различных симметричных и~несимметричных функций потерь. Демонстрируется, что
качество прогнозов двухэтапного алгоритма превосходит качество прогнозов
модели ARIMA в случае несимметричных функций потерь.
	
\bigskip
\noindent
\textbf{Ключевые слова}: \emph {прогнозирование; временные ряды;
нестационарность; ARIMA; свертка с функцией потерь;
несимметричная функция потерь}
}
\titleEng
    [Forecasting nonstationary time series under asymmetric loss]
    {Forecasting nonstationary time series under asymmetric loss}
\authorEng
	{V.\,Y.~Chernykh, M.\,M.~Stenina}
	[V.\,Y.~Chernykh$^1$ and M.\,M.~Stenina$^{1, 2}$]
\organizationEng
    {$^1$Moscow Institute of Physics and Technology, Dolgoprudny, Russia\par
$^2$Higher School of Economics, Moscow, Russia}
\abstractEng
    {\noindent
The problem of forecasting time series under asymmetric loss functions
is considered. A~new two-step forecasting algorithm ARIMA\;+\;Hist
is presented. At the first step, autoregression integrated moving average
algorithm ARIMA with seasonal components is used. The parameters of the model
are selected according to Box--Jenkins methodology. At the second step, the
residuals are analyzed and optimal addition to the forecast of the first step
which minimize the expected value of losses is found. Expected loss is
estimated by convolution of loss function with the histogram of regression
residuals. The performance of the algorithm is demonstrated
on time series with different types of nonstationarity (i.\,e.,
trend or seasonality) and for different symmetric and asymmetric loss functions. The results obtained during this experiment show that the quality of the forecast of two-step ARIMA+Hist exceed the quality of usual ARIMA in case of asymmetric loss functions.

\bigskip		
\noindent
\textbf{Keywords}: \emph{forecasting; time series; nonstationary; ARIMA;
convolution with loss function; asymmetric loss}
}

\begin{document}
\maketitle
%\linenumbers
\section{Введение}
Рассматривается задача прогнозирования нестационарных временн\'{ы}х
рядов в случае несимметричных функций потерь. Предлагается двухэтапный
алгоритм прогнозирования ARIMA\;+\;Hist, на первом этапе которого
отслеживаются свойства временн\'{о}го ряда, обуслов\-ли\-ва\-ющие его нестационарность, такие как тренд и сезонность. На втором этапе предлагается находить поправку, обеспечивающую оптимальность прогноза в случае несимметричной функции потерь.

Свойства прогнозов временн\'{ы}х рядов при использовании несимметричных функций потерь были исследованы в работе \cite{patton2007properties}, авторы которой отмечают смещенность оптимальных прогнозов при несимметричных потерях и делают вывод о необходимости разработки специальных методов прогнозирования временн\'{ы}х рядов в условиях несимметричности функции потерь.

Один из используемых методов прогнозирования нестационарных временн\'{ы}х
рядов, авторегрессионное интегрированное скользящее среднее
ARIMA~\cite{box1994timeseries}, позволяет с хорошим качеством
прогнозировать временн\'{ы}е ряды с трендом, а также при небольшой
модификации и ряды с сезонной компонентой. Однако настройка параметров
этого алгоритма осуществляется путем минимизации квадратичной функции
потерь, но функция потерь, по которой производится оценка качества
прогноза, может существенно отличаться от квадратичной. Это приводит
к~тому, что оптимальный прогноз для модели ARIMA является несмещенным,
а~регрессионные остатки должны удовлетворять условиям, описанным далее.
Ввиду вышесказанного, модель ARIMA не подходит для решения задачи прогнозирования в случае несимметричной функции потерь, что отмечается в \cite{patton2007properties, berk2011asymmetric}.

Авторами работ \cite{cipra1994asymmetric, koenker2006quantile} были
предложены модификации модели ARIMA, позволяющие учесть несимметричность
функции потерь при настройке параметров алгоритма. Однако обе предложенные
модификации сложны в реализации, не позволяют использовать пакеты для
прогнозирования временн\'{ы}х рядов, в которых есть стандартные реализации
ARIMA, и~требуют для каждой функции потерь создания и обучения индивидуальной модели, что неприемлемо в промышленных задачах. Еще одним методом, предложенным для работы с несимметричными функциями потерь, является квантильная регрессия \cite{koenker2005quantile}. Она позволяет находить оптимальный смещенный прогноз для несимметричных функций потерь кусочно-линейного вида, но не дает возможности работать с функциями потерь других видов, а также применима только для стационарных временн\'{ы}х рядов.

Предлагаемый алгоритм ARIMA\;+\;Hist использует результат
из~\cite{christoffersen1997optimal} о том, что при несимметричной функции
потерь оптимальный прогноз смещен, причем его смещение зависит только от
функции потерь и дисперсии временн\'{о}го ряда. Также используется идея из статьи \cite{granger1969prediction}, где автор для построения прогноза использовал авторегрессионную модель с минимизацией квадратичной функции потерь для получения несмещенного прогноза
и~анализ регрессионных остатков для оценки оптимального смещения прогноза.

Алгоритм ARIMA\;+\;Hist строит прогноз в два этапа. На первом этапе
используется модель ARIMA с сезонной компонентой в случае необходимости,
параметры которой подбираются при помощи анализа временн\'{о}го
ряда по методологии Бокса--Дженкинса~\cite{box1994timeseries}.
На этом этапе получается несмещенный прогноз. На втором этапе
производится анализ регрессионных остатков модели ARIMA
с~целью оценки оптимального смещения прогноза для минимизации
математического ожидания потерь. Оптимальное смещение находится при помощи
алгоритма Hist. Финальный прогноз получается путем прибавления к несмещенному
прогнозу, полученному с помощью ARIMA, найденной при помощи алгоритма Hist добавки.

Алгоритм Hist является обобщением алгоритма квантильной регрессии~\cite{koenker2005quantile}.
Он находит приближенное решение задачи минимизации математического ожидания потерь
и~используется только для прогнозирования стационарных временн\'{ы}х рядов. Такая
задача минимизации рассматривалась в~работах~\cite{christoffersen1996further, diebold1997evaluating},
где математическое ожидание потерь было представлено как свертка функции потерь с функцией плотности
распределения значений временн\'{о}го ряда. На втором этапе алгоритма
ARIMA\;+\;Hist в качестве временн\'{о}го ряда выступают регрессионные остатки,
однако их плотность распределения неизвестна. В~качестве оценки плотности
используется гистограмма значений регрессионных остатков, как предложено
в~\cite{biau2010nonparametric}. В~алгоритме Hist используется ряд упрощений задачи минимизации свертки функции потерь с оценкой плотности распределения регрессионных остатков, которые приводят к задаче приближенного нахождения минимума путем перебора конечного числа значений, из которых выбирается то, которое обеспечивает наименьшее значение свертки.

Основное преимущество ARIMA\;+\;Hist состоит в том, что не накладывается ограничений на класс функций потерь, которые можно использовать в задаче прогнозирования.

Алгоритм тестируется на наборе временн\'{ы}х рядов, обладающих различными
элементами нестационарности. Качество полученных прогнозов сравнивается
с~качеством прогнозов модели ARIMA при использовании различных функций потерь.
Демонстрируется, что чем более несимметричная будет функция потерь, тем более
существенный выигрыш в качестве можно будет получить при помощи двухэтапного
алгоритма ARIMA\;+\;Hist по сравнению с ARIMA.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Задача прогнозирования временных рядов}

Данные представляют собой временной ряд $\mathbf{x} = \{ (x_i)_{i=1}^{T} \cond
x_i \in \RR \}$. Также задается горизонт прогнозирования $h$.
Ставится задача прогнозирования этого временн\'{о}го ряда, т.\,е. нахождения
регрессионной модели
\begin{gather*}
	f: (\mathbf{w}, \mathbf{x}, h) \mapsto \hat{\mathbf{x}}, %\label{eq:RegressionModel}
\end{gather*}
где $\bold{w}$~--- вектор параметров; $\hat{\mathbf{x}}$~--- вектор прогнозов длины $h$. В данной работе прогнозирование производится с горизонтом $h=1$, поэтому вектор прогнозов $\hat{\mathbf{x}}$ является скаляром и обозначается далее как $\hat{x}_{T+1}$.

\paragraph{Прогнозирование стационарных временных рядов}
Временной ряд $\mathbf{x}$ называется \emph{стационарным}, если для любых $v$
многомерное распределение $x_t,\ldots,x_{t+v}$ не зависит от $t$, т.\,е.\
его свойства не зависят от времени. Из определения немедленно следует, что
все значения ряда $x_1, \ldots, x_T$ генерируются из одного распределения
$\rho(u)$, которое не меняется во времени. Пусть задана функция потерь
$\mathscr{L}(\hat{x}, x)$ и требуется получить прогноз $\hat{x}_{T+1}$
следующего значения $x_{T+1}$ временн\'{о}го ряда, минимизируя ожидаемые
потери. Предполагается, что следующее значение временн\'{о}го ряда генерируется из того же распределения, что и все предыдущие. При этом задача прогнозирования запишется как
\begin{gather*}
    \hat{x}_{T+1} = \argmin\limits_{c \in \mathbb{R}} \mathsf{E}\, \mathscr{L}(c, x_{T+1}).
\end{gather*}

Если предположить, что плотность распределения $\rho(u)$,
из которого генерируются значения временн\'{о}го ряда, известна, математическое ожидание потерь запишется как
\begin{gather*}
    L(c) = \mathsf{E}\, \mathscr{L}(c, x_{T+1}) = \int\limits_{-\infty}^{+\infty} \mathscr{L}(c, u)\, \rho(u)\, du.
\end{gather*}

В таком случае задача прогнозирования формулируется как
\begin{gather}
    \hat{x}_{T+1} = \argmin\limits_{c \in \mathbb{R}} \int\limits_{-\infty}^{+\infty} \mathscr{L}(c, u)\, \rho(u)\, du \equiv \argmin\limits_{c \in \mathbb{R}} L(c).\label{eq:StationaryForecastProblem}
\end{gather}

\paragraph{Прогнозирование нестационарных временных рядов}
В случае, когда временной ряд не является стационарным, необходимо оценить
и исключить из временн\'{о}го ряда нестационарные особенности,
прежде чем минимизировать ожидаемые потери в задаче \eqref{eq:StationaryForecastProblem}.
Таким образом, прогноз $\hat{x}_{T+1}$ нестационарного временн\'{о}го ряда будет складываться из двух частей: прогноз нестационарной компоненты $\hat{x}_{T+1}^{\text{ns}}$ и~прогноз стационарной компоненты $\hat{x}_{T+1}^{\text{s}}$:
\begin{gather*}
    \hat{x}_{T+1} = \hat{x}_{T+1}^{\text{ns}} + \hat{x}_{T+1}^{\text{s}}.
%\label{eq:FinalForecast}
\end{gather*}

Алгоритм прогнозирования нестационарной компоненты временного ряда должен быть таким, чтобы регрессионные остатки при прогнозе доступной для обучения истории $\mathbf{x}$
\begin{gather*}
    \mathbf{r} = \{(r_i)_{i=1}^{T} \cond r_i = x_i - \hat{x}_i^{\text{ns}} \}
%\label{eq:RegressionRemainders}
\end{gather*}
были стационарным временн\'{ы}м рядом, значения которого сгенерированы из одного распределения с плотностью $\gamma(u)$.

В качестве алгоритма прогнозирования нестационарной части ряда предлагается
использовать ARIMA. Для оптимизации параметров этот алгоритм использует квадратичную функцию потерь $\mathscr{L}_{\text{sq}}(\hat{x},x) = \left(\hat{x}-x\right)^2$, по которой строится функционал потерь:
\begin{equation}
	\mathcal{Q}(f^{\text{ns}},\mathbf{x}) = \frac{1}{T}\sum_{i=1}^{T}\mathscr{L}_{\text{sq}}(f^{\text{ns}}(\mathbf{w}, \mathbf{x}_{i}, 1),x_{i+1});\quad \label{eq:QualityFunctional}
		\mathbf{x}_{i} = \{x_1 \cdots x_i\}.  %\label{eq:QualityFunctional}
\end{equation}
Тогда решение задачи минимизации \eqref{eq:QualityFunctional} дает вектор параметров искомой регрессионной модели:
\begin{gather*}
	\mathbf{w^*} = \argmin_{\mathbf{w} \in \RR^n}\mathcal{Q}(f^{\text{ns}},\mathbf{x}).
%\label{eq:NonstationaryForecastProblem}
\end{gather*}
При этом прогноз вычисляется следующим образом:
\begin{gather*}
	\hat{x}_{T+1}^{\text{ns}} = f^{\text{ns}}(\mathbf{w^*},\mathbf{x},1).
% \label{eq:NonstationaryForecast}
\end{gather*}

После получения прогноза нестационарной компоненты  временн\'{о}го ряда $\hat{x}_{T+1}^{\text{ns}}$ прогноз стационарной компоненты $\hat{x}_{T+1}^{\text{s}}$ может быть получен при помощи оценки плотности распределения $\gamma(u)$ регрессионных остатков $\mathbf{r}$ и решения для этой плотности задачи минимизации ожидаемых потерь \eqref{eq:StationaryForecastProblem}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Прогнозирование нестационарной компоненты. ARIMA. Методология Бокса--Дженкинса}

В данном разделе описывается модель авторегрессионного интегрированного
скользящего среднего ARIMA и методология Бокса--Дженкинса прогнозирования
временн\'{ы}х рядов. Принято записывать модель в виде $\mathrm{ARIMA}(p,d,q)$,
где $p,d,q \in \mathbb{Z}_{+}$ ~--- структурные параметры, характеризующие
порядок для соответствующих частей модели~--- авторегрессионной,
интегрированной и скользящего среднего. ARIMA с подходящими параметрами для
каждого временн\'{о}го ряда предлагается использовать для получения прогноза
нестационарной компоненты $\hat{x}_{T+1}^{\text{ns}}$. Анализ того, насколько
хорошо выбранная модель аппроксимирует временной ряд, по методологии Бокса--Дженкинса,
включает проверку регрессионных остатков на несмещенность, стационарность
и~неавтокоррелированность. Модель считается подходящей для аппроксимации
временн\'{о}го ряда, если все эти свойства выполняются для ряда регрессионных
остатков, как это описано в \cite{hyndman}. Таким образом, при выборе
подходящей модели ARIMA для прогнозирования нестационарной компоненты
временн\'{о}го ряда получается стационарный ряд регрессионных остатков,
который можно использовать для построения прогноза $\hat{x}_{T+1}^{\text{s}}$
стационарной компоненты временн\'{о}го ряда.

Стационарный временной ряд со средним значением $\mu$ описывается моделью
$\mathrm{ARMA}(p, q)$, если выполняется
\begin{equation*}
x_t = \alpha + \epsilon_t + \sum_{i=1}^{q}{\psi_i \epsilon_{t-i}} + \sum_{i=1}^{p}{\theta_i x_{t-i}};\quad
\alpha = \mu\left(1-\sum_{i=1}^{p}{\theta_i}\right). %\label{eq:ARMA}
\end{equation*}
где $\theta_1, \ldots, \theta_p$, $\psi_1, \ldots, \psi_q$ --- константы;
$\epsilon_t$ --- гауссов белый шум с нулевым средним и постоянной дисперсией.
Вводя оператор сдвига $L$, действующий по правилу $L x_i = x_{i-1}$, можно
записать модель $\mathrm{ARMA}(p, q)$ в следующем виде:
\begin{gather}
\theta(L)x_t = \alpha + \psi(L)\epsilon_t;
\quad \theta(L) = 1 - \sum_{i=1}^{p}{\theta_i L^i};
\quad
\psi(L) = 1 + \sum_{i=1}^{q}{\psi_i L^i}. \label{eq:ARMAFunctional}
\end{gather}

Временной ряд описывается моделью $\mathrm{ARIMA}(p,d,q)$, если ряд его разностей
\begin{gather*}
    \nabla^d x_t = (1 - L)^d x_t %\label{eq:LagOperator}
\end{gather*}
описывается моделью \eqref{eq:ARMAFunctional},
при этом модель $\mathrm{ARIMA}(p,d,q)$ записывается как
\begin{gather*}
\theta(L)\nabla^d x_t = \alpha + \psi(L)\epsilon_t. %\label{eq:ARIMA}
\end{gather*}

Временной ряд, обладающий мультипликативной сезонностью с периодом $S$,
описывается моделью $\mathrm{ARIMA}(p, d, q) \times (P, D, Q)_S$, если
\begin{gather*}
\theta_p(L)\Theta_P(L^S)\nabla^d\nabla_{S}^{D} x_t = \alpha + \psi_q(L)\Psi_Q(L^S)\epsilon_t\,.
%\label{eq:SeasonalARIMA}
\end{gather*}

\paragraph{Методология Бокса--Дженкинса анализа временных рядов}
Методология Бокса--Дженкинса используется для оценки параметров модели ARIMA.
Согласно этой методологии, порядок дифференцирования временн\'{о}го ряда $d$
выбирается так, чтобы ряд разностей порядка $d$ был стационарным. Параметры $p$ и $q$ выбирают при помощи анализа автокорреляционной и частичной автокорреляционной функций.

\begin{Def}\label{def:ACF}
    Автокорреляционная функция $\mathrm{ACF}_{\tau}$ с лагом автокорреляции $\tau$ для временн\'{о}го ряда $\mathbf{x}$ вычисляется по формуле:
\begin{gather*}
\mathrm{ACF}_{\tau} = \cfrac{\sum\nolimits_{i=1}^{T-\tau} (x_i - \bar{x})
(x_{i+\tau} - \bar{x})}{\sum\nolimits_{i=1}^T (x_i - \bar{x})^2}\,;
\quad \bar{x} = \frac{1}{T} \sum_{i=1}^T x_i\,.
\end{gather*}
\end{Def}

\begin{Def}\label{def:PACF}
    Частичная автокорреляционная функция $\mathrm{PACF}_{\tau}$ с лагом автокорреляции $\tau$ для стационарного временн\'{о}го ряда $\mathbf{x}$ вычисляется по формуле:
\begin{gather*}
\mathrm{PACF}_{\tau} = \left\{
	\begin{array}{ll}
		\mathsf{E}\left[x_{t+1} x_t\right], & \hbox{$\tau=1$;} \\
		\mathsf{E}\left[(x_{t+\tau} - x_{t+\tau}^{\tau-1}) (x_t - x_t^{\tau-1})\right], & \hbox{$\tau \geq 2$;}
	\end{array}
	\right.
	\\
	\\
	x_t^{\tau-1} = \beta_1 x_{t+1} + \beta_2 x_{t+2} + \cdots + \beta_{\tau-1} x_{t+\tau-1};
	\\
	\\
	x_{t+\tau}^{\tau-1} = \beta_1 x_{t+\tau-1} + \beta_2 x_{t+\tau-2} + \cdots + \beta_{\tau-1} x_{t+1},
\end{gather*}
где $\beta_1, \ldots, \beta_{\tau-1}$ ~--- коэффициенты линейной регрессии.
\end{Def}
Выбор параметров $p$ и $q$ осуществляется из следующих соображений:
\begin{enumerate}[(1)]
  \item в модели $\mathrm{ARIMA}(p, d, 0)$ автокорреляционная функция экспоненциально затухает или имеет синусоидальный вид, а частичная автокорреляционная функция значимо отличается от нуля при лагах, не больших $p$;
  \item в модели $\mathrm{ARIMA}(0, d, q)$ частичная автокорреляционная функция экспоненциально затухает или имеет синусоидальный вид, а автокорреляционная функция значимо отличается от нуля при лагах, не больших $q$.
\end{enumerate}
Множество структурных параметров сезонной компоненты ARIMA
назначается с помощью анализа автокорреляционной и частичной
автокорреляционной функций. При наличии сезонной компоненты
у~временн\'{о}го ряда на графиках этих функций будут наблюдаться характерные максимумы в лагах, соответствующих периоду $S$ сезонной ком\-по\-ненты.

Необходимые коэффициенты многочленов $\theta(L)$ и~$\psi(L)$ оптимизируются при использовании квадратичной функции потерь $\mathscr{L}_{\text{sq}}(\hat{x},x)$ и функционала потерь \eqref{eq:QualityFunctional}, основанного на ней.

После оптимизации параметров модели проводится анализ остатков. Регрессионные остатки проверяются на
\begin{enumerate}[(1)]
  \item несмещенность $\mathsf{E}\,r_t = 0$;
  \item стационарность $\forall t \hookrightarrow r_t \sim \gamma(u)$;
  \item неавтокоррелированность $\mathsf{E}\left[r_t r_{t+k}\right] = 0, k \neq 0,$
\end{enumerate}
Если регрессионные остатки обученной модели обладают всеми этими свойствами, то модель признается подходящей для аппроксимации анализируемого временн\'{о}го ряда.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Прогнозирование стационарной компоненты. Hist. Влияние функции потерь}

После обучения модели ARIMA с выбранными параметрами даваемый ею
прогноз~$\hat{x}_{T+1}^{\text{ns}}$ учитывает характерные особенности
временн\'{о}го ряда $\mathbf{x}$, но не функции потерь $\mathscr{L}(\hat{x}, x)$. Пусть ряд регрессионных остатков $\mathbf{r}$ описывается неизвестной плотностью распределения $\gamma(u)$. Предлагается построить добавочный прогноз $\hat{x}_{T+1}^{\text{s}}$ для стационарного ряда из регрессионных остатков, который минимизирует математическое ожидание потерь \eqref{eq:StationaryForecastProblem}. Такая добавка к несмещенному прогнозу $\hat{x}_{T+1}^{\text{ns}}$ позволит учесть особенности несимметричной функции потерь.

В случае квадратичной $\mathscr{L}_{\text{sq}}(\hat{x},x)=(\hat{x}-x)^2$ или
абсолютной $\mathscr{L}_{\text{abs}}(\hat{x},x) = \left| \hat{x} - x \right|$
функций потерь добавочный прогноз $x_{T+1}^{\text{s}}$ можно найти аналитически,
не зная при этом конкретного вида распределения $\gamma(u)$:
для квадратичной функции потерь $x_{T+1}^{\text{s}} = \mathsf{E}\,r_t$;
для абсолютной $x_{T+1}^{\text{s}} = \text{med}\,\gamma(u)$, что можно получить, продифференцировав $L(c)$. В случае же более общего вида функции потерь задача не поддается аналитическому решению без знания конкретного распределения $\gamma(u)$, а в практических задачах оно, как правило, неизвестно.

Алгоритм Hist предлагает следующий путь для решения этой проблемы. Он состоит из двух приближений функции $L(c)$.

\paragraph{Оценка плотности {\boldmath{$\gamma(u)$}} гистограммой}
Плотность вероятности $\gamma(u)$ приближается гистограммой значений ряда, т.\,е.\
кусоч\-но-по\-сто\-ян\-ной функцией $\hat{\gamma}(u)$. Обозначим
$u_{\text{min}} = \min_{t}r_t$; $u_{\text{max}} = \max_{t}r_t$. Они существуют, так как рассматриваются только конечные множества $\mathbf{r}$. Произведем разбиение области $\left[u_{\text{min}};u_{\text{max}}\right]$ на $n$ отрезков $\left[u_i;u_{i+1}\right]$ равной длины, где
\begin{gather*}
u_i = u_{\text{min}} + i  a ;\enskip a = \frac{u_{\text{max}}-u_{\text{min}}}{n}.
%\label{eq:HistogramSegments}
\end{gather*}
На этих отрезках положим значения функции $\hat{\gamma}(u)$ постоянными и равными $y_i$ на отрезке $\left[u_{i-1};u_i\right]$, где $y_i$ пропорционально количеству точек ряда $\mathbf{r}$, значения которых $r_t \in \left[u_{i-1};u_i\right]$.

Точное значение $y_i$ определяется из условия нормировки функции $\hat{\gamma}(u)$:
\begin{gather*}
\int\limits_{u_{\text{min}}}^{u_{\text{max}}}{\hat{\gamma}(u)}\,du = \sum_{i=1}^{n}y_i(u_{i-1}-u_i)=a\sum_{i=1}^{n}y_i=1.
%\label{eq:HistogramNormalize}
\end{gather*}
Тогда $\hat{\gamma}(u)$ есть оценка плотности распределения.
При использовании этого приближения функция математического ожидания потерь $L(c)$ оценивается как
\begin{gather}
L_{\text{hist}}(c) = \int\limits_{u_{\text{min}}}^{u_{\text{max}}}\mathscr{L}(c,u)\hat{\gamma}(u)\,du = \sum_{i=1}^{n}y_i\int\limits_{u_{i-1}}^{u_i}\mathscr{L}(c,u)\,du. \label{eq:Lhist}
\end{gather}

\paragraph{Приближение интеграла}
Интеграл от функции потерь, присутствующий в \eqref{eq:Lhist}, приближается по методу прямоугольников со средней точкой:
\begin{gather*}
\int\limits_{u_{i-1}}^{u_i}\mathscr{L}(c,u)\,du \approx a \, \mathscr{L}\left(c,\frac{u_{i-1}+u_i}{2}\right).
%\label{eq:IntegrateRectangular}
\end{gather*}
После этого приближенная функция математического ожидания потерь примет окончательный вид:
\begin{gather}
L_{\text{conv}}(c) = a\, \sum_{i=1}^{n}y_i \, \mathscr{L}\left(c,\frac{u_{i-1}+u_i}{2}\right). \label{eq:Lconv}
\end{gather}

Точность приближений растет с ростом числа отрезков $n$; в первом случае \eqref{eq:Lhist} это связано с уточнением приближения гистограммой исходной плотности распределения, во втором \eqref{eq:Lconv} --- с уточнением оценки интеграла.

Работа алгоритма заключается в поиске $c^*$, на котором достигается
минимум $L_{\text{conv}}(c)$, и~взятии значения $c^*$ в качестве прогноза. В силу возможной сложности функции потерь $\mathscr{L}(\hat{x},x)$ минимум ищется среди значений функции в ограниченном наборе точек
\begin{gather*}
G = \left\lbrace \frac{u_0+u_1}{2}, \cdots , \frac{u_{n-1}+u_n}{2} \right\rbrace,
% \label{MinimizationSet}
\end{gather*}
состоящем из середин отрезков разбиений:
\begin{gather}
\hat{x}_{T+1}^{\text{s}} = \argmin_{c \, \in \, G}{L_{\text{conv}}(c)}. \label{eq:HistFinalForecast}
\end{gather}

\paragraph{Алгоритм Hist}

\begin{algorithmic}[1]
    \medskip\hrule\medskip
        \REQUIRE стационарный ряд регрессионных остатков $\mathbf{r}$, функция потерь $\mathscr{L}(\hat{x}, x)$, число столбцов гистограммы $n$;
        \ENSURE прогноз $\hat{x}_{T+1}^s$, минимизирующий математическое ожидание потерь;
    \medskip\hrule\medskip
        \STATE вычислить ширину столбцов гистограммы $a = ({\max \mathbf{r} -
\min \mathbf{r}})/{n} $ и координаты концов отрезков постоянства $u_0, u_1, \ldots, u_n$ для функции $\hat{\gamma}(u)$;
        \STATE построить гистограмму, найти функцию $\hat{\gamma}(u)$, отнормировав гистограмму, получить значения функции на отрезках постоянства $y_1, \ldots, y_n$;
        \STATE найти значения свертки $\sum\limits_{i=1}^n y_i~ \mathscr{L}
\left(c, ({u_i + u_{i-1}})/{2} \right)$ \newline для всех $c \in \{
({u_0 + u_1})/{2}, \ldots, ({u_{n-1} + u_n})/{2} \}$;
        \STATE выбрать $c^*$, дающее минимальное значение свертки;
        \STATE $\hat{x}_{T+1}^s = c^*$.
    \medskip\hrule\medskip
\end{algorithmic}

Основной параметр алгоритма, который можно варьировать, ~--- число столбцов гистограммы $n$. При малых $n$ оценка плотности распределения $\hat{\gamma}(u)$ получается огрубленной, при больших $n$ --- более детальной. В следующем разделе будут приведены результаты исследования свойств алгоритма и на регрессионных остатках различных временн\'{ы}х рядов.

Алгоритм Hist минимизирует математическое ожидание потерь прогнозирования
при любом распределении регрессионных остатков $\mathbf{r}$ и~произвольной
функции потерь $\mathscr{L}(\hat{x}, x)$. Если регрессионные остатки имеют
нулевое среднее, то смещение $\hat{x}_{T+1}^s$ будет обуслов\-ле\-но лишь
несимметричностью функции потерь. Однако использование алгоритма ARIMA\;+\;Hist
при двухэтапном прогнозе может уменьшить средние потери и в том случае, если
подобранная для прогнозирования нестационарной компоненты модель дает смещенные
прогнозы. Это может происходить при смене характера тренда. Например, увеличивается
темп роста величины или величина сначала убывала, а~потом начинает возрастать.
Если изменение однократное и смещение прогнозов ARIMA, обученной на первом
характере тренда, постоянное, то при поиске решения задачи минимизации
ожидаемых потерь \eqref{eq:HistFinalForecast} это смещение будет
скомпенсировано, что приведет к повышению качества даже в случае
симметричной функции потерь. Примером такого ряда может служить
ряд~\cite{chocolate}, во второй половине которого тренд более сильный.
В~разд.~7 будет показано, что для этого временн\'{о}го ряда использование
алгоритма Hist действительно дает ощутимый выигрыш в качестве по сравнению
с~ARIMA даже для квадратичной функции потерь.

Отметим также, что прогноз Hist является константой в том смысле, что не зависит от горизонта прогнозирования, и для любого будущего момента времени $t$ ответ будет одним и тем же, т.\,е.\ Hist
строит регрессионную модель нулевого порядка.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Двухэтапное прогнозирование. Алгоритм ARIMA\;+\;Hist}

Как было показано в \eqref{eq:QualityFunctional}, ARIMA
настраивается таким образом, чтобы минимизировать регрессионные остатки для квадратичной функции потерь $\mathscr{L}_{\text{sq}}(\hat{x},x)$. Если же функция потерь $\mathscr{L}(\hat{x},x)$, по которой производится оценка качества прогноза, не является квадратичной, то и регрессионные остатки в общем случае минимальными не будут.

Далее запускается алгоритм Hist с действительной функцией ошибок на
ряде~$\epsilon_t$, т.\,е.\ минимизируем остатки в смысле новой функцией
потерь $\mathscr{L}(\hat{x},x)$. Отметим, что первый этап действительно
необходим и нельзя давать на вход Hist просто продифференцированный ряд, так как этот алгоритм не учитывает некоторые особенности, которые не уходят при дифференцировании, например сезонность.

Итоговой прогноз суммируется из двух $\hat{x}_{T+1} = \hat{x}_{T+1}^{\text{ns}}+\hat{x}_{T+1}^{\text{s}}$.
По сути же Hist добавляет одинаковый на всем горизонте сдвиг вверх или вниз от исходного прогноза
ARIMA в~зависимости от конкретного вида функции потерь.

%\pagebreak
\paragraph{Алгоритм ARIMA\;+\;Hist}

\begin{algorithmic}[1]
    \medskip\hrule\medskip
        \REQUIRE временной ряд $\mathbf{x}$, функция потерь $\mathscr{L}(\hat{x}, x)$;
        \ENSURE прогноз $\hat{x}_{T+1}$;
    \medskip\hrule\medskip
        \STATE подобрать подходящую для временн\'{о}го ряда модель ARIMA по методологии Бокса--Дженкинса;
        \STATE вычислить прогноз нестационарной компоненты $\hat{x}_{T+1}^{\text{ns}}$ с помощью выбранной модели ARIMA;
        \STATE вычислить регрессионные остатки $\mathbf{r}$ для выбранной модели ARIMA;
        \STATE задать число столбцов $n$ в гистограмме для алгоритма Hist;
        \STATE вычислить прогноз стационарной компоненты $\hat{x}_{T+1}^s$ с помощью алгоритма Hist;
        \STATE $\hat{x}_{T+1} = \hat{x}_{T+1}^{\text{ns}}+\hat{x}_{T+1}^{\text{s}}$;
    \medskip\hrule\medskip
\end{algorithmic}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Исследование свойств алгоритма Hist}

В данном разделе описываются и исследуются свойства алгоритма Hist,
основанного на свертке гистограммы с функцией потерь.

\paragraph{Используемые временные ряды}



Для исследования свойств алгоритма Hist и последующего вычислительного
эксперимента были использованы временн\'{ы}е ряды \cite{river,lake,chocolate,sugar,electricity},
изображенные на рис. \ref{fig:TimeSeries}. Рассматриваемые ряды отличаются друг от друга длиной
истории, наличием или отсутствием сезонности и тренда, диапазоном значений. После первого этапа
алгоритма ARIMA\;+\;Hist получаются стационарные ряды регрессионных остатков. Именно на этих
рядах и проводится исследование свойств Hist. Первый этап алгоритма и сравнение качества прогнозов описаны в следующем разделе.

\paragraph{Функции потерь}


\begin{figure}
	\subfloat[Fraser River at hope]
        {
		\includegraphics[width=0.45\linewidth%, trim = 0 150 0 100
]{fraser-river-at-hope.eps}
		\label{fig:RiverSeries}
	    }
	\hfill
	\subfloat[Monthly Lake Erie Levels]
        {
		\includegraphics[width=0.45\linewidth%, trim = 0 150 0 100
]{lake-erie-levels.eps}
		\label{fig:LakeSeries}
	    }
    \\
	\vskip -1cm
	\subfloat[Monthly production of chocolate confectionery in Australia]
        {
		\centering
		\includegraphics[width=0.45\linewidth%, trim = 0 150 0 150
]{chocolate.eps}
		\label{fig:ChocolateSeries}
        }	
    \hfill
	\subfloat[Sugar price]
		{
        \centering
		\includegraphics[width=0.45\linewidth%, trim = 0 150 0 150
]{sugar.eps}
		\label{fig:SugarSeries}
        }
    \\
%	\vskip -1cm
	\subfloat[Electricity consumption July 2005]
        {
		\centering
			\includegraphics[width=0.45\linewidth%, trim = 0 150 0 150
]{ElectricityTimeSeries.eps}
		\label{fig:ElectricitySeries}
	    }
	\caption{Временн\'{ы}е ряды}
	\label{fig:TimeSeries}
\end{figure}

Эксперименты проводились для трех различных функций потерь:
\begin{align}
				\mathscr{L}_{\text{sq}}(\hat{x}, x) &= (\hat{x} - x)^2\,; \label{eq:SseLoss} \\
				\mathscr{L}_{\text{abs}}(\hat{x}, x) &= |\hat{x} - x|\,;\label{eq:AbsLoss} \\
				\mathscr{L}_{\text{asym}}(\hat{x}, x) &=
\begin{cases}
\displaystyle \frac{1}{2}|\hat{x} - x|, & x\leq \hat{x}\,;\\
			2|\hat{x} - x|, & x > \hat{x}\,.
										   				\end{cases}\label{eq:AsymLoss}
			\end{align}


Графики квадратичной, абсолютной и ассимметричной функций потерь изображены
на рис. \ref{fig:LossFunctions}. Все три функции выпуклые, достигают минимума
при совпадении прогноза и~действительного значения временн\'{о}го ряда. Первые две функции симметричные, последняя ~--- несимметричная кусочно-линейная функция.

\begin{figure}[H]
\centering
	\includegraphics[width=0.5\linewidth]{LossFunctions.eps}
	\caption{Функции потерь}
	\label{fig:LossFunctions}
\end{figure}

\paragraph{Свойства прогноза алгоритма Hist}



Чтобы определить, как зависит поведение алгоритма Hist от функции потерь
и~количества столбцов в гистограмме, для каждого ряда регрессионных остатков
были построены графики зависимости прогноза алгоритма Hist от количества
столбцов в гистограмме для каждой функции потерь~\eqref{eq:SseLoss}--\eqref{eq:AsymLoss}.
Графики изображены на рис.~\ref{fig:HistRiverStabilization}--\ref{fig:HistElectricityStabilization}.
На каждом графике по оси абсцисс отложено количество столбцов гистограммы, по оси ординат ---
прогноз, полученный алгоритмом Hist при использовании заданной функции потерь и гистограммы с заданным числом столбцов.



\begin{figure}
	\subfloat[Квадратичная функция потерь]
        {
		\includegraphics[width=0.3\linewidth, trim = 0 0 0 0]{HistSseRiverStabilization.eps}
		\label{fig:RiverHistSSE}
	    }
	\hfill
	\subfloat[Абсолютная функция потерь]
        {
		\includegraphics[width=0.3\linewidth, trim = 0 0 0 0]{HistAbsRiverStabilization.eps}
		\label{fig:RiverHistAbs}
	    }
	\hfill
	\subfloat[Асимметричная функция потерь]
        {
		\includegraphics[width=0.3\linewidth, trim = 0 0 0 0]{HistAsymRiverStabilization.eps}
		\label{fig:RiverHistAsym}
	    }
	\caption{Прогнозы алгоритма Hist для регрессионных остатков ряда Fraser River at hope}
	\label{fig:HistRiverStabilization}
	\vfill
	\subfloat[Квадратичная функция потерь]
        {
		\includegraphics[width=0.3\linewidth, trim = 0 0 0 0]{HistSseLakeStabilization.eps}
		\label{fig:LakeHistSSE}
	    }
	\hfill
	\subfloat[Абсолютная функция потерь]
        {
		\includegraphics[width=0.3\linewidth, trim = 0 0 0 0]{HistAbsLakeStabilization.eps}
		\label{fig:LakeHistAbs}
	    }
	\hfill
	\subfloat[Асимметричная функция потерь]
        {
		\includegraphics[width=0.3\linewidth, trim = 0 0 0 0]{HistAsymLakeStabilization.eps}
		\label{fig:LakeHistAsym}
	    }
	\caption{Прогнозы алгоритма Hist для регрессионных остатков ряда Monthly Lake Erie Levels}
	\label{fig:HistLakeStabilization}
	\vfill
	\subfloat[Квадратичная функция потерь]
        {
		\includegraphics[width=0.3\linewidth, trim = 0 0 0 0]{HistSseChocolateStabilization.eps}
		\label{fig:ChocolateHistSSE}
	    }
	\hfill
	\subfloat[Абсолютная функция потерь]
        {
		\includegraphics[width=0.3\linewidth, trim = 0 0 0 0]{HistAbsChocolateStabilization.eps}
		\label{fig:ChocolateHistAbs}
	    }
	\hfill
	\subfloat[Асимметричная функция потерь]
        {
		\includegraphics[width=0.3\linewidth, trim = 0 0 0 0]{HistAsymChocolateStabilization.eps}
		\label{fig:ChocolateHistAsym}
	    }
	\caption{Прогнозы алгоритма Hist для регрессионных остатков ряда Monthly production of chocolate confectionery in Australia}
	\label{fig:HistChocolateStabilization}
	\vfill
	\subfloat[Квадратичная функция потерь]
        {
		\includegraphics[width=0.3\linewidth, trim = 0 0 0 0]{HistSseSugarStabilization.eps}
		\label{fig:SugarHistSSE}
	    }
	\hfill
	\subfloat[Абсолютная функция потерь]
        {
		\includegraphics[width=0.3\linewidth, trim = 0 0 0 0]{HistAbsSugarStabilization.eps}
		\label{fig:SugarHistAbs}
	    }
	\hfill
	\subfloat[Асимметричная функция потерь]
        {
		\includegraphics[width=0.3\linewidth, trim = 0 0 0 0]{HistAsymSugarStabilization.eps}
		\label{fig:SugarHistAsym}
	    }
	\caption{Прогнозы алгоритма Hist для регрессионных остатков ряда Sugar price}
	\label{fig:HistSugarStabilization}
\end{figure}
\begin{figure}[!t]
	\subfloat[Квадратичная функция потерь]
        {
		\includegraphics[width=0.3\linewidth%, trim = 40 150 0 300
]{HistSseElectricityStabilization.eps}
		\label{fig:SugarHistSSE}
	    }
	\hfill
	\subfloat[Абсолютная функция потерь]
        {
		\includegraphics[width=0.3\linewidth%, trim = 40 150 0 300
]{HistAbsElectricityStabilization.eps}
		\label{fig:SugarHistAbs}
	    }
	\hfill
	\subfloat[Асимметричная функция потерь]
        {
		\includegraphics[width=0.3\linewidth%, trim = 40 150 0 300
]{HistAsymElectricityStabilization.eps}
		\label{fig:SugarHistAsym}
	    }
	\caption{Прогнозы алгоритма Hist для регрессионных остатков ряда Electricity consumption}
	\label{fig:HistElectricityStabilization}
\end{figure}

На рис. \ref{fig:HistRiverStabilization}--\ref{fig:HistElectricityStabilization}
видно, что для всех временн\'{ы}х рядов и любой функции потерь с увеличением
числа столбцов гистограммы полученные прогнозы стабилизируются вокруг
предельного значения. Для симметричных функций потерь \eqref{eq:SseLoss}
и~\eqref{eq:AbsLoss} предельное значение для прогнозов близко к нулю, что
означает, что для симметричных функций потерь алгоритм Hist не дает
существенной поправки к прогнозу нестационарной компоненты,
полученному с помощью модели ARIMA. В~то же время для несимметричной функции потерь \eqref{eq:AsymLoss} предельное значение прогнозов существенно больше нуля. Это значит, что суммарный прогноз будет значительно превышать прогноз нестационарной компоненты, поскольку рассматриваемая функция потерь \eqref{eq:AsymLoss} штрафует недопрогноз гораздо сильнее, чем перепрогноз.

Стабилизация прогнозов алгоритма Hist с увеличением количества столбцов
в~гистограмме связана с увеличением точности оценки плотности распределения
регрессионных остатков $\gamma(u)$, о которой говорилось в разд.~4.
Однако для конечных временн\'{ы}х рядов добиться сходимости прогнозов
к~предельному значению с~любой наперед заданной точностью невозможно из-за конечного количества доступных данных для оценки плотности распределения $\gamma(u)$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Вычислительный эксперимент}

Целью проведенного вычислительного эксперимента является сравнение средних
потерь прогнозирования различных временн\'{ы}х рядов для различных функций
потерь при использовании модели ARIMA и предложенного двухэтапного алгоритма
ARIMA\;+\;Hist. Рассмотрены пять различных временн\'{ы}х рядов \cite{river,lake,chocolate,sugar,electricity}, изображенных на рис. \ref{fig:TimeSeries}, и три функции потерь \eqref{eq:SseLoss}--\eqref{eq:AsymLoss}, одна из которых несимметричная. Получено экспериментальное подтверждение того, что при несимметричных потерях использование двухэтапного прогнозирования позволяет уменьшить средние потери.

\begin{table}[b]\small
\begin{center}
	\caption{Выбранные модели ARIMA для прогноза нестационарной компоненты
	\label{table:ArimaModels}}
\vspace*{2ex}

\tabcolsep=15pt
		\begin{tabular}{|l|l|}
		\hline
\multicolumn{1}{|c|}{Временной ряд} & \multicolumn{1}{c|}{Модель ARIMA} \\
		\hline
		Fraser River at hope & $\mathrm{ARIMA}(1, 0, 0) \times (1, 0, 1)_{12}$ \\
%		\hline
		Monthly Lake Erie Levels & $\mathrm{ARIMA}(2, 0, 0) \times (1, 0, 1)_{12}$ \\
%		\hline
		Chocolate production in Australia & $\mathrm{ARIMA}(1, 1, 1) \times (1, 0, 1)_{12}$ \\
%		\hline
		Sugar price & $\mathrm{ARIMA}(1, 0, 0)$ \\
%		\hline
		Electricity consumption & $\mathrm{ARIMA}(2, 1, 2) \times (1, 0, 1)_{24} \times (1, 0, 1)_{168}$ \\
		\hline
		\end{tabular}
\end{center}
\end{table}

Для каждого временного ряда, изображенного на рис. \ref{fig:TimeSeries},
подбиралась модель ARIMA по методологии Бокса--Дженкинса~\cite{box1994timeseries}.
Выбранные модели для каждого временн\'{о}го ряда показаны в табл. \ref{table:ArimaModels}.

Для прогнозирования стационарной компоненты используются регрессионные остатки алгоритма ARIMA.

Для сравнения качества прогнозов модели ARIMA и связки алгоритмов
ARIMA\;+\;Hist 20\%~последних точек каждого временн\'{о}го ряда использовались
как контрольные. Для каждой контрольной точки по доступной истории временн\'{о}го
ряда (все точки от первой до предшествующей рассматриваемой контрольной)
обучалась выбранная для временн\'{о}го ряда модель ARIMA, затем
для обученной модели вычислялся ряд регрессионных остатков. По ряду
регрессионных остатков обучался алгоритм Hist с заданной функцией потерь
и~заданным количеством столбцов в гистограмме. Прогноз для контрольной точки
складывался из прогноза ARIMA и Hist. Эксперимент был проведен для функций
потерь~\eqref{eq:SseLoss}--\eqref{eq:AsymLoss} и вариантов алгоритма Hist с~20,
50, 300 и~500~столбцами в гистограмме. Средние потери для каждой функции потерь приведены для всех вариантов алгоритма в~ табл.~\ref{table:Losses}.

\begin{table}\small
\begin{center}
  \caption{Средние потери прогнозирования
   \label{table:Losses}}
\vspace*{2ex}

  \begin{tabular}{|c|c|c|c|c|}
     \hline
     %& & $\mathscr{L}_{\text{sq}}$ & $\mathscr{L}_{\text{abs}}$ & $\mathscr{L}_{\text{asym}}$ \\
     Ряд & Алгоритм & \textbf{Квадратичная} & \textbf{Абсолютная} & \textbf{Асимметричная}\\
     \hline
 & No\,Hist & 52400 & 498 & 616 \\
     & $\mathrm{Hist}(20)$ & 53500 & 495 & 523 \\
     \textbf{River}     & $\mathrm{Hist}(50)$ & \textbf{52200} & 496 & 516 \\
     & $\mathrm{Hist}(300)$ & 52500 & 493 & 516 \\
     & $\mathrm{Hist}(500)$ & 52400 & \textbf{492} & \textbf{515} \\
     \hline
 & No\,Hist & 0,172 & 0,313 & 0,410 \\
     & $\mathrm{Hist}(20)$ & 0,182 & 0,316 & 0,315 \\
     \textbf{Lake}     & $\mathrm{Hist}(50)$ & 0,171 & \textbf{0,313} & 0,312 \\
     & $\mathrm{Hist}(300)$ & 0,171 & 0,314 & 0,311 \\
     & $\mathrm{Hist}(500)$ & \textbf{0,171} & 0,314 & \textbf{0,311} \\
     \hline
 & No\,Hist & 71500000 & 8350 & 4180 \\
     & $\mathrm{Hist}(20)$ & 66000 & 612 & 579 \\
     \textbf{Chocolate}     & $\mathrm{Hist}(50)$ & 65800 & 609 & 575 \\
     & $\mathrm{Hist}(300)$ & 65300 & 610 & 575 \\
     & $\mathrm{Hist}(500)$ & \textbf{65100} & \textbf{609} & \textbf{575} \\
     \hline
& No\,Hist & 0,127 & 0,265 & 0,340 \\
     & $\mathrm{Hist}(20)$ & 0,128 & 0,267 & \textbf{0,260} \\
     \textbf{Sugar}      & $\mathrm{Hist}(50)$ & 0,127 & 0,266 & 0,267 \\
     & $\mathrm{Hist}(300)$ & 0,127 & 0,265 & 0,266 \\
     & $\mathrm{Hist}(500)$ & \textbf{0,127} & \textbf{0,265} & 0,266 \\
     \hline
 & No\,Hist & 500 & 16,9 & 19,9 \\
     & $\mathrm{Hist}(20)$ & 717 & 19,1 & \textbf{12,7} \\
     \textbf{Electricity}     & $\mathrm{Hist}(50)$ & 589 & \textbf{16,5} & 13,4 \\
     & $\mathrm{Hist}(300)$ & \textbf{498} & 17,1 & 13,0 \\
     & $\mathrm{Hist}(500)$ & 502 & 16,9 & 13,0 \\
     \hline
   \end{tabular}
\end{center}
\vspace*{9pt}
\end{table}

Как видно из табл. \ref{table:Losses}, при использовании асимметричной функции
потерь двухэтапный алгоритм прогнозирования ARIMA\;+\;Hist позволяет получать
среднюю ошибку прогноза существенно ниже, чем прогнозирование с помощью модели
ARIMA. В большинстве случаев для симметричных функций потерь использование
двухэтапного алгоритма прогнозирования не приводит к значительным изменениям
по сравнению с прогнозом модели ARIMA. Исключение составляют только средние
потери прогнозирования для временн\'{о}го ряда Monthly production of chocolate
confectionery in Australia. Для этого временн\'{о}го ряда использование
двухэтапного алгоритма прогнозирования ARIMA\;+\;Hist привело
к~существенному уменьшению потерь для всех функций потерь. Это связано
с~тем, что, как видно на рис.~\ref{fig:TimeSeries},\,\textit{в},
этот временной ряд во второй половине истории имеет более высокий темп
роста, чем в первой половине. Обученная преимущественно по первой половине
истории модель ARIMA дает прогнозы в контрольных точках, сильно смещенные
в~одну сторону относительно реальных значений. При использовании двухэтапного
алгоритма прогнозирования ARIMA\;+\;Hist на втором шаге с помощью алгоритма
Hist удается оценить это смещение и сделать более точный прогноз.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bigskip

\section{Заключение}

Предложен двухэтапный алгоритм прогнозирования нестационарных временн\'{ы}х
рядов ARIMA\;+\;Hist, минимизирующий ожидаемые потери. Он не накладывает на
вид функции потерь ограничений~--- она может быть симметричной или
несимметричной, диффе\-рен\-ци\-ру\-емой или нет. На первом этапе строится прогноз
нестационарной компоненты временн\'{о}го ряда путем выбора подходящей модели
ARIMA. На втором этапе оценивается плотность распределения регрессионных
остатков выбранной модели ARIMA и~строится прогноз стационарной компоненты
путем минимизации математического ожидания потерь, которые заданы несимметричной
функцией потерь. Финальный прогноз вычисляется как сумма прогнозов нестационарной
и~стационарной компоненты временн\'{о}го \mbox{ряда}. С~по\-мощью вычислительного
эксперимента показано, что двухэтапное прогнозирование в~случае несимметричной
функции потерь позволяет уменьшить средние потери по сравнению с одноэтапным
прогнозированием ARIMA. Также на практике средние потери можно уменьшить с~по\-мощью двухэтапного прогнозирования в~случае симметричной функции потерь и смещенных прогнозов нестационарной компоненты временн\'{о}го ряда.
{\looseness=1

}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bigskip

\renewcommand{\bibname}{Литература}
{\baselineskip=16pt
\begin{thebibliography}{99}

\medskip

\def\selectlanguageifdefined#1{
\expandafter\ifx\csname date#1\endcsname\relax
\else\selectlanguage{#1}\fi}
\providecommand*{\href}[2]{{\small #2}}
\providecommand*{\url}[1]{{\small #1}}
\providecommand*{\BibUrl}[1]{\url{#1}}
\providecommand{\BibAnnote}[1]{}
\providecommand*{\BibEmph}[1]{#1}
\ProvideTextCommandDefault{\cyrdash}{\hbox to.8em{--\hss--}}
\providecommand*{\BibDash}{\ifdim\lastskip>0pt\unskip\nobreak\hskip.2em\fi
\cyrdash\hskip.2em\ignorespaces}

\bibitem{rus_patton2007properties}
\selectlanguageifdefined{english} %1
\BibAuthor{Patton~A.\,J., Timmermann~A}. Properties of optimal forecasts
  under asymmetric loss and nonlinearity~// {J.~Econometrics},
2007.  Vol.~140. No.~2. P.~884--918.

\bibitem{rus_box1994timeseries}     %2
\selectlanguageifdefined{english}
\BibAuthor{Box~G.\,E.\,P., Jenkins~G.\,M., Reinsel~G.\,C.}
Time series analysis:
  Forecasting and control.~--- 3rd ed.~---
 Englewood Cliffs, NJ:~Prentice~Hall, 1994.

\bibitem{rus_berk2011asymmetric}
\selectlanguageifdefined{english}
\BibAuthor{Berk~R}. Asymmetric loss functions for forecasting in criminal
  justice settings~// {J.~Quantitative Criminology},
 2011.  Vol.~27. No.\,1.  P.~107--123.

\bibitem{rus_cipra1994asymmetric}
\selectlanguageifdefined{english}
\BibAuthor{Cipra,~T}. Asymmetric recursive methods for time
  series~// {Appl. Math}., 1994. Vol.~39. No.\,3.  P.~203--214.

\bibitem{rus_koenker2006quantile}     %5
\selectlanguageifdefined{english}
\BibAuthor{Koenker~R., Xiao~Z}. Quantile autoregression~//
{J.~Am. Stat. Association}, 2006.  Vol.~101. No.\,475.  P.~980--990.

\bibitem{rus_koenker2005quantile}
\selectlanguageifdefined{english}
\BibAuthor{Koenker~R}. Quantile regression.~---
 Cambridge University Press, 2005.

\bibitem{rus_christoffersen1997optimal}  %7
\selectlanguageifdefined{english}
\BibAuthor{Christoffersen~P.\,F, Diebold~F.\,X}. Optimal prediction under
  asymmetric loss~// Econometric Theory,
 1997.  Vol.~13. No.\,06.  P.~808--817.

\bibitem{rus_granger1969prediction}        %8
\selectlanguageifdefined{english}
\BibAuthor{Granger~C.\,W.\,J}. Prediction with a generalized cost of error
  function~// {OR}, 1969.  Vol.~20. No.\,2. P.~199--207.

\bibitem{rus_christoffersen1996further} %9
\selectlanguageifdefined{english}
\BibAuthor{Christoffersen~P.\,F, Diebold~F.\,X}. Further results on
  forecasting and model selection under asymmetric loss~//
J.~Appl. Econometrics, 1996.  Vol.~11. No.\,5.  P.~561--571.

\bibitem{rus_diebold1997evaluating} %10
\selectlanguageifdefined{english}
\BibAuthor{Diebold F.\,X., Gunther~T., Tay~A.}
Evaluating density forecasts~// Int. Econ. Rev., 1998.
Vol.~39. P.~863--883.


\bibitem{rus_biau2010nonparametric}       %11
\selectlanguageifdefined{english}
\BibAuthor{Biau~G.,
Bleakley~k., Gy{\"o}rfi~L., Ottucs{\'a}k~G}.
Nonparametric sequential prediction of time series~//
{J.~Nonparametric Stat}., 2010.
 Vol.~22. No.\,3. P.~297--317.


\bibitem{rus_hyndman}                        %12
\selectlanguageifdefined{english}
\BibAuthor{Hyndman~R.\,J., Athanasopoulos~G.} Forecasting:
Principles and practice.~---
OTexts, 2006.
{\sf  https://www.otexts.org/book/fpp}.

\bibitem{rus_chocolate} %13
\selectlanguageifdefined{english}
Monthly production of chocolate confectionery in Australia.
\BibUrl{https://datamarket.com/data/set/22rl/monthly-production-of-chocolate-confectionery-in-australia-tonnes-july-1957-aug-1995#!ds=22rl&display=line}.

\bibitem{rus_river}                             %14
\selectlanguageifdefined{english}
Fraser River at hope.
\BibUrl{https://datamarket.com/data/set/22nm/fraser-river-at-hope-1913-1990#!ds=22nm&display=line}.

\bibitem{rus_lake} %15
\selectlanguageifdefined{english}
Monthly Lake Erie Levels.
\BibUrl{https://datamarket.com/data/set/22pw/monthly-lake-erie-levels-1921-1970#!ds=22pw&display=line}.

\bibitem{rus_sugar}
\selectlanguageifdefined{english}
Sugar price.
\BibUrl{https://mlalgorithms.svn.sourceforge.net/svnroot/mlalgorithms/TSForecasting/TimeSeries/Sources/tsSugarPrice.csv}.

\bibitem{rus_electricity}
\selectlanguageifdefined{english}
Electricity consumption.
\BibUrl{https://mlalgorithms.svn.sourceforge.net/svnroot/mlalgorithms/TSForecasting/TimeSeries/Sources/tsEnergyConsumption.csv}.
  	
\end{thebibliography}

}

\bigskip

\renewcommand{\bibname}{References}
{\baselineskip=16pt
\begin{thebibliography}{99}
\medskip

\def\selectlanguageifdefined#1{
\expandafter\ifx\csname date#1\endcsname\relax
\else\selectlanguage{#1}\fi}
\providecommand*{\href}[2]{{\small #2}}
\providecommand*{\url}[1]{{\small #1}}
\providecommand*{\BibUrl}[1]{\url{#1}}
\providecommand{\BibAnnote}[1]{}
\providecommand*{\BibEmph}[1]{#1}
\ProvideTextCommandDefault{\cyrdash}{\hbox to.8em{--\hss--}}
\providecommand*{\BibDash}{\ifdim\lastskip>0pt\unskip\nobreak\hskip.2em\fi
\cyrdash\hskip.2em\ignorespaces}

\bibitem{patton2007properties}
\selectlanguageifdefined{english}
{Patton,~A.\,J., and A.~Timmermann}. 2007.
Properties of optimal forecasts
  under asymmetric loss and nonlinearity. \BibJournal{J.~Econometrics}
140(2):884--918.

\bibitem{box1994timeseries}
\selectlanguageifdefined{english}
{Box,~G.\,E.\,P., G.\,M.~Jenkins, and G.\,C.~Reinsel.}
\BibTitle{Time series analysis:
  Forecasting and control}. 3rd ed.
Englewood Cliffs: NJ:~Prentice~Hall.

\bibitem{berk2011asymmetric}
\selectlanguageifdefined{english}
{Berk,~R}. 2011. Asymmetric loss functions for forecasting in criminal
  justice settings. \BibJournal{J.~Quantitative Criminology}
27(1)107--123.

\bibitem{cipra1994asymmetric}
\selectlanguageifdefined{english}
{Cipra,~T}. 1994. Asymmetric recursive methods for time
  series. \BibJournal{Appl. Math.} 39(3):203--214.

\bibitem{koenker2006quantile}
\selectlanguageifdefined{english}
{Koenker,~R., and Z.~Xiao}. 2006. Quantile autoregression.
  \BibJournal{J.~Am. Stat. Association} 101(475):980--990.

\bibitem{koenker2005quantile}
\selectlanguageifdefined{english}
{Koenker,~R}. 2005. \BibTitle{Quantile regression}.
 Cambridge University Press.

\bibitem{christoffersen1997optimal}
\selectlanguageifdefined{english}
{Christoffersen,~P.\,F, and F.\,X.~Diebold}. 1997. Optimal prediction under
  asymmetric loss. \BibJournal{Econometric Theory}
13(06):808--817.

\bibitem{granger1969prediction}
\selectlanguageifdefined{english}
{Granger,~C.\,W.\,J}. 1969. Prediction with a generalized cost of error
  function. \BibJournal{OR} 20(2):199--207.



\bibitem{christoffersen1996further} %9
\selectlanguageifdefined{english}
{Christoffersen,~P.\,F, and F.\,X.~Diebold}. 1996. Further results on
  forecasting and model selection under asymmetric loss. \BibJournal{J.~Appl.
Econometrics} 11(5):561--571.

\bibitem{diebold1997evaluating} %10
\selectlanguageifdefined{english}
Diebold, F.\,X., T.~Gunther, and A.~Tay.
1998. Evaluating density forecasts. \BibJournal{Int. Econ. Rev.} 39:863--883.

\bibitem{biau2010nonparametric} %11
\selectlanguageifdefined{english}
Biau,~G.,
  K.~Bleakley, L.~Gy{\"o}rfi, and G.~Ottucs{\'a}k. 2010.
Nonparametric sequential prediction of time series.
  \BibJournal{J.~Nonparametric Stat}.
22(3):297--317.

\bibitem{hyndman}                  %12
\selectlanguageifdefined{english}
{Hyndman,~R.\,J., and G.~Athanasopoulos.}  2006.
\BibTitle{Forecasting: Principles and practice}.
OTexts. Available at: {\sf https://www.otexts.org/book/fpp}
(accessed December~29, 2015).



\bibitem{chocolate} %13
\selectlanguageifdefined{english}
Monthly production of chocolate confectionery in Australia.
Available at:
\BibUrl{https://datamarket.com/data/set/22rl/monthly-production-of-chocolate-confectionery-in-australia-tonnes-july-1957-aug-1995#!ds=22rl&display=line}
(accessed December~29, 2015).

\bibitem{river} %14
\selectlanguageifdefined{english}
Fraser River at hope.
Available at: \BibUrl{https://datamarket.com/data/set/22nm/fraser-river-at-hope-1913-1990#!ds=22nm&display=line}
(accessed December~29, 2015).

\bibitem{lake} %15
\selectlanguageifdefined{english}
Monthly Lake Erie Levels.
Available at:
\BibUrl{https://datamarket.com/data/set/22pw/monthly-lake-erie-levels-1921-1970#!ds=22pw&display=line}
(accessed December~29, 2015).

\bibitem{sugar} %16
\selectlanguageifdefined{english}
Sugar price.
Available at:
\BibUrl{https://mlalgorithms.svn.sourceforge.net/svnroot/mlalgorithms/TSForecasting/TimeSeries/Sources/tsSugarPrice.csv}
(accessed December~29, 2015).

\bibitem{electricity} %17
\selectlanguageifdefined{english}
Electricity consumption.
Available at:
\BibUrl{https://mlalgorithms.svn.sourceforge.net/svnroot/mlalgorithms/TSForecasting/TimeSeries/Sources/tsEnergyConsumption.csv}
(accessed December~29, 2015).
  	     	
\end{thebibliography}

}


\end{document}

