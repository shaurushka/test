\documentclass[9pt, unicode]{beamer}

%Пакеты для русского языка
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
%Пакет для вставки рисунков
\usepackage{graphicx}
%AMS TEX значки и пр.
\usepackage{amssymb}
\usepackage{eqnarray}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{slashbox}
%разные пакеты
\usepackage{wrapfig}
%\usepackage{breakurl}
\usepackage{multirow}

%Привычный шрифт для математических формул
\usefonttheme[onlymath]{serif}

%Нужно включать, если используется "тема" (стиль оформления) по умолчанию
\usepackage{beamerthemesplit}

%Общий стиль ("тема") оформления слайдов
%Можно выбрать любую тему в \localtexmf\tex\latex\beamer\themes\theme\
%и её имя подставить в качестве аргумента в \usetheme
%Требование: чёрные буквы на белом фоне
\usetheme{Frankfurt}

%Более крупный шрифт для подзаголовков титульного листа
\setbeamerfont{institute}{size=\normalsize}

%Задание команды (\bluetext) для выделения конкретным (синим) цветом
%(используйте \alert для выделения цветом выбранной "темы")
\setbeamercolor{bluetext_color}{fg=blue}
\newcommand{\bluetext}[1]{{\usebeamercolor[fg]{bluetext_color}#1}}

\setbeamertemplate{navigation symbols}{}
\setlength{\topsep}{0pt}%
\DeclareMathOperator{\med}{med}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\rank}{rank}

\title[ПСАД-7. Дисперсионный анализ.]{Прикладной статистический анализ данных.\\7. Дисперсионный анализ.}
\author[Шаура Ишкина]{Шаура Ишкина \\ \href{mailto:psad.homework@gmail.com}{psad.homework@gmail.com}}
\date{I/2017}

\begin{document}
\begin{frame}
    \titlepage
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%
%Дисперсионный анализ (на английском Analysis Of Variance - ANOVA) применяется для исследования влияния одной или нескольких качественных переменных (факторов) на одну зависимую количественную переменную (отклик).
%В основе дисперсионного анализа лежит предположение о том, что одни переменные могут рассматриваться как причины (факторы, независимые переменные), а другие как следствия (зависимые переменные). Независимые переменные называют иногда регулируемыми факторами именно потому, что в эксперименте исследователь имеет возможность варьировать ими и анализировать получающийся результат. Примерами независимой переменной с двумя градациями могут служить пол (женский, мужской) или тип экспериментальной группы (контрольная, экспериментальная). Градации, соответствующие независимым выборкам объектов, называются межгрупповыми, а градации, соответствующие зависимым выборкам, — внутригрупповыми.
%Основной целью дисперсионного анализа является исследование значимости различия между средними с помощью сравнения (анализа) дисперсий.
%Исходным материалом для дисперсионного анализа служат данные исследования двух и более выборок, которые могут быть как равными, так и неравными по численности, как связными, так и несвязными.
%По количеству выявляемых регулируемых факторов дисперсионный анализ может быть однофакторным (при этом изучается влияние одного фактора на результаты эксперимента), двухфакторным (при изучении влияния двух факторов) и многофакторным (позволяет оценить не только влияние каждого из факторов в отдельности, но и их взаимодействие).
%Дисперсионный анализ относится к группе параметрических методов и поэтому его следует применять только тогда, когда доказано, что распределение является нормальным.
%Дисперсионный анализ используют, если зависимая переменная измеряется в шкале отношений, интервалов или порядка, а влияющие переменные имеют нечисловую природу (шкала наименований).
%Откуда произошло название Дисперсионный анализ? Может показаться странным, что процедура сравнения средних называется дисперсионным анализом. В действительности, это связано с тем, что при исследовании статистической значимости различия между средними двух (или нескольких) групп, мы на самом деле сравниваем выборочные дисперсии. Фундаментальная концепция дисперсионного анализа предложена Фишером в 1920 году. Возможно, более естественным был бы термин анализ суммы квадратов или анализ вариации, но в силу традиции употребляется термин дисперсионный анализ.
%%
%Допустим, что на некоторые объекты оказано несколько разных воздействий и возникли несколько последовательностей данных, описывающих объекты и имеющих различное распределение. Задача состоит в том, чтобы как-то это воздействие оценить. Наиболее простой является ситуация, когда можно указать ровно один фактор, влияющий на конечный результат, и этот фактор может принимать лишь конечное число значений. Такие задачи называются задачами однофакторного анализа. Типичный пример - сравнение по достигаемым результатам нескольких различных способов воздействия, направленных на достижение одной цели. Принята следующая терминология. То, что предположительно оказывает влияние на конечный результат, называют фактором; число, определяющее конкретную величину фактора называют уровнем фактора или способом обработки. Значения измеряемого признака, то есть результата воздействия, называют откликом. Для сравнения влияния факторов на результат необходим статистический материал. Обычно его получают следующим образом: каждый из k способов обработки применяют несколько раз к исследуемому объекту и регистрируют результаты. Итогом подобных испытаний являются k групп данных возможно с различным числом значений.
%%%%%%%%%%%%
%ANOVA - это процедура сравнения средних значений выборок, на основании которой можно сделать вывод о соотношении средних значений генеральных совокупностей. Ближайшим и более простым аналогом ANOVA является t-критерий. В отличие от t-критерий, дисперсионный анализ предназначен для сравнения не двух, а нескольких выборок. Слово "дисперсионный" в названии указывает на то, что в процессе анализа сопоставляются компоненты дисперсии изучаемой переменной. Общая изменчивость переменной раскладывается на две составляющие: межгрупповую (факторную), обусловленную различием групп (средних значений) и внутригрупповую (ошибки), обусловленную случайными (неучтенными) причинами. Чем больше частное от деления межгрупповой и внутригрупповой изменчивости (F-отношение), тем больше различаются средние значения сравниваемых выборок, и тем выше статистическая значимость этого различия.
\begin{frame}{Разновидности дисперсионного анализа (ANOVA)}
    \begin{itemize}
    \item По числу факторов: однофакторный (one-way), двухфакторный (two-way) и т.\,д.
    \item По типу выборок: независимые (between-subjects), связанные (within-subjects, repeated measurements).
    \item По типу альтернативы: общая, тренда.
    \item По типу эффектов: случайные (random-effects), фиксированные (fixed-effects).
    \item По типу уровней факторов: независимые, вложенные (nested), с~болтающимся контролем (dangling control group), латинский квадрат (latin square).
	\item По используемым предположениям: нормальный, непараметрический.
	\item По объёму выборок: одинаковый (balanced), различный (unbalanced).
    \end{itemize}
\end{frame}


\section{1-way b.s.}
%Простейшим случаем дисперсионного анализа является одномерный однофакторный анализ для двух или нескольких независимых групп, когда все группы объединены по одному признаку. В ходе анализа проверяется нулевая гипотеза о равенстве средних.
\subsection{Омнибус-критерии}%- это тип статистического теста, который проверяет, что доля объясненной дисперсии в данных значимо больше, чем необъясненной
\begin{frame}{Однофакторный дисперсионный анализ}
    \only<1>{
    Пусть имеется $K$ выборок:
    $$X^N = X_1^{n_1}\bigcup X_2^{n_2}\bigcup\ldots\bigcup X_K^{n_K}, \;\; N = \sum\limits_{i=1}^K n_i.$$

    \bigskip

    Эквивалентная запись в виде псевдотаблицы:

    фактор $f\colon X \rightarrow \left\{1,\ldots,K\right\}$

    \bigskip

    \begin{center}
        \begin{tabular}{|c|c|c|c|c|c|} \hline
        $f$   & $1$ & $\ldots$ & $k$ & $\ldots$ & $K$ \\ \hline
        $X^N$ & $\footnotesize{\begin{matrix} X_{11} \\ \vdots \\ X_{1n_{1}} \end{matrix}}$ & \ldots & $\footnotesize{\begin{matrix} X_{k1} \\ \vdots \\ X_{kn_{k}} \end{matrix}}$ & \ldots & $\footnotesize{\begin{matrix} X_{K1} \\ \vdots \\ X_{Kn_{K}} \end{matrix}}$    \\\hline
        \end{tabular}
    \end{center}

    \bigskip

    \textbf{Задача}: проверить гипотезу об отсутствии влияния фактора $f$ на среднее значение признака $X$, то есть, о равенстве средних значений $K$ выборок.
    }
%Разделение общей дисперсии на несколько источников позволяет сравнить дисперсию, вызванную различием между группами, с дисперсией, вызванной внутригрупповой изменчивостью. При истинности нулевой гипотезы (о равенстве средних в нескольких группах наблюдений, выбранных из генеральной совокупности), оценка дисперсии, связанной с внутригрупповой изменчивостью, должна быть близкой к оценке межгрупповой дисперсии. Если вы просто сравниваете средние в двух выборках, дисперсионный анализ даст тот же результат, что и обычный t-критерий для независимых выборок (если сравниваются две независимые группы объектов или наблюдений) или t-критерий для зависимых выборок (если сравниваются две переменные на одном и том же множестве объектов или наблюдений).
%Процедура дисперсионного анализа состоит в определении соотношения систематической (межгрупповой) дисперсии к случайной (внутригрупповой) дисперсии в измеряемых данных. В качестве показателя изменчивости используется сумма квадратов отклонения значений параметра от среднего: SS (от англ. Sum of Squares). Можно показать, что общая сумма квадратов SS_{{total}} раскладывается на межгрупповую сумму квадратов SS_{{BG}} и внутригрупповую сумму квадратов SS_{{WG}}:
%Внутригрупповая изменчивость (SS) обычно называется остаточной компонентой или дисперсией ошибки. Это означает, что обычно при проведении эксперимента она не может быть предсказана или объяснена. С другой стороны, SS эффект (или компоненту дисперсии между группами) можно объяснить различием между средними значениями в группах. Иными словами, принадлежность к некоторой группе объясняет межгрупповую изменчивость, т.к. нам известно, что эти группы обладают разными средними значениями.
    \only<2>{
    \textbf{Идея}: рассмотрим две компоненты разброса значений $X_{ki}$ относительно глобального среднего $\bar{X}$:
    $$X_{ki}-\bar{X} = \left(X_{ki} - \bar{X}_k\right) + \left(\bar{X}_k - \bar{X}\right),$$
    где $\bar{X}_k$~--- среднее в $k$-й выборке.

    \bigskip

    Возведём в квадрат и просуммируем:
    \begin{align*}
        \sum_{k=1}^K \sum_{i=1}^{n_k} \left(X_{ki}-\bar{X}\right)^2 & = \sum_{k=1}^K \sum_{i=1}^{n_k} \left(X_{ki} - \bar{X}_k\right)^2 + \sum_{k=1}^K n_k\left(\bar{X}_k - \bar{X}\right)^2, \\
        SS_{total} & = SS_{wg} + SS_{bg}.
    \end{align*}

    Если средние в группах значительно отличаются, преобладает вторая компонента, если же они одинаковы~--- первая.
    }
%Математическая модель дисперсионного анализа представляет собой частный случай основной линейной модели. Пусть с помощью методов A_{j},(j = 1... m) производится измерение нескольких параметров x_{i},(i = 1...n), чьи точные значения — \mu _{i}, (i = 1...n). В таком случае результаты измерений различных величин различными методами можно представить как:
%x_{{i,j}}=\mu _{{i}}+a_{{i,j}}+e_{{i,j}},
%где:
%x_{{i,j}} — результат измерения i-го параметра по методу A_{{j}};
%\mu _{{i}} — точное значение i-го параметра;
%a_{i,j} — систематическая ошибка измерения i-го параметра в группе по методу A_{{j}};
%e_{{i,j}} — случайная ошибка измерения i-го параметра по методу A_{{j}}.
    \only<3>{
    Линейная модель:
    $$X_{ki} = \mu + \alpha_k + \varepsilon_{ki},$$
    $i=1,\dots,n_k, \; k=1,\dots,K.$

    \bigskip

    $\mu$~--- глобальное среднее значение признака $X$,

    $\alpha_k$~--- отклонение от $\mu$, вызванное влиянием $k$-го уровня фактора $f$,

    $\varepsilon_{ki}$~--- случайные независимые одинаково распределённые ошибки.

    \bigskip

    Средние значения $X$ во всех $K$ выборках одинаковы $\Leftrightarrow$ $\alpha_1=\dots=\alpha_K$.
    }
\end{frame}

%Сущность дисперсионного анализа заключается в расчленении общей дисперсии изучаемого признака на отдельные компо­ненты, обусловленные влиянием конкретных факторов, и проверке гипотез о значимости влияния этих факторов на исследуемый признак. Сравнивая компоненты дисперсии друг с другом посредством F—критерия Фишера, можно определить, какая доля общей вариативности результативного признака обусловлена действием регулируемых факторов.
%Проверка значимости в дисперсионном анализе основана на сравнении компоненты дисперсии, обусловленной межгрупповым разбросом (называемой средним квадратом эффекта или MSэффект) и компоненты дисперсии, обусловленной внутригрупповым разбросом (называемой средним квадратом ошибки или MSошибка; эти термины были впервые использованы в работе Edgeworth, 1885). Если верна нулевая гипотеза (равенство средних в двух популяциях), то можно ожидать сравнительно небольшое различие выборочных средних из-за чисто случайной изменчивости. Поэтому, при нулевой гипотезе, внутригрупповая дисперсия будет практически совпадать с общей дисперсией, подсчитанной без учета групповой принадлежности. Полученные внутригрупповые дисперсии можно сравнить с помощью F-критерия, проверяющего, действительно ли отношение дисперсий значимо больше 1.
%При анализе двух групп дисперсионный анализ тождественен двухвыборочному t-критерию Стьюдента для независимых выборок, и величина F-статистики равна квадрату соответствующей t-статистики.
\begin{frame}{Критерий Фишера}
    \only<1>{
    \begin{center}
        \begin{tabular}{rl}
            выборки:                        & $X^N = X_1^{n_1}\bigcup\ldots\bigcup X_K^{n_K};$ \\
            нулевая гипотеза:               & $H_0\colon \alpha_1=\dots=\alpha_K;$ \\
            альтернатива:                   & $H_1\colon H_0$ неверна;\\
            статистика:                     & $F\left(X^N\right) = \frac{SS_{bg} / \left(K-1\right)}{SS_{wg} / \left(N-K\right)},$ \\
                                            & $SS_{bg} = \sum\limits_{k=1}^K n_k\left(\bar{X}_k - \bar{X}\right)^2,$ \\
                                            & $SS_{wg} = \sum\limits_{k=1}^K \sum\limits_{i=1}^{n_k} \left(X_{ki} - \bar{X}_k\right)^2,$ \\
                                            & $F\left(X^N\right) \sim F(K-1, N-K)$ при $H_0.$\\
        \end{tabular}
        \includegraphics[width=\textwidth]{./2013-2/fish.eps}
    \end{center}
    }

    \only<2>{
    Предположения метода:
    \begin{enumerate}
    \item выборочные распределения средних значений признака во всех группах нормальны;
    \item дисперсия значений признака во всех группах одинакова;
    \item наблюдения независимы.
    \end{enumerate}

    \bigskip

	\begin{itemize}
	\item Первое предположение считается выполненным, если распределение признака во всех группах нормально, или если объёмы выборок примерно одинаковы и $N-K-1\geq 20.$
	\item Второе предположение считается выполненным, если отношение наибольшей выборочной дисперсии к наименьшей не превосходит 10.
	\item При $n_1=\dots=n_K$ метод устойчив к нарушению первых двух предположений.
	\item Если объёмы выборок различаются, нарушение предположения о~равенстве дисперсий может привести к росту вероятности ошибки первого рода.
	\item Выбросы могут оказывать существенное влияние на результат.
	\end{itemize}
    }

    \only<3>{
    \textbf{Пример 1} (Bonnini, табл. 3.1): измерен вес пятидесяти пятиграммовых пакетиков сахара, расфасованы пятью разными производителями.
    Зависит ли от производителя средний вес сахара в пакетиках?

    \begin{figure}
    	\includegraphics[width=0.7\textwidth,natwidth=669,natheight=419]{./2015/sugar.png}
    \end{figure}

    $H_0 \colon$ средний вес сахара одинаков для всех производителей.

    $H_1 \colon$ у каких-то производителей средний вес сахара отличается от~остальных $\Rightarrow p = 0.115.$

%топливная компания тестирует влияние трёх видов присадок на~потребление бензина. Выборка получена на 12~одинаковых автомобилях, на каждом из которых использовалась одна из трёх присадок.
%
%    \bigskip
%
%    $H_0 \colon$ все три вида присадок одинаково влияют на среднее потребление бензина.
%
%    $H_1 \colon$ между средними уровнями потребления бензина с разными присадками есть различия $\Rightarrow p = 2.1717 \times 10^{-5}.$
    }

    \only<4>{
    \textbf{Пример 2} (Bonnini, табл. 3.2): исследуется эффективность четырёх жаропонижающих средств, в составе которых один и тот же активный ингридиент присутствует в разных дозировках. Для каждой из четырёх групп из 15~морских свинок известно изменение температуры после введения жаропонижающего. Есть ли различия в действии препаратов?

    \begin{figure}
    	\includegraphics[width=0.7\textwidth,natwidth=669,natheight=415]{./2015/drugs.png}
    \end{figure}

    $H_0 \colon$ температура меняется в среднем одинаково.

    $H_1 \colon$ для каких-то препаратов среднее изменение температуры отличается от остальных $\Rightarrow p = 5.43\times10^{-14}.$
    }
\end{frame}
%Критерий Краскела-Уоллиса предназначен для проверки равенства средних нескольких выборок. Данный критерий является многовыборочным обобщением критерия Уилкоксона-Манна-Уитни. Критерий Краскела-Уоллиса является ранговым, поэтому он инвариантен по отношению к любому монотонному преобразованию шкалы измерения.
%Заданы k выборок: X_1=\left\{x_1^1,\dots,x_1^{n_1}\right\}, \dots, X_k=\left\{x_k^1,\dots,x_k^{n_k}\right\}. Объединённая выборка: X=X_1\cup X_2\cup \dots \cup X_k.
%Дополнительные предположения: -все k выборок простые, объединённая выборка независима; -выборки взяты из неизвестных непрерывных распределений  F_1(x),\dots,F_k(x).
%Проверяется нулевая гипотеза при альтернативе сдвига.
%Упорядочим данные Xij и обозначим через rij ранг числа Xij во всей совокупности наблюдений. Проверим, нельзя ли объяснить наблюденное в опыте расположение рангов действием чистой случайности. Вопрос формулируем в виде статистической гипотезы о том, что все k представленных групп однородны, то есть порождены одной и той же случайной величиной. Строим статистику, в данном случае функцию от рангов rij, распределение которой при гипотезе Н0 заметно отличается от её распределения при альтернативах. При гипотезе Н0 все возможные значения рангов равновероятны. Это дает возможность рассчитать закон распределения при Н0 любой ранговой статистики: все N!/(n1!...nK!) возможных наборов рангов при выполнении H0 равновероятны. Для каждого из них вычисляется значение статистики.
%Критерий, предложенный Краскелом и Уоллисом, свободен от предположений о виде распределения данных. При его применении для каждой обработки j вычисляется средний ранг данных. Если между обработками нет систематических различий, средние ранги не должны значительно отличаться от среднего ранга, рассчитанного по всей совокупности rij, равного 0,5(N + 1). Поэтому величины rjср - 0,5(N + 1) при гипотезе Н0 в совокупности должны быть небольшими. В качестве меры отступления от чистой случайности принято брать статистику Краскела-Уоллеса.
%Первый сомножитель стабилизирует ее распределения при большом числе наблюдений.
%При наличии связанных рангов (т.е. когда совпадают значения величин из разных выборок и им присваиваются одинаковые средние ранги) необходимо использовать модифицированную статистику H*=H\left\{1-\left(\sum_{j=1}^q \frac{T_j}{N^3-N} \right) \right\} ^{-1}, где T_j=t_j^3-t_j;\; t_j — размер j-й группы одинаковых элементов; q — количество групп одинаковых элементов.
%Гипотеза сдвига отклоняется на уровне значимости \alpha, если H \ge H_{\alpha}, где H_{\alpha} — критическое значение, при k \le 5 и n_i \le 8 вычисляемое по таблицам. При больших значениях применимы различные аппроксимации.
%При n_i > 5 справедлива аппроксимация распределения статистики H \chi_{k-1}^2-распределением с k-1 степенями свободы, т.е. нулевая гипотеза отклоняется, если H \ge \chi_{k-1,\alpha}^2.
%%%%%%%%%%
\begin{frame}{Критерий Краскела-Уоллиса}
    \only<1>{
%    \vspace{-15pt}
    \begin{center}
        \begin{tabular}{rl}
            выборки:                        & $X^N = X_1^{n_1}\bigcup\ldots\bigcup X_K^{n_K}, \;\; X_{k} \sim F\left(x + \Delta_k\right);$ \\
            нулевая гипотеза:               & $H_0\colon \Delta_1 = \Delta_2 = \ldots = \Delta_K;$ \\
            альтернатива:                   & $H_1\colon H_0$ неверна;\\
            статистика:                     & $K\left(X^N\right) = \left(N-1\right)\frac{\sum\limits_{k=1}^K n_k \left(\bar{r}_k-\bar{r}\right)^2 }{\sum\limits_{k=1}^K \sum\limits_{i=1}^{n_k} \left(r_{ki} - \bar{r}\right)^2}, \; r_{ki} \equiv \rank \left(X_{ki}\right), $\\
                                            & $K\left(X^N\right)$ имеет табличное распределение при $H_0.$\\
        \end{tabular}
    \end{center}
    %если связки есть, нужно брать средние ранги, а также сделать поправку домножением на коэффициент, формула в Лагутине.
    Если нет связок, то:
    \begin{align*}
        \bar{r} &= \frac{N+1}{2}, \\
        \sum\limits_{k=1}^K \sum\limits_{i=1}^{n_k} \left(r_{ki} - \bar{r}\right)^2 &= \frac{\left(N-1\right) N \left( N+1\right) }{12}, \\
        K\left(X^N\right) &= \frac{12}{N\left(N+1\right)} \sum\limits_{k=1}^K n_k \bar{r}_k^2 - 3\left(N+1\right).
    \end{align*}

    Аппроксимация для $n_k>5$:
    $$K\left(X^N\right) \sim \chi^2_{K-1}.$$
    }

    \only<2>{
    \textbf{Пример} (вес сахара в пакетиках): $p=0.1799.$

    \bigskip

    \textbf{Пример} (действие жаропонижающих на морских свинок): $p=1.527\times 10^{-9}.$

%    дегустаторы оценивают торты по совокупности факторов~--- вкус, внешний вид, запах и фактура. Итоговая оценка выставляется в баллах от~0 до~100. Сравниваются оценки трёх видов тортов, представленных каждый отдельной команде дегустаторов.
%
%    \bigskip
%
%    $H_0 \colon$ оценки трёх видов тортов в среднем одинаковы.
%
%    $H_1 \colon$ между оценками разных видов тортов есть различия $\Rightarrow p = 0.6587.$
    }
\end{frame}
%Критерий Джонкхиера (также известен как критерий Джонкхира-Терпстры) основан на попарных статистиках Уилкоксона-Манна-Уитни и используется для проверки гипотезы сдвига против альтернатив упорядоченности.
%Предположим, что из некоторых соображений, не связанных со значениями данных, заранее известно, что имеющиеся группы результатов упорядочены по возрастанию влияния фактора. Пусть, для определенности, первая группа отвечает наименьшему уровню фактора, последняя - наибольшему, а промежуточные группы получили номера, соответствующие их положению. В рассматриваемом случае это допустимо, так как с ростом курса возрастает как разочарование в преподавателях, так и загрузка на работе, которой занимаются в большинстве своём студенты. В таких случаях можно использовать критерий Джонкхиера, более мощный против альтернатив об упорядоченном влиянии фактора. Против других альтернатив свойства этого критерия могут оказаться хуже свойств критерия Краскела-Уоллиса. Пусть сравниваются только два способа обработки. Данные в этом случае сформированы в две группы. Фактически здесь речь идет о проверке однородности двух групп данных. Это осуществляется с использованием статистики Манна-Уитни. Напомним, что для двух групп данных х1,...,xm и у1,...,уn, всякое событие yj > хi обозначает "успех", zij = I(yj > хi), статистика Манна-Уитни U = ΣI(yj > хi). Джонкхиер предложил для сравнения k способов обработки, для каждой пары натуральных чисел и и v, где 1 ≤ и < v ≤ k составлять по группам с номерами и, v статистику Манна-Уитни Uu,v = ΣΣI(yui > хvj). Статистика Джонкхиера есть сумма по всем парам статистик Манна-Уитни Uu,v: J = ΣΣUu,v. Свидетельством в пользу альтернативы упорядоченности эффектов и против гипотезы однородности служат большие значения статистики J, полученные в эксперименте.
%При небольших объемах данных и небольших k распределение статистики J табулировано. Нетрудно видеть, что величину статистики можно вычислить по совместной ранжировке всех N наблюдений. Таким образом, хотя для подсчета J и не нужна совместная ранжировка, зная ее и не зная самих x_{ij}, можно восстановить значение J. Поэтому распределение случ.величины J при условии справедливости H0, как и в критерии Краскела-Уоллиса, можно найти так: все N!/(n1!...nK!) возможных наборов рангов равновероятны, для каждого из них вычисляется значение статистики.
%Для больших выборок в отношении J действует нормальная аппроксимация: J* ~ N(0,1), где ...
%Вышеуказанный критерий применяется в случаях априорного предположения об упорядоченности группы результатов по возрастанию влияния фактора. В этих случаях критерий Джонкхиера оказывается более чувствителен в оценке влияния фактора, нежели критерий Краскела-Уоллиса.
%%%%%(Лагутин)
%На практике часто встречается ситуация, когда исследователь пытается выявить значимое возрастание (или убывание) уровня интересующего его фактора от выборки к выборке. В этом случае нужно применять не критерий Краскела-Уоллиса, а более чувствительный критерий Джонкхиера.
\begin{frame}{Критерий Джонкхиера}
    \only<1>{
    \begin{center}
        \begin{tabular}{rl}
            выборки:                        & $X^N = X_1^{n_1}\bigcup\ldots\bigcup X_K^{n_K}, \;\; X_{k} \sim F\left(x + \Delta_k\right);$ \\
            нулевая гипотеза:               & $H_0\colon \Delta_1 = \Delta_2 = \ldots = \Delta_K $ \\
                                            & \; $\Rightarrow \; \med X_1 = \ldots = \med X_K;$ \\
            альтернатива:                   & $H_1\colon \med X_1 \leq \ldots \leq \med X_K$;\\
            статистика:                     & $S\left(X^N\right) = \sum\limits_{k=1}^K \sum\limits_{i=1}^{n_k} a_{ki},$\\
                                            & $a_{ki}$~--- число наблюдений из первых $k-1$~выборок, \\
                                            & меньших, чем $X_{ki};$ \\
                                            & $S\left(X^N\right)$ имеет табличное распределение при $H_0.$\\
        \end{tabular}
    \end{center}

    \bigskip

    Аппроксимация для $n_k>10$:
    \begin{align*}
        S\left(X^N \right) &\sim N\left(\mu,\sigma^2\right),\\
        \mu &= \frac1{4}\left(N^2 - \sum\limits_{k=1}^{K} n_k^2\right), \\
        \sigma &=\frac1{72} \left( N^2\left(2N+3\right) -\sum\limits_{k=1}^K n_k^2\left(2n_k+3\right) \right).
    \end{align*}
    }

    \only<2>{
    \textbf{Пример} (Bonnini, табл. 3.4): исследуется зависимость предела прочности (в Ньютонах на квадратный метр) армированного бетона с разной концентрацией присадки~--- 16, 20, 24 и 28\%. Меняется ли средний предел прочности вместе с уровнем присадки?

    \begin{figure}
    	\includegraphics[width=0.7\textwidth,natwidth=672,natheight=418]{./2015/concrete.png}
    \end{figure}
%    исследуется влияние информированности (знания цели работы) на выполнение монотонных производственных операций. 18 рабочих были случайным образом разделены на 3 группы. Попавшие в группу 1 не~имели информации о требуемой производительности, в группу 2~--- получили общее представление о том, что нужно делать, в группу 3~--- точную информацию о задании и график выполнения работ.

    $H_0 \colon$ концентрация присадки не влияет на среднюю прочность.

    $H_1 \colon$ концентрация присадки влияет на среднюю прочность $\Rightarrow p = 0.0042.$

    $H_1 \colon$ увеличение концентрации присадки повышает среднюю прочность $\Rightarrow p = 2.936\times 10^{-5}.$
    }
\end{frame}
%Термин случайные эффекты в контексте дисперсионного анализа используется для обозначения факторов плана ANOVA, уровни которых не фиксируются заранее (факторы с фиксированными заранее уровнями называются фиксированными эффектами), а получаются из выборки в ходе эксперимента. Например, если нас интересует влияние образовательного уровня школы на теоретическую подготовленность учеников, можно сделать случайную выборку учебных заведений для оценивания дисперсии теоретической подготовленности (компоненты дисперсии), которая связана с различием между школами.
%Для определения, является ли данный эффект в эксперименте случайным или фиксированным достаточно ответить на вопрос, каким образом выбираются (задаются) уровни соответствующего фактора в процессе повторения такого исследования. Например, если мы хотели бы повторить описанный пример, нам следовало бы сделать некоторую выборку из общего числа школ. Поэтому фактор "школа" в этом исследовании будет случайным фактором. С другой стороны, если бы мы хотели сравнить теоретическую подготовленность молодых людей и девушек в эксперименте с фиксированным фактором Пол, мы в любом случае получили бы две группы: юноши и девушки. Следовательно, в этом случае (и только в этом случае) для повторения исследования уровни фактора Пол будут выбраны однозначно.
%В некоторых исследованиях иногда ошибочно предполагается, что достаточно только проделать некоторые действия с уровнями независимых переменных и оценить соответствующие отклики зависимых переменных. Независимые переменные, уровни которых определяются исследователем, называются фиксированными эффектами. Другой тип эффектов, часто вызывающий интерес исследователей, представляют случайные эффекты. Предполагается, что уровни фактора этого типа случайным образом выбраны из генеральной совокупности всех возможных уровней. В исследовательской работе иногда не представляется возможным осуществлять какие-либо действия с независимыми переменными, участвующими в анализе. Выходом является рассмотрение данных переменных как случайных. Например, генетический набор особей различных видов в настоящий момент не может быть полностью изменен в результате генетических экспериментов, поэтому генетик не имеет возможности полностью воссоздать картину воздействия различных комбинаций генов на здоровье, поведенческие характеристики и т.п. для обследуемой особи. В качестве еще одного примера, рассмотрим задачу производителя, который желает исследовать компоненты дисперсии характеристик какого-либо продукта, производящегося с помощью некоторого набора случайно выбранных станков, которыми управляли некоторые случайно выбранные операторы. Статистический анализ случайных эффектов основан на модели случайных эффектов, если все независимые переменные являются случайными эффектами, или на смешанной модели, если некоторые эффекты предполагаются случайными, а некоторые являются фиксированными.
\subsection{Вторичный анализ}
\begin{frame}{Модель со случайным эффектом}
    \only<1>{
    \begin{itemize}
    \item Характеристика, определяющая разбиение на группы, не~представляет непосредственного интереса.
    \item Группы случайно выбраны из множества возможных групп.
    \item Если между группами есть неоднородность, ожидается, что она сохранится при повторе эксперимента, но соотношения между средними могут измениться.
    \end{itemize}

    \bigskip

    Примеры.
    \begin{itemize}
    \item Размеры горбаток в разных семьях, выращенных на одном и том же растении; цель --- определить значимость фактора семьи для дальнейших исследований.
    \item Уровень гликогена в различных образцах икроножной мышцы крысы; если вариация между образцами даёт маленький вклад в общую вариацию,  то можно считать, что для измерения уровня достаточно одного образца.
    \item Вкусовые качества персиков с 10 различных деревьев; планируется сравнить различия во вкусовых качествах персиков с разных деревьев с различиями у персиков с одного дерева. Если последние больше, то~бессмысленно выбрать для размножения дерево с лучшей средней оценкой.
    \end{itemize}
    }
%В простейшем случае, когда совокупность разбита на группы по одному фактору, изучение вариации достигается посредством исчисления и анализа трех видов дисперсий: общей, межгрупповой и внутригрупповой.
%Общая дисперсия D(x) измеряет вариацию признака по всей совокупности под влиянием всех факторов, обусловивших эту вариацию. Она равна среднему квадрату отклонений отдельных значений признака (хi) от общей средней величины и может быть вычислена как: 1. простая дисперсия   2. взвешенная дисперсия.
%Межгрупповая дисперсия (факторная) характеризует систематическую вариацию результативного признака, обусловленную влиянием признака-фактора, положенного в основание группировки. Она равна среднему квадрату отклонений групповых (частных) средних  от общей средней.
%Внутригрупповая дисперсия (частная, остаточная, случайная) отражает случайную вариацию неучтенных факторов и не зависящую от признака-фактора, положенного в основание группировки. Она равна среднему квадрату отклонений отдельных значений признака внутри группы (хi) от средней арифметической этой группы (xср) (групповой средней) и может быть исчислена как...
%Согласно правилу сложения дисперсий, общая дисперсия равна сумме средней из внутригрупповых и межгрупповой дисперсий.
%Пользуясь правилом сложения дисперсий, можно всегда по двум известным дисперсиям определить третью – неизвестную. Чем больше доля межгрупповой дисперсии в общей дисперсии, тем сильнее влияние группировочного признака на изучаемый признак. Поэтому в статистическом анализе широко используется эмпирический коэффициент детерминации - показатель, представляющий собой долю межгрупповой дисперсии в общей дисперсии результативного признака и характеризующий силу влияния группировочного признака на образование общей вариации:
%При отсутствии связи эмпирический коэффициент детерминации равен нулю, а при функциональной связи – единице. Эмпирическое корреляционное отношение (см. пример) – это корень квадратный из эмпирического коэффициента детерминации:
%Он показывает тесноту связи между группировочным и результативным признаками. Эмпирическое корреляционное отношение может принимать значения от 0 до 1. Если связь отсутствует, то корреляционное отношение равно нулю, т.е. все групповые средние будут равны между собой, межгрупповой вариации не будет. Значит, группировочный признак никак не влияет на образование общей вариации. Если связь функциональная, то корреляционное отношение будет равно единице. В этом случае дисперсия групповых средних равна общей дисперсии, т.е. внутригрупповой вариации не будет. Это означает, что группировочный признак целиком определяет вариацию изучаемого результативного признака. Чем значение корреляционного отношения ближе к единице, тем теснее, ближе к функциональной зависимости связь между признаками.
    \only<2>{
    Если используется \textbf{модель со случайным эффектом}, следующий шаг~--- разделение дисперсий на внутригрупповые и межгруповые.

    \bigskip
    %эмпирический коэффициент детерминации
	Доля межгрупповой дисперсии в общей дисперсии выборки:
	$$\eta^2 = \frac{SS_{bg}}{SS_{total}};$$

	в популяции:
	
	$$\hat{\omega}^2 = \frac{SS_{bg} - SS_{wg} \left(K-1\right)/ \left(N-K\right)}{SS_{total} + SS_{wg}/\left(N-K\right)}.$$
    }
\end{frame}
%Термин фиксированные эффекты в контексте дисперсионного анализа используется для обозначения факторов плана, уровни которых заранее определяются исследователем, а не случайно выбираются в ходе эксперимента (факторы с неизвестными заранее уровнями называются свободными эффектами). Например, если мы хотим провести эксперимент по проверке гипотезы, что повышение температуры ведет увеличению агрессивности, мы, наверное, провели бы наблюдение объектов в условиях нормальной и повышенной температуры, и оценили бы их агрессивность в этих условиях. Температура в этом эксперименте будет фиксированным эффектом, поскольку интересующие нас уровни температуры преднамеренно фиксируются экспериментатором.
%
%Для определения, является ли данный эффект в эксперименте случайным или фиксированным достаточно ответить на вопрос, каким образом выбираются (задаются) уровни соответствующего фактора в процессе повторения такого исследования. Например, если мы хотели бы повторить описанный пример, нам следовало бы выбрать те же самые уровни температуры из возможных уровней. Поэтому фактор "температура" в этом исследовании будет фиксированным фактором. Если же нас интересует зависимость агрессивности от температуры, нам следовало бы подвергнуть объекты воздействию набору случайно выбранных (из допустимого диапазона) температур. Уровни температуры в процессе повторения исследования, скорее всего, будут отличаться от уровней температуры, использованных первоначально, поэтому температуру можно рассматривать как случайный эффект.
\begin{frame}{Модель с фиксированным эффектом}
    \only<1>{
    \begin{itemize}
    \item Разбиение на группы определено до получения данных.
    \item При повторе эксперимента ожидается, что соотношения между средними групп сохранятся.
    \item Если между средними есть различия, на следующем этапе анализируется, какие именно группы различаются.
    \end{itemize}

    \bigskip

    Примеры.
    \begin{itemize}
    \item Продолжительность жизни разноногих раков в морской воде и~растворах глюкозы и маннозы.
    \item Экспрессия определённого гена в тканях мозга, печени, лёгких и~мышц; необходимо понять, в какой ткани экспрессия выше.
    \item Вкусовые качества персиков с 10 различных деревьев; планируется выбрать лучшее дерево для дальнейшего разведения.
    \end{itemize}
    }

    \only<2>{
    Если используется \textbf{модель с фиксированным эффектом}, то, в случае отвержения гипотезы однородности средних, проводится дополнительное сравнение с целью уточнения характера различий.
    %данный тип анализа называется post-hoc или апостериорным анализом

    Сравнение может быть:
    \begin{itemize}
    \item запланированным, когда группы для дальнейшего сравнения отобраны до сбора данных.
    \item незапланированным, когда группы для сравнения выбираются по~результатам первичного анализа данных.
    \end{itemize}

    Для запланированного попарного сравнения групп можно просто использовать подходящий двухвыборочный критерий.

    Для незапланированного сравнения всё сложнее.
    }
\end{frame}

%Иногда задача заключается в том, чтобы сравнить несколько групп с единственной — контрольной. Конечно, можно было бы использовать любой из описанных методов множественного сравнения (критерий Стьюдента с поправкой Бонферрони, Ньюмена—Кейлса или Тьюки): попарно сравнить все группы, а затем отобрать те сравнения, в которых участвовала контрольная группа. Однако в любом случае (особенно при применении поправки Бонферрони) из-за большого числа лишних сравнений критическое значение окажется неоправданно высоким. Иными словами, мы слишком часто будем пропускать реально существующие различия. Преодолеть эту трудность позволяют специальные методы сравнения, например, критерий Даннета. Его следует применять только после того, как с помощью дисперсионного анализа отвергнута нулевая гипотеза о равенстве всех средних.
\begin{frame}{Критерий Даннета}
    \begin{align*}
    D_i &= \frac{\bar{X}_i-\bar{X}_1}{S\sqrt{\frac1{n_i} + \frac1{n_1}}}, \\
    S^2 &= \frac1{N-K} \sum\limits_{k=1}^K \left(n_k-1\right)S_k^2, \\
    \intertext{где $S_k^2$ --- дисперсия выборки $X_k^{n_k}$.}
    \end{align*}

    \vspace{-20pt}

    Если $X_{i,j}\sim N\left(\mu_i, \sigma^2\right),$ то при $\mu_1=\dots=\mu_K$ вектор $D = \left(D_2,\dots,D_k\right)$ имеет многомерное распределение Стьюдента.
    Кроме того, для $D$ выполняется свойство subset pivotality, поэтому можно построить процедуру, контролирующую FWER, методом maxT.

    \bigskip

    Варианты процедуры:
    \begin{itemize}
    	\item нисходящая модификация;
    	\item непараметрическая версия.
    \end{itemize}
\end{frame}
%Метод LSD = Метод группирования выборок с наименее значимой разницей = Least Significant Difference method.
%Метод LSD позволяет проверять равенство средних значений нескольких выборок и выделять группы выборок с одинаковыми средними значениями. Метод изобретен Фишером в 1935 году и является первым методом множественных сравнений. Также известен как безопасный t-тест (protected t-test method).
%Метод состоит из двух этапов:
%Сначала при помощи критерия Фишера проверяется гипотеза о равенстве всех \mu_i. Если гипотеза принимается, то метод останавливается, иначе переход к шагу 2.
%Выборки упорядочиваются по возрастанию выборочных средних. После этого поэтапно проверяются гипотезы равенства средних соседних выборок помощи критерия Стьюдента. В качестве оценки дисперсии используется внутригрупповое среднее. Если гипотеза принимается, то соответствующие выборки объединяются в одну группу.
%Если выполнять только шаг 2, то получим небезопасный метод LSD (unprotected LSD method). Под небезопасностью понимается неконтролируемое увеличение вероятности ошибок 1-го рода при многократном применении критерия Стьюдента.
%Главным достоинством метода LSD является его простота и прозрачность.
%Главным недостатком метода LSD является неконтролируемый рост вероятности ошибки первого рода на шаге 2. Если же для уменьшения ошибки первого рода применить поправку Бонферрони, то очень сильно падает мощность критерия (возрастает вероятность ошибки второго рода).
%Таким образом, рекомендуется использовать метод LSD на первом этапе анализа данных для выявления подозрительных областей. Для более аккуратного анализа рекомендуется использовать более современные методы.
\begin{frame}{LSD Фишера (Least Significant Difference)}
    Если $\alpha_i=\alpha_j,$ то
    $$\frac{\bar{X}_i - \bar{X}_j}{S \sqrt{\frac1{n_i} + \frac1{n_j}}} \sim St\left(n_i + n_j - 2\right),$$
    где $S^2 = \frac{\left(n_i-1\right)S_i^2 + \left(n_j-1\right)S_j^2}{n_i + n_j - 2}.$

    Рассмотрим величину
    $$LSD_{ij} = \frac{t_{\alpha} S}{\sqrt{\frac1{n_i} + \frac1{n_j}}},$$
    где $t_{\alpha}$~--- $\alpha$-квантиль распределения Стьюдента с $n_i + n_j - 2$ степенями свободы.

    \bigskip

    Если $\left|\bar{X}_i - \bar{X}_j\right|>LSD_{ij},$ то частная нулевая гипотеза $H_0\colon \alpha_i = \alpha_j$ отклоняется против двусторонней альтернативы.

    \bigskip

    LSD можно использовать только в случае отвержения общей гипотезы однородности.
\end{frame}
%Рассмотрим критерий достоверно значимой разности Тьюки. В нем, в отличие от LSD, в знаменателе статистики в качестве оценки дисперсии используется внутригрупповая дисперсия, рассчитанная по всем группам, а не по одной паре. За счет этого критерий обеспечивает контроль над групповой вероятностью ошибки первого рода. Это свойство делает критерий Тьюки подходящим критерием для выполнения большого числа попарных сравнений групповых средних.
%В данном критерии возникает распределение стьюдентизированного размаха. Оно строится следующим образом. Пусть у нас имеется N объектов в K группах, каждая из которых распределена нормально с одинаковым средним и дисперсией. Пусть y_1 - min из выборочных средних, y_2 - max из выборочных средних и S^2 выборочная внутригрупповая дисперсия. Тогда q = (y2 - y1) / (S * sqrt(2 / N)) - это стьюд.размах с N-K степ.свободы. Это табличное распределение.
\begin{frame}
    \frametitle{HSD Тьюки (Honest Significant Difference)}
    \begin{align*}
        n   &= \frac{K}{\sum\limits_{k=1}^K \frac1{n_k}}, \\
        S^2 &= \frac1{N-K} \sum\limits_{k=1}^K \left(n_k-1\right)S_k^2, \\
        \intertext{где $S_k^2$ --- дисперсия выборки $X_k^{n_k}$,}
        HSD &= \frac{q_{\alpha}\left(N-K\right)S}{\sqrt{n},}
    \end{align*}
    где $q_{\alpha}\left(N-K\right)$~--- критическое значение распределения стьюдентизированного размаха с $N-K$ степенями свободы.

    \bigskip

    Если $\left|\bar{X}_i - \bar{X}_j\right|>HSD,$ то частная нулевая гипотеза $H_0\colon \alpha_i = \alpha_j$ отклоняется против двусторонней альтернативы.

    \bigskip

    HSD можно использовать независимо от справедливости общей гипотезы однородности.
\end{frame}
%Недостатком критериев LSD, HSD является предположение о нормальности данных. В случае, когда предположение не выполнено, необходимо пользоваться критерием Неменьи.
\begin{frame}{Критерий Неменьи}
    Ранговый аналог HSD.
    $$    CD = q'_{\alpha} \sqrt{\frac{K\left(K+1\right)}{6N}},$$
    где $q'_{\alpha}$~--- критическое значение статистики критерия, основанное на распределении стьюдентизированного размаха.

    \bigskip

    Если $\left|\bar{r}_i - \bar{r}_j\right|>CD,$ то частная нулевая гипотеза $H_0\colon \Delta_i = \Delta_j$ отклоняется против двусторонней альтернативы.
\end{frame}



\begin{frame}{Примеры}
\only<1>{
    Овсяная мука пяти видов помола расфасовывается при помощи одного диспенсера. Стандартный объём упаковки~--- 500~г, но диспенсер обычно насыпает больше. Производитель подозревает, что объём упаковки может зависеть от помола муки.

    \bigskip

    Метод LSD: вес в группах 3 и 5 значимо отличается.

    \begin{center}
        \includegraphics[width=0.45\textwidth]{./2013-2/flour.eps}
    \end{center}

    Метод HSD: значимых различий между средними не обнаружено.
    }
    \only<2>{
    Действие жаропонижающих на морских свинок:

    \begin{figure}
    	\includegraphics[width=0.5\textwidth,natwidth=669,natheight=415]{./2015/drugs.png}
    \end{figure}

    HSD:
    \begin{center}\small
    \begin{tabular}{|c|c|c|c|} \hline
       & T1                   &  T2                & T3 \\ \hline
	T2 & $3.5\times10^{-8}$   & -                  & - \\
	T3 & $0.9983$             & $6.7\times10^{-8}$ & - \\
	T4 & $4.95\times10^{-11}$ & $0.2949$           & $8.6\times10^{-11}$ \\ \hline
    \end{tabular}
    \end{center}

    \bigskip

    Критерий Неменьи:
    \begin{center}\small
    \begin{tabular}{|c|c|c|c|} \hline
       & T1                 & T2        & T3 \\ \hline
	T2 & $0.00016$          & -         & - \\
	T3 & $0.99999$          & $0.00018$ & - \\
	T4 & $1.9\times10^{-6}$ & $0.79418$ & $2.2\times10^{-6}$ \\ \hline
    \end{tabular}
    \end{center}

    }
\end{frame}

\subsection{Сравнение дисперсий}
%К сравнению нескольких дисперсий прибегают в тех случаях, когда возникает необходимость оценить однородность результатов анализа, представленных рядом выборочных совокупностей и их пригодность для совместной статистической обработки.
%К тому же, основным предположением вышеизложенных тестов ANOVA является однородность выборок - равенство дисперсий по уровням фактора. Для проверки данного предположения используется следующий тест.
%Если справедливо допущение, что наблюдения X_{ij} имеют нормальное распределение (или очень похожее на него), то можно воспользоваться критерием Бартлетта для сравнения дисперсий.
%Параметры mu_k, sigma_k неизвестны. Несмещенными оценками для среднего и дисперсии, как мы знаем, являются ср.арифметическое и среднеквадр.отклонение.
%Статистикой критерия служит отношение взвешенных среднего арифметического и среднего геометрического величин S^2_1, ..., S^2_K.
%Когда гипотеза принимается, для установления однородности выборок остается убедиться, что верна гипотеза о равенстве средних. Для ее проверки можно использовать F-критерий Фишера.
\begin{frame}{Критерий Бартлетта}
    \only<1>{
%    \vspace{-15pt}
    \begin{center}
        \begin{tabular}{rl}
            выборки:                        & $X^N = X_1^{n_1}\bigcup\ldots\bigcup X_K^{n_K}, \;\; X_{ki} \sim N\left(\mu_k, \sigma^2_k\right);$ \\
            нулевая гипотеза:               & $H_0\colon \sigma_1 = \sigma_2 = \ldots = \sigma_K;$ \\
            альтернатива:                   & $H_1\colon H_0$ неверна;\\
            %раньше в числителе стояло \frac{\ln 10}{C}
            статистика:                     & $B\left(X^N\right) = \frac{1}{C} \left(\left(N-K\right)\ln S^2 - \sum\limits_{k=1}^K \left(n_k-1\right)\ln S_k^2\right),$ \\
                                            & $S^2 = \frac1{N-K} \sum\limits_{k=1}^K \left(n_k-1\right) S_k^2$, \\
                                            %раньше в знаменателе дроби было 3K + 1
                                            & $C = 1 + \frac1{3(K - 1)}\left(\sum\limits_{k=1}^K \frac1{n_k-1} - \frac1{N}\right)$ ; \\
                                            & $B\left(X^N\right)$ имеет табличное распределение при $H_0.$\\
        \end{tabular}
    \end{center}
    %в лагутине и кобзаре написано достаточно n_k > 3
    Аппроксимация для $n_k>6$:
    $$B\left(X^N\right)\sim\chi^2_{K-1}.$$
    }

    \only<2>{
    \textbf{Пример} (Beall, 1942): шесть видов инсектицидов тестируется на 12 полях каждый, исследуемый признак~--- количество насекомых на поле через некоторое время после обработки.


    \begin{figure}
    	\includegraphics[width=0.7\textwidth,natwidth=670,natheight=412]{./2015/insectspray.png}
    \end{figure}

    \bigskip

    $H_0 \colon$ дисперсия числа насекомых на полях, обрабатываемых разными инсектицидами, одинакова.

    $H_1 \colon$ дисперсия числа насекомых на полях, обрабатываемых разными инсектицидами, неодинакова $\Rightarrow p = 9\times10^{-5}.$
    }
\end{frame}
%Недостатком критерия Бартлетта является то, что он очень чувствителен к небольшим отклонениям распределения элементов выборок от нормального. В Лагутине есть пример, в котором при замене нормального распределения на распределение Стьюдента t7 с 7 степенями свободы, которое очень похоже на N(0,1), ошибка 1го рода даже для больших выборок вместо положенных 5% равна 49%.
%Рассмотрим ранговый критерий, который устойчив к нарушению предположения о нормальности. В работе 1981 года было проведено сравнение критерия проверки однородности дисперсий и показано, что этот критерий является самым мощным и устойчивым к отлонениям от нормальности и наличию выбросов.
%Все выборки центрируются относительно медианы, после чего объединяются в генеральную совокупность. Затем вычисляются ранги элементов каждой выборки. Эти ранги нормализуются с помощью функции Ф^{-1}, и вычисляется средний ранг для каждой выборки и средний ранг по всем объектам. Затем рассматривается отклонение среднего по каждой группе от глобального среднего. При справедливости нулевой гипотезы дисперсия с.в. в скобках в формуле статистики равна V^2. Тогда статистика равна сумме K независимых с.в. и распределена как хи-квадрат с K-1 ст.свободы (из-за оценки среднего). Если статистика принимает большие значения,  нулевая гипотеза отклоняется в пользу альтернативы.
\begin{frame}{Критерий Флайнера-Киллиана}
    \only<1>{
%    \vspace{-15pt}
    \begin{center}
        \begin{tabular}{rl}
            выборки:                        & $X^N = X_1^{n_1}\bigcup\ldots\bigcup X_K^{n_K}, \;\; X_{ki} \sim F\left(\mu_k+\sigma_kx\right);$ \\
            нулевая гипотеза:               & $H_0\colon \sigma_1 = \sigma_2 = \ldots = \sigma_K;$ \\
            альтернатива:                   & $H_1\colon H_0$ неверна;\\
            статистика:                     & $X^2\left(X^N\right) = \frac1{V^2}  \sum\limits_{k=1}^K n_k \left(\bar{A}_k - \bar{a}\right)^2,$ \\
                                            & $\bar{a} = \frac1{N} \sum\limits_{k=1}^K\sum\limits_{i=1}^{n_k} a_{ki}, \;\; \bar{A}_k = \frac1{n_k} \sum\limits_{i=1}^{n_k} a_{ki}, \;\; a_{ki} = \Phi^{-1}\left(\frac{1+\frac{r_{ki}}{N+1}}{2}\right),$ \\
                                            & $r_{ki}$~--- ранг $\left|X_{ki}-\tilde{X}_k\right|$ в объединённой выборке,\\
                                            & $\tilde{X}_k$~--- выборочная медиана $k$-й выборки, \\
                                            & $V^2 = \frac1{N-1}\sum\limits_{k=1}^K\sum\limits_{i=1}^{n_k} \left(a_{ki}-\bar{a}\right)^2;$ \\
                                            & $X^2\left(X^N\right)\approx \sim \chi^2_{K-1}$  при $H_0.$\\
        \end{tabular}
    \end{center}
	
	\bigskip
	
    \textbf{Пример} (инсектициды): $p = 0.01282.$
    }
\end{frame}

%\begin{frame}{Критерий квадратов рангов}
%	\only<1>{
%		%    \vspace{-15pt}
%		\begin{center}
%			\begin{tabular}{rl}
%				выборки:                        & $X^N = X_1^{n_1}\bigcup\ldots\bigcup X_K^{n_K}, \;\; X_{ki} \sim F\left(\mu_k+\sigma_kx\right);$ \\
%				нулевая гипотеза:               & $H_0\colon \sigma_1 = \sigma_2 = \ldots = \sigma_K;$ \\
%				альтернатива:                   & $H_1\colon H_0$ неверна;\\
%				статистика:                     & $T_2\left(X^N\right) = \frac1{D^2} \left( \sum\limits_{k=1}^K \frac{S_k^2}{n_k} - N \bar{S}^2\right),$ \\
%				& $S_k = \sum\limits_{i=1}^{n_k}  r\left(\left|X_{ki} - \bar{X}_k\right|\right)^2$, \\
%				& $\bar{S} = \frac1{N} \sum\limits_{k=1}^K S_k,$ \\
%				& $D^2 = \frac1{N-1} \left( \sum\limits_{i=1}^N r_i^4 - N \bar{S}^2 \right);$ \\
%				& $T_2\left(X^N\right)$ имеет табличное распределение при $H_0.$\\
%			\end{tabular}
%		\end{center}
%		Если нет связок, то:
%		\begin{align*}
%		\bar{S} &= \frac1{6} \left(N+1\right)\left(2N+1\right), \\
%		D^2     &= \frac1{180} N \left(N+1\right) \left(2N+1\right)\left(8N+11\right).
%		\end{align*}
%		
%		Аппроксимация для $n_k>10$:
%		$$T_2\left(X^N\right)\sim\chi^2_{K-1}.$$
%	}
%	
%	\only<2>{
%		\textbf{Пример} (вариабельность деталей): $p = 0.0856.$
%	}
%\end{frame}


\subsection{Пример}
\begin{frame}{Пример}
	Рост певцов хора:
	
	\url{https://yadi.sk/d/97dWepW7f4xKq}
\end{frame}
%
%\begin{frame}{Рост певцов хора}
%    \only<1>{
%    В 1979 году 130 участников Нью-Йоркской ассоциации хорового пения сообщили данные своего роста; для каждого известен также регистр голоса. Есть ли связь между ростом и регистром?
%
%    \bigskip
%
%    \begin{center}
%        \includegraphics[width=0.6\textwidth]{./2013-2/4/Vocal_Ranges.eps}
%    \end{center}
%    }
%
%    \only<2>{
%    \begin{center}
%        \includegraphics[width=0.85\textwidth]{./2013-2/4/choir_box.eps}
%    \end{center}
%
%    \bigskip
%
%    \begin{center}
%        \includegraphics[width=0.5\textwidth]{./2013-2/4/soprano.eps}
%    \end{center}
%    }
%
%    \only<3>{
%    $H_0\colon$ рост и регистр голоса не связаны.
%
%    $H_1\colon$ для каких-то видов регистра голоса средний рост отличается.
%
%    \bigskip
%
%     \begin{center}
%     \begin{tabular}{cccccc}
%        Source  &   SS    &  df &     MS  &      F    &    Prob>F \\ \hline
%        Groups  &  $6901.4$ &    $3$&   $2300.47$  & $55.73$  & $5.34718e-023$ \\
%        Error   &  $5201.1$ &  $126$&     $41.28$  & &\\
%        Total   & $12102.5$ &  $129$& & &        \\
%     \end{tabular}
%     \end{center}
%
%     SS~--- сумма квадратов отклонений, df~--- число степеней свободы, MS~--- средний квадрат отклонений, F~--- статистика критерия;
%
%     строка Groups~--- оценки по выборочным средним, строка Error~--- оценки по выборочным дисперсиям.
%    }
%
%    \only<4>{
%    Критерий Стьюдента для проверки гипотезы равенства роста певцов с~альтом и~сопрано: $p=0.2460$~--- против двусторонней альтернативы, $p=0.1230$~--- против односторонней альтернативы.
%
%    \bigskip
%
%    Критерий Стьюдента для проверки гипотезы равенства роста певцов с~тенором и~басом: $p=0.0597$~--- против двусторонней альтернативы, $p=0.0298$~--- против односторонней альтернативы.
%
%    \bigskip
%
%    Критерий Джонкхиера для проверки наличия тренда (увеличение роста с~понижением регистра голоса): $p<0.00001.$
%    }
%
%    \only<5>{
%    \begin{center}
%        \includegraphics[height=0.85\textheight]{./2013-2/4/hsd1.eps}
%    \end{center}
%    }
%
%    \only<6>{
%    \begin{center}
%        \includegraphics[height=0.85\textheight]{./2013-2/4/hsd2.eps}
%    \end{center}
%    }
%
%    \only<7>{
%    \begin{center}
%        \includegraphics[height=0.85\textheight]{./2013-2/4/hsd3.eps}
%    \end{center}
%    }
%
%    \only<8>{
%    \begin{center}
%        \includegraphics[height=0.85\textheight]{./2013-2/4/hsd4.eps}
%    \end{center}
%    }
%\end{frame}


\section{2-way b.s.}
\subsection{Омнибус-критерии}
\begin{frame}{Двухфакторный дисперсионный анализ}
    \only<1>{
    $f_1\colon X \rightarrow \left\{1,\ldots,K_1\right\}, \;\; f_2 \colon X \rightarrow \left\{1,\ldots,K_2\right\}$

    \bigskip

    \begin{center}
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    \backslashbox{$f_1$}{$f_2$} & $1$ & $\ldots$ & $j$ & $\ldots$ & $K_2$ \\\hline
    $1$        &&&&& \\\hline
    $\vdots$ &&&&& \\\hline
    $i$      &&&  $\footnotesize{\begin{matrix} X_{ij1} \\ \vdots \\ X_{ijn_{ij}} \end{matrix}}$ && \\\hline
    $\vdots$ &&&&& \\\hline
    $K_1$    &&&&& \\\hline
    \end{tabular}
    \end{center}

    \bigskip

    Задача: проверить гипотезу об отсутствии влияния факторов $f_1$ и $f_2$ на~среднее значение признака $X$.

    Случай выборок разного размера для двух факторов значительно сложнее, поэтому будем считать, что $n_{11} = \ldots = n_{K_1 K_2} = n$.
    }

    \only<2>{
    Линейная модель:
    $$X_{ijk} = \mu + \alpha_i + \beta_j + \gamma_{ij} + \varepsilon_{ijk}, $$

    $i=1,\ldots,K_1, \; j=1,\ldots,K_2, \; k=1,\ldots,n.$

    \bigskip

    $\mu$~--- общее среднее значение признака,

    $\alpha_i$~--- воздействие уровня $i$ фактора $f_1$,

    $\beta_j$~---  воздействие уровня $j$ фактора $f_2$,

    $\gamma_{ij}$~--- дополнительное воздействие комбинации уровней $i$ и $j$ факторов $f_1$~и~$f_2$,

    $\varepsilon_{ijk}$~--- случайные независимые одинаково распределённые ошибки.
    }

    \only<3>{
    \begin{align*}
    H_0^1\colon & \text{фактор $f_1$ не влияет на значение признака } X \Leftrightarrow \\
                & \alpha_i=0 \;\; \forall i,\\
    H_1^1\colon & f_1 \text{ влияет на значение } X;\\
    \end{align*}

    \begin{align*}
    H_0^2\colon & \text{фактор $f_2$ не влияет на значение признака } X \Leftrightarrow \\
                & \beta_j=0 \;\; \forall j, \\
    H_1^2\colon & f_2 \text{ влияет на значение } X;\\
    \end{align*}

    \begin{align*}
    H_0^{12}\colon & \text{между факторами $f_1, f_2$ нет взаимодействия} \Leftrightarrow \\
                   & \gamma_{ij}=0 \;\; \forall i,j,\\
    H_1^{12}\colon & \text{ между факторами $f_1, f_2$ есть взаимодействие.}\\
    \end{align*}
    }

    \only<4>{
    \textbf{Пример:} $X$~--- успешность решения задачи (в баллах от 0 до 10),

    $f_1$~--- размер команды (1~--- маленькая, 2~--- средняя, 3~--- большая),

    $f_2$~--- наличие назначенного лидера (1~--- нет, 2~--- есть).

    \bigskip

    \begin{center}
        \includegraphics[width=0.95\textwidth]{./2013-2/interactions.eps}
    \end{center}
    }
\end{frame}

\subsection{Параметрический вариант}
\begin{frame}{Нормальный двухфакторный дисперсионный анализ}
    \only<1>{
    %НЕТ

    Предположим, что $X_{ijk} \sim N\left(\mu_{ij}, \sigma^2\right)$ $\Leftrightarrow \varepsilon_{ijk} \sim N\left(0,\sigma^2\right)$.

    $\bar{X}_{ij}$~--- среднее в ячейке,

    $\bar{X}_{i \bullet}$~--- среднее по строке $i$,

    $\bar{X}_{\bullet j}$~--- среднее по столбцу $j$,

    $\bar{X}$~--- среднее по всей таблице.

    Внутрифакторные дисперсии:

    \begin{align*}
        S_1^2    &= \frac{nK_2}{K_1-1} \sum\limits_{i=1}^{K_1} \left(\bar{X}_{i \bullet} - \bar{X}\right)^2, \\
        S_2^2    &= \frac{nK_1}{K_2-1} \sum\limits_{i=1}^{K_2} \left(\bar{X}_{\bullet j} - \bar{X}\right)^2, \\
        S_{12}^2 &= \frac{n}{\left(K_1-1\right)\left(K_2-1\right)} \sum\limits_{i,j} \left(\bar{X}_{ij} - \bar{X}_{i \bullet} - \bar{X}_{\bullet j} + \bar{X}\right)^2, \\
        S_{res}^2&= \frac1{K_1 K_2\left(n-1\right)} \sum\limits_{k=1}^{n} \sum\limits_{i,j} \left(X_{ijk} - \bar{X}_{i j}\right)^2. \\
    \end{align*}
    }

    \only<2>{
    Проверка значимости факторов и их взаимодействия:
    \begin{itemize}
    \item $n>1$:
    \begin{align*}
        F_1    &= \frac{S_1^2}{S_{res}^2} \sim F\left(K_1-1, K_1K_2\left(n-1\right)\right) \text{ при } H_0^1, \\
        F_2    &= \frac{S_2^2}{S_{res}^2} \sim F\left(K_2-1, K_1K_2\left(n-1\right)\right) \text{ при } H_0^2, \\
        F_{12} &= \frac{S_{12}^2}{S_{res}^2} \sim F\left(\left(K_1-1\right)\left(K_2-1\right), K_1K_2\left(n-1\right)\right) \text{ при } H_0^{12}; \\
    \end{align*}
    \item $n=1$:
    \begin{align*}
        F_1    &= \frac{S_1^2}{S_{12}^2} \sim F\left(K_1-1, \left(K_1-1\right)\left(K_2-1\right) \right) \text{ при } H_0^1, \\
        F_2    &= \frac{S_2^2}{S_{12}^2} \sim F\left(K_2-1, \left(K_1-1\right)\left(K_2-1\right) \right) \text{ при } H_0^2. \\
    \end{align*}
    При этом подразумевается, что $H_0^{12}$ верна.
    \end{itemize}
    }
\end{frame}

\subsection{Примеры}
\begin{frame}{Примеры}
    \only<1>{
    \textbf{Пример 1}: изучалось воздействие марихуаны на скорость реакции. В~качестве испытуемых были выбраны по 12 человек из каждой категории:
    \begin{itemize}
    \item никогда не пробовали марихуану;
    \item иногда употребляют марихуану;
    \item регулярно употребляют марихуану.
    \end{itemize}
    Испытуемые были разделены на две равные группы; половине из них дали выкурить две сигареты с марихуаной, вторая половина выкурила две обычные сигареты с запахом и вкусом марихуаны. Сразу после этого все испытуемые прошли тест на скорость реакции.

    Требуется оценить влияние марихуаны на скорость реакции, учитывая фактор предыдущего опыта употребления.
    }

    \only<2>{
    \begin{center}
        \includegraphics[width=0.8\textwidth]{./2013-2/weed.eps}
    \end{center}
    }

    \only<3>{
    $H_0^1\colon$ средняя скорость реакции одинакова при употреблении и~марихуаны, и~сигарет.

    $H_0^2\colon$ средняя скорость реакции не зависит от предыдущего опыта употребления марихуаны.

    $H_0^{12}\colon$ отсутствует межфакторное взаимодействие между употребляемым веществом и предыдущим опытом употребления марихуаны.

    \bigskip

    \begin{center}
     \begin{tabular}{cccccc}
        Source  & SS       & df & MS      & F    & Prob>F \\ \hline
        Group   & $103041$   &   $1$&   $103041$&     $17.58$&   $0.0002$ \\
        Past use& $23634.5$  &  $2$ &   $11817.2$&    $2.02$ &  $0.1508$ \\
        Interaction &   $23642.2$ &   $2$  &  $11821.1$ &   $2.02$ &  $0.1507$ \\
        Error   & $175796.3$ &  $30$  &   $5859.9$  &      &        \\
        Total   & $326114$  &   $35$ &         &      &        \\
     \end{tabular}
     \end{center}
    }

    \only<4>{
    Вывод: гипотеза о том, что предыдущий опыт употребления не влияет на скорость реакции, не отклоняется $\Rightarrow$ данные по группам можно объединить.

     \bigskip

    Для объединённых данных:
    \begin{itemize}
    \item однофакторный дисперсионный анализ: $p=0.00036;$
    \item критерий Уилкоксона, двусторонняя альтернатива: $p=0.000596;$
    \item критерий Стьюдента, односторонняя альтернатива: $p=0.00018, \;\; ci=\left(61.3, \infty\right);$
    \end{itemize}

    \begin{center}
        \includegraphics[width=0.6\textwidth]{./2013-2/weed_cdfs.eps}
    \end{center}
    }

    \only<5>{
    \textbf{Пример 2}: витамин C и рост зубов
    	
	\url{https://yadi.sk/d/mPb2G8cqf52as}
    }
\end{frame}

\subsection{Иерархический дизайн}
\begin{frame}{Иерархический дизайн}
    Стандартная постановка двухфакторного дисперсионного анализа предполагает, что уровни факторов в выборке распределены независимо.

    \bigskip

    Пример, когда это не так:

    признак --- уровень гликогена в икроножной мышце крысы,

    фактор~1~--- уровень стресса крыс,

    фактор~2~--- различия между клетками.

    Крысы со стрессом живут в клетках~1~и~2, без стресса --- 3~и~4.

    \bigskip

    Решение --- иерархический дисперсионный анализ.
\end{frame}

\begin{frame}
    \frametitle{CBI чернобрюхой дрозофилы}
    \only<1>{
    Codon bias index (CBI) --- мера случайности использования синонимичных кодонов в геноме --- была определена для нескольких регионов двух хромосом чернобрюхой дрозофилы.
    Требуется определить, есть ли систематические различия по величине CBI между разными хромосомами и регионами.

    \bigskip

    \begin{center}
        \includegraphics[height=0.6\textheight]{./2013-2/fly.eps}
    \end{center}
    }

    \only<2>{
    \begin{center}
     \begin{tabular}{cccccc}
        Source            & SS       & df & MS      & F    & Prob>F \\ \hline
        Chromosome        & 0.00496  &  2 & 0.00248 & 0.32 & 0.7319 \\
        Region(Chromosome)& 0.16295  &  3 & 0.05432 & 6.92 & 0.0011 \\
        Error             & 0.23564  & 30 & 0.00785 &      &        \\
        Total             & 0.40891  & 35 &         &      &        \\
     \end{tabular}
     \end{center}

     Есть различия между регионами, нет различий между хромосомами.
    }

    \only<3>{
     Для  уточнения различий применим метод HSD:
    \begin{center}
     \begin{tabular}{ccccc}
     Группа 1 & Группа 2 & $CI_L$ & mean   & $CI_U$ \\\hline
     7D       & 93C      & -0.1485& 0.0093 & 0.1672\\
     7D       & 49E      & -0.0847& 0.0732 & 0.2310\\
     7D       & 41F      & -0.0161& 0.1417 & 0.2996\\
     7D       & 1A       &  0.0181& 0.1886 & 0.3591\\ %!
     7D       & 66D      & -0.0207& 0.1498 & 0.3203\\
     93C      & 49E      & -0.0802& 0.0639 & 0.2079\\
     93C      & 41F      & -0.0117& 0.1324 & 0.2765\\
     93C      & 1A       &  0.0214& 0.1793 & 0.3371\\ %!
     93C      & 66D      & -0.0174& 0.1405 & 0.2983\\
     49E      & 41F      & -0.0755& 0.0686 & 0.2127\\
     49E      & 1A       & -0.0424& 0.1154 & 0.2733\\
     49E      & 66D      & -0.0812& 0.0766 & 0.2345\\
     41F      & 1A       & -0.1110& 0.0469 & 0.2047\\
     41F      & 66D      & -0.1498& 0.0081 & 0.1659\\
     1A       & 66D      & -0.2093&-0.0388 & 0.1317\\
     \end{tabular}
     \end{center}
    }

    \only<4>{
    \begin{center}
        \includegraphics[width=0.9\textwidth]{./2013-2/hsd_fly1.eps}
    \end{center}
    }
     \only<5>{
    \begin{center}
        \includegraphics[width=0.9\textwidth]{./2013-2/hsd_fly2.eps}
    \end{center}
    }
     \only<6>{
    \begin{center}
        \includegraphics[width=0.9\textwidth]{./2013-2/hsd_fly3.eps}
    \end{center}
    }
     \only<7>{
    \begin{center}
        \includegraphics[width=0.9\textwidth]{./2013-2/hsd_fly4.eps}
    \end{center}
    }
     \only<8>{
    \begin{center}
        \includegraphics[width=0.9\textwidth]{./2013-2/hsd_fly5.eps}
    \end{center}
    }
     \only<9>{
    \begin{center}
        \includegraphics[width=0.9\textwidth]{./2013-2/hsd_fly6.eps}
    \end{center}
    }
\end{frame}

\subsection{Болтающийся контроль}
\begin{frame}
	\frametitle{Болтающаяся контрольная группа}

    \begin{center}
	\begin{tabular}{|c|c|c|c|}
		\cline{1-3}
		\backslashbox{Лекарство}{Доза}  & 5 мг & 10 мг &  \multicolumn{1}{c}{} \\ \cline{1-3}
							Препарат А  &      &       &  \multicolumn{1}{c}{} \\ \cline{1-3}
							Препарат B  &      &       &  \multicolumn{1}{c}{} \\ \hline
						   \multicolumn{3}{c|}{}        &  Плацебо, 0 мг       \\ \cline{4-4}
	\end{tabular}
    \end{center}	
	
	\bigskip
	
	Используется однофакторный дисперсионный анализ с последующими запланированными сравнениями.	
\end{frame}

\section{3-way b.s.}
\subsection{Пример}
\begin{frame}{Пример}
	Лечение гипертонии:
	
	\url{https://yadi.sk/d/nHJk7_C4fGW38}
	
%    \only<1>{
%    72 пациента проходили лечение от гипертонии. Для лечения использовались три вида лекарств, при этом их эффект изучался как при использовании специальной диеты, так и в её отсутствии; кроме того, в~ряде случаев применялась психотерапия. Данные~--- артериальное давление пациента по окончании лечения.
%
%    Требуется сравнить эффективность методов для лечения гипертонии.
%
%    \bigskip
%
%    Дизайн $[3\times2\times2].$
%    }
%
%    \only<2>{
%    Трёхфакторный дисперсионный анализ, все взаимодействия:
%
%    \bigskip
%
%    \begin{center}
%    \begin{tabular}{cccccc}
%    Source            & SS      & df  & MS       & F       & Prob>F  \\ \hline
%    Therapy           & $2048$  & $1$ & $2048$   & $13.07$ & $0.0006$\\
%    Diet              & $5202$  & $1$ & $5202$   & $33.2$  & $3\times10^{-7}$     \\
%    Drug              & $3675$  & $2$ & $1837.5$ & $11.73$ & $0.0001$\\
%    Therapy*Diet      & $32$    & $1$ & $32$     & $0.2$   & $0.6529$\\
%    Therapy*Drug      & $259$   & $2$ & $129.5$  & $0.83$  & $0.4425$\\
%    Diet*Drug         & $903$   & $2$ & $451.5$  & $2.88$  & $0.0638$\\
%    Therapy*Diet*Drug & $1075$  & $2$ & $537.5$  & $3.43$  & $0.0388$\\
%    Error             & $9400$  & $60$& $156.67$ &         &         \\
%    \end{tabular}
%    \end{center}
%
%	Воздействие одного из факторов различно при различных комбинациях двух других.
%	Хотя эффект Therapy*Drug незначим в целом, значимость Therapy*Diet*Drug говорит о том, что влияние Therapy*Drug необходимо оценивать отдельно для пациентов, использующих и не использующих диету.
%    }
%
%    \only<3>{
%    	\begin{itemize}
%    		\item Для пациентов, соблюдающих диету:
%    \begin{center}
%    	\begin{tabular}{cccccc}
%    		Source            & SS      & df  & MS      & F       & Prob>F  \\ \hline
%    		Therapy           & $784$   & $1$ & $784.0$ & $4.436$ & $0.0437$\\
%    		Drug              & $474$   & $2$ & $237.0$ & $1.341$ & $0.2768$\\
%    		Therapy*Drug      & $182$   & $2$ & $91.0$  & $0.515$ & $0.6027$\\
%    		Error             & $5302$  & $30$& $176.7$ &         &         \\
%    	\end{tabular}
%    \end{center}    		
%    		
%    		
%    		\item
%    	\end{itemize}
%    }
\end{frame}

%%%%%%%%%%%%%%%%%
%Теперь рассмотрим случай, когда данные представляют собой K-кратные повторные наблюдения, K>=2
%В каждом из n блоков содержится по одному наблюдению x_{ki} на каждую из k обработок. Будем считать наблюдения
%реализацией случайных величин X_{ki} в линейной модели..., где mu - неизвестное общее среднее, beta_i - эффект блока i (неизвестный мешающий параметр), alpha_k - эффект обработки k (интересующий нас параметр), eps_{ki} - случайные ошибки.
% Пусть справедливы те же предположения, что и в случае независимых выборок: все ошибки независимы и имеют одинаковое непрерывное (неизвестное) распределение.

\section{1-way w.s.}
\subsection{Омнибус-критерии}
\begin{frame}{Однофакторный дисперсионный анализ для связанных выборок}
    \begin{center}
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    \backslashbox{Объект}{$f$} & $1$      & $\ldots$ & $k$      & $\ldots$ & $K$      \\ \hline
    1                           & $X_{11}$ &          & $X_{k1}$ &          & $X_{K1}$ \\ \hline
    $\vdots$                    & $\vdots$ & $\cdots$ & $\vdots$ & $\cdots$ & $\vdots$ \\ \hline
    $n$                         & $X_{1n}$ &          & $X_{kn}$ &          & $X_{Kn}$ \\ \hline
    \end{tabular}
    \end{center}

    \bigskip

    Линейная модель:
    $$X_{ki} = \mu + \alpha_k + \beta_i + \varepsilon_{ki},$$
    $i=1,\dots,n, \; k=1,\dots,K.$

    \bigskip

    $\mu$~--- глобальное среднее значение признака $X$,

	$\beta_i$~--- отклонение от $\mu$, вызванное влиянием особенностей $i$-го объекта,

    $\alpha_k$~--- отклонение от $\mu+\beta_i$, вызванное влиянием $k$-го уровня фактора $f$,

    $\varepsilon_{ki}$~--- случайные независимые одинаково распределённые ошибки.

    \bigskip

    Средние значения $X$ во всех $K$ выборках одинаковы $\Leftrightarrow$ $\alpha_1=\dots=\alpha_K$.
\end{frame}

\begin{frame}{Критерий Фишера}
    \only<1>{\small
    \begin{center}
        \begin{tabular}{rl}
            выборки:                        & $X^N = X_1^{n_1}\bigcup\ldots\bigcup X_K^{n_K};$ \\
            нулевая гипотеза:               & $H_0\colon \alpha_1 = \alpha_2 = \ldots = \alpha_K;$ \\
            альтернатива:                   & $H_1\colon H_0$ неверна;\\
            статистика:                     & $F\left(X^N\right) = \frac{SS_{bg}/ \left(K-1\right)}{\left(SS_{wg}-SS_{s}\right) / \left(n-1\right)\left(K-1\right)},$ \\
                                            & $SS_{bg} = n \sum\limits_{k=1}^K \left(\bar{X}_k - \bar{X}\right)^2,$ \\
                                            & $SS_{wg} =   \sum\limits_{k=1}^K \sum\limits_{i=1}^{n} \left(X_{ki} - \bar{X}_k\right)^2,$ \\
                                            & $SS_{s}  = K \sum\limits_{i=1}^n \left(\bar{X}_{i} - \bar{X}\right)^2$; \\
                                            & $F\left(X^N\right) \sim F(K-1, (n-1)(K-1))$ при $H_0.$\\
        \end{tabular}
        \includegraphics[width=\textwidth]{./2013-2/fish.eps}
    \end{center}
    }

    \only<2>{
    Предположения метода:
    \begin{enumerate}
    \item выборочные распределения средних значений признака во всех группах нормальны;
    \item для фактора с более чем двумя уровнями: попарные разности признака имеют одинаковую дисперсию для любых уровней фактора (сферичность);
    \item объекты независимы.
    \end{enumerate}

    \bigskip

    Предположение сферичности на практике нарушается наиболее часто, причём это может привести к росту вероятности ошибки первого рода.

    Проверить гипотезу сферичности можно с помощью критерия Маухли, если она отвергается, используются модификации числа степеней свободы критерия Фишера.
    }

    \only<3>{
    \textbf{Пример} (Pearson, 2003): исследовалось влияние метилфенидата на~способность к~отсрочке удовольствия умственно отсталыми детьми с~синдромом дефицита внимания и гиперактивности. Каждый испытуемый принимал либо препарат в одной из трёх дозировок, либо плацебо, после чего проходил тест.

    \bigskip

    $H_0 \colon$ препарат не влияет на среднюю способность к отсрочке удовольствия.

    $H_1 \colon$ препарат влияет на среднюю способность к отсрочке удовольствия $\Rightarrow p = 0.004.$
    }
\end{frame}

%%%%
%Рассмотрим ранговый критерий Фридмана, преимущество которого состоит в отсутствии каких-либо предположений о распределении данных.
%1. Отдельно для каждого i-го блока (строки таблицы) ранжируем K наблюдений внутри него от меньшего к большему. Обозначим через r_{ki} ранг элемента X_{ki} в совместной ранжировке X_{1i}...X_{Ki}.
%Для k = 1 ...K положим R_k = .... - средний ранг по всем n блокам наблюдений, относящихся к k-му уровню фактора(k-ой обработке, столбцу таблицы). Рассчитаем средний ранг по всей таблице - для каждой строки одно и то же значение.
%В качестве статистики Фридмана возьмем среднеквадратичное отклонение рангов по строкам от среднего. Если гипотеза H0 верна,
%то все значения R_k должны быть близки к среднему. Если же верна альтернатива, то некоторые слагаемые окажутся больше других, что приведет к бОльшим значениям S.
%Табличное распределение получается из предположения, что все (k!)^n ранговые наборы равновероятны.
%Если среди значений в одной строке есть одинаковые значения, то следует вычислять средние ранги, а затем в знаменателе  статистики добавить поправку, формула которой дана в Лагутине.
%Если гипотеза H0 верна, то статистика сходится по распределению при n->\infty к хи-квадрат. Но для небольших выборок это приближение оказывается грубым. Рекомендуют использовать другую поправку, подробнее об этом можно почитать в Лагутине.
\begin{frame}{Критерий Фридмана}
    \only<1>{
    \begin{center}
        \begin{tabular}{rl}
            выборки:                         & $X_{ki} = \mu + \alpha_k + \beta_i + \varepsilon_{ki}, \;\;i=1,\dots,n, \; k=1,\dots,K;$ \\
            нулевая гипотеза:           & $H_0\colon \alpha_1=\ldots=\alpha_K;$ \\
            альтернатива:                 & $H_1\colon H_0$ неверна;\\
            статистика:                     & {$\!\begin{aligned}
            											S\left(X\right) &= \frac{12n}{K\left(K+1\right)} \sum\limits_{k=1}^{K} R_k^2 - 3n\left(K-1\right) = \\
            											                      &= \frac{12n}{K(K + 1)} \sum\limits_{k = 1}^{K}(R_k - \bar{R})^2,
            								             \end{aligned}$} \\
                                            	     & $R_k = \frac{1}{n}\sum\limits_{i=1}^{n} r_{ki}, \, \, \, \bar{R} = \frac{1}{K}\sum\limits_{k = 1}^K R_k = \frac{K + 1}{2}$\\
                                                   & $r_{ki}$~--- ранг $k$-го элемента в $i$-й строке;\\
                                                   & $S\left(X\right)$ имеет табличное распределение при $H_0.$\\

        \end{tabular}
    \end{center}
    Распространённая аппроксимация для $n>15, K>10$:
    $$S\left(X\right) \sim \chi^2_{K-1}.$$
    Более точная аппроксимация:
    $$\frac{\left(n-1\right)S\left(X\right)}{n\left(K-1\right)-S\left(X\right)} \sim F\left(n-1, \left(n-1\right)\left(K-1\right) \right).$$
    }

    \only<2>{
    \textbf{Пример:} исследуется 5~технологий вытачивания детали. Каждый из~15~рабочих в течение нескольких смен использовал каждую из~технологий. $X_{ki}$~--- производительность $i$-го рабочего при использовании $k$-й~технологии.

    \bigskip

    $H_0 \colon$ выбор технологии не меняет производительности рабочих.

    $H_1 \colon$ выбор технологии влияет на производительность рабочих $\Rightarrow p = 0.356.$
    }
\end{frame}
%%%%%
%Нередко условия эксперимента таковы, что обработки упорядочены естественным образом, например, по интенсивности стимулов, сложности заданий и т.п. Хочется использовать эту информацию о предполагаемой упорядоченности. Для этого применяется критерий Пейджа. В отличие от него, в критерии Фридмана статистика S принимает одно и то же значение для всех K! перенумераций уровней фактора.
%Для проверки нулевой гипотезы против альтернативы возрастания эффектов уровней фактора, где хотя бы одно неравенство строгое, вычисляется статистика Пейджа, где ранги элементов получены как и в критерии Фридмана, после упорядочивания элементов по строкам.
%Табличное распределение получается из предположения, что все (k!)^n ранговые наборы равновероятны.
%Если имеются связки, нужно использовать средние ранги.
\begin{frame}{Критерий Пейджа}
    \only<1>{
    \begin{center}
        \begin{tabular}{rl}
            выборки:                        & $X_{ki} = \mu + \alpha_k + \beta_i + \varepsilon_{ki}, \;\;i=1,\dots,n, \; k=1,\dots,K;$ \\
            нулевая гипотеза:               & $H_0\colon \alpha_1=\ldots=\alpha_{K};$ \\
            альтернатива:                   & $H_1\colon \alpha_1\leq\ldots\leq\alpha_{K}; \, \exists i \, \alpha_i < \alpha{i + 1}$\\
            статистика:                     & $L\left(X\right) = \sum\limits_{k=1}^{K} kR_k,$\\
                                            & $R_k = \sum\limits_{i=1}^{n} r_{ki},$\\
                                            & $r_{ki}$~--- ранг $k$-го элемента в $i$-й строке;\\
                                            & $L\left(X\right)$ имеет табличное распределение при $H_0.$\\
        \end{tabular}
    \end{center}

    \bigskip

    Аппроксимация для $n>15, K>10$:
    $$ L\left(X\right) \sim N\left(\frac{nK\left(K+1\right)^2}{4}, \frac{n\left(K^3 - K\right)^2}{144\left(K-1\right)}\right).$$
    }

    \only<2>{
    \textbf{Пример:} на $20$ полях тестируется $5$ доз калийных удобрений. Каждое поле поделено на $5$ участков, по одному на каждую дозу. Измерена прочность выращенного на каждом участке хлопка.

    \bigskip

    $H_0 \colon$ дозировка удобрений не влияет на прочность хлопка.

    $H_1 \colon$ дозировка удобрений влияет на прочность хлопка $\Rightarrow p = 0.126.$

    $H_1 \colon$ с ростом дозировки удобрений прочность хлопка увеличивается $\Rightarrow p = 0.046.$
    }
\end{frame}

\begin{frame}{Пример}
	Выведение нейролептиков у шизофреников (для самостоятельной работы):
	
	\url{https://yadi.sk/i/C-F91VFApY5D9}
\end{frame}


\section{}
\begin{frame}{Литература}
    \only<1>{
    \begin{itemize}
    \item разновидности ANOVA~--- Tabachnick, 3.2;
%    \item применение в R~--- Chang, \burl{http://www.cookbook-r.com/Statistical_analysis/ANOVA/};
%    \item проверка однородности дисперсии в R: \burl{http://www.cookbook-r.com/Statistical_analysis/Homogeneity_of_variance/};
    \item unbalanced two-way ANOVA~--- Tabachnik, 6;
    \item критерии Краскела-Уоллиса (Kruskal–Wallis) и Джонкхиера (Jonckheere)~--- Кобзарь, 4.2.1.2.1, 4.2.1.2.9;
    \item критерий Флайнера-Киллиана~--- Conover, 1981.
    \item критерии Фридмана (Friedman) и Пейджа (Page)~--- Лагутин, гл. 17;
    \item перестановочные аналоги~--- Bonnini, гл. 3, 4;
    \item критерий Маухли (Mauchly's sphericity test), поправки при отсутствии сферичности (Huynh-Feldt, Greenhouse-Geisser, lower-bound)~--- \url{http://en.wikipedia.org/wiki/Mauchly's_sphericity_test};
    \item profile analysis~--- альтернатива w.s. ANOVA~--- Davis;
	\item \textbf{примеры проведения дисперсионного анализа в R:}
	
		\href{http://www.uni-kiel.de/psychologie/rexrepos/posts/anovaCRp.html}{1-way b.s.},
	    \href{http://www.uni-kiel.de/psychologie/rexrepos/posts/anovaCRFpq.html}{2-way b.s.},
	    \href{http://www.uni-kiel.de/psychologie/rexrepos/posts/anovaRBp.html}{1-way w.s.},
	    \href{http://www.uni-kiel.de/psychologie/rexrepos/posts/anovaRBFpq.html}{2-way w.s.}
    \end{itemize}
	}
	
	\only<2>{
	
    {\small
     Лагутин М.Б. \textit{Наглядная математическая статистика}. — Москва: Бином, 2007.
		
		\vspace{5pt}
		
     Кобзарь А.И. \textit{Прикладная математическая статистика}. — Москва: Физматлит, 2006.
		
		\vspace{5pt}
		
     Beall G. (1942). \textit{The Transformation of data from entomological field experiments}. Biometrika, 29, 243–262.
		
		\vspace{5pt}
		
	 Bonnini S., Corain L., Marozzi M., Salmaso S. \textit{Nonparametric Hypothesis Testing - Rank and Permutation Methods with Applications in R}. John Wiley \& Sons, 2014.
		
		\vspace{5pt}
		Conover W.\,J., Johnson M.\,E., Johnson M.\,M. (1981) \textit{A comparative study of tests for homogeneity of variances, with applications to the outer continental shelf bidding data}. Technometrics 23, 351--361.
		\vspace{5pt}
		
     Davis C.S. \textit{Statistical Methods for the Analysis of Repeated Measurements}. — New York: Springer-Verlag, 2002.
		
		\vspace{5pt}
		
     Pearson D.A, Santos C.W., Casat C.D., et al. (2004). \textit{Treatment effects of methylphenidate on cognitive functioning in children with mental retardation and ADHD}. Journal of the American Academy of Child and Adolescent Psychiatry, 43(6), 677–685.
		
		\vspace{5pt}
		
     Tabachnick B.G., Fidell L.S. \textit{Using Multivariate Statistics}. — Boston: Pearson Education, 2012.

%     Wilcox R.R. \textit{Introduction to Robust Estimation and Hypothesis Testing}. — Academic Press, 2012.
    }
	}
\end{frame}
\end{document}
