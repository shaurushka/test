\documentclass[twoside, 12pt]{article}
\usepackage{jmlda}
\newcommand{\hdir}{.}
\setcounter{page}{1796}
%\NOREVIEWERNOTES
\title
    [Минимизация признакового пространства распознавания трехмерного изображения] % Краткое название; не нужно, если полное название влезает в~колонтитул
    {Минимизация признакового пространства распознавания трехмерного изображения на основе стохастической геометрии и функционального анализа}
\author
    %[Федотов~Н.\,Г., Семов~А.\,А., Моисеев~А.\,В.]% список авторов для колонтитула; не нужен, если основной список влезает в колонтитул
    {Н.\,Г. Федотов, А.\,А. Семов, А.\,В. Моисеев} % основной список авторов, выводимый в оглавление
    [Н.\,Г. Федотов$^1$, А.\,А. Семов$^1$, А.\,В. Моисеев$^2$] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\thanks
    {Работа выполнена при финансовой поддержке РФФИ, проект \No\,15-07-04484.}
\email
    {fedotov@pnzgu.ru, mathematik\_aleksey@mail.ru, moigus@mail.ru}
\organization
    {$^1$Пензенский государственный университет, ул.~Красная,~40, г.~Пенза, Россия\par
$^2$Пензенский государственный технологический университет,\par
проезд~Байдукова/ул.~Гагарина, 1,~а/11, г.~Пенза, Россия}
\abstract
    {Предложен новый подход к распознаванию трехмерных (3D) изображений,
осно\-ван\-ный на современных методах стохастической геометрии
и~функционального анализа. Данный метод обладает рядом преимуществ,
в~частности позволяет описывать метрические свойства 3D объектов. Так, благодаря построению строгой математической модели аналитик может строить признаки не интуитивно, а аналитически, описывая форму  объектов и их особенности (в частности, конструирование геометрических признаков).
           %
Ги\-пер\-трейс-пре\-об\-ра\-зо\-ва\-ние позволяет создавать инвариантное описание пространственного объекта, которое является более устойчивым к искажениям и координатным шумам, чем описание, получаемое в результате процедуры нормализации объекта. Достоверность и~эффективность предлагаемого метода подтверждается как адекватно построенной математической моделью с применением современных подходов анализа и распознавания 3D изображений, так и результатами практических экспериментов, а~также регистрацией разработанного программного пакета.
            %
Дано подробное описание техники сканирования ги\-пер\-трейс-пре\-об\-ра\-зо\-ва\-ния и его
математической модели. Проанализированы основные подходы к~построению и выделению
информативных признаков. Предложена собственная методика минимизации
признакового пространства и соответствующая ей решающая процедура. Приведены результаты практического эксперимента сравнения стохастического и детерминированного способов сканирования.


\bigskip
\noindent
\textbf{Ключевые слова}: \emph {3D распознавание образов;
гипертрейс-преобразование; композиционная структура признака;
минимизация признакового пространства; инвариантное описание;
стохастический способ сканирования}}
\titleEng
    {Feature space minimization of~three-dimensional~image~recognition based~on~stochastic~geometry and~functional analysis}
\authorEng
    {N.\,G. Fedotov$^1$, A.\,A. Syemov$^1$, and A.\,V. Moiseev$^2$}
\organizationEng
    {$^1$Penza State University, Penza, Russia\par $^2$Penza State Technological University, Penza, Russia}
\abstractEng
    {
		\noindent
		\textbf{Background}: In recent decades, the emphasis in the
analysis and pattern recognition shifts from two-dimensional to
three-dimensional (3D) images, because 3D design allows to use more information
about the object. Three-dimensional modeling gives possibility to see object from different angles, in particular, allows to analyze its spatial form.	
		
		\noindent
		\textbf{Methods}: A new approach to the 3D objects’ recognition based on modern methods of stochastic geometry and functional analysis is proposed. This method has many advantages; in particular, it allows to describe 3D objects metric properties.
Thus, due to building a~rigorous mathematical model, the analyst can construct analytical and not intuitive features, describing object form and their characteristics (in particular, constructing geometric features).
		
		\noindent
		\textbf{Results}: Hypertrace transform allows to create
invariant description of spatial object, which is more resistant to distortion
and coordinate noise than the description obtained as a result of the object
normalization procedure. The proposed method reliability and efficiency are
confirmed both an adequate constructed mathematical model by using modern
approaches of 3D images analysis and recognition and practical experiments
results and also the developed software package registration.
		
		\noindent
		\textbf{Concluding Remarks}: Detailed description of hypertrace transform scan technique and its mathematical model is provided. The main approaches to construct and distinguish informative features are analyzed. Own method to minimize the feature space and its appropriate decision procedure are proposed. The practical experiment results of comparing
stochastic and deterministic scan methods are presented.
		
    \noindent
    \textbf{Keywords}: \emph{3D image recognition; hypertrace transform;
compositional structure of feature; feature space minimization;
invariant description; stochastic scan method}}
\begin{document}
\maketitle
%\linenumbers
\section{Введение}
Одной из проблем распознавания образов является выработка решающей процедуры
для различия одних изображений от других \cite{1, 2}. Определение наиболее
оптимального решающего правила осуществляется на основе априорной информации
и~обучающей выборки. При этом существуют два подхода к формированию словаря
признаков. Первый подход предполагает, что алфавит классов и словарь признаков
заранее предопределены и имеют четкую детерминированную структуру. Второй же
подход использует методы динамического обучения словаря, наиболее активно
развивавшиеся в последние 15~лет~\cite{4, 3}. Так, динамическое обучение
словаря может формироваться непосредственно на обуча\-ющей выборке и может,
например, значительно улучшить качество удаления шума с~по\-мощью разреженного представления изображения.

Однако предположение о полной определенности словаря признаков (первый подход) еще до распознавания изображения не вполне верно. Большие базы изображений содержат огромное количество разнообразных классов объектов, каждый из которых обладает своими собственными значимыми характеристиками и особенностями. А потому одни классы будут хорошо различаться по некоторому признаку, а другие классы --- нет.

Достоинства и недостатки построения оптимальных признаков на основе априорной
информации и обучающей выборке (второй подход) отмечаются, в частности,
в~работе~\cite{5}. Чем удачнее выбраны признаки, тем компактнее образы
и~успешнее решается задача обуче\-ния. Однако если признаки заранее не заданы
или выбираются случайно и неудачно, то любой метод может потерять работоспособность
и~снизится качество распознавания. Тем не менее второй подход является более перспективным, чем первый.

Таким образом, формирование информативных числовых признаков по классам и~учет
их различной различающей способности (весов) для разных типов объектов являются
не менее важной и трудной задачей \cite{6}, чем разработка решающей процедуры,
и~могут тоже заметно повысить надежность распознавания.

Для современного этапа развития теории распознавания образов актуально расширение круга рассматриваемых задач распознавания на 3D изображения, в то время как ранее внимание исследователей было сосредоточено на решении задач анализа и распознавания
двумерных (2D) изображений.

Проблема распознавания конкретно 3D изображений имеет много
различных аспектов~\cite{7,8}: проблемы анализа сцены (в том числе
проблемы положения, ориентации и освещения объекта), проблемы понимания
изображения, проблемы машинного зрения, а также собственно проблемы
распознавания и классификации пространственных объектов на 3D изображении.

В данной статье предлагается новый подход к конструированию признаков
3D изображения на основе стохастической геометрии, дающие инвариантное описание объекта при любой его пространственной ориентации --- гипертрейс-преобразование. Благодаря композиционной структуре функционалов, входящих в структуру признака, возможно построение большого числа признаков 3D изображений и применение простого решающего правила для отнесения объекта к тому или иному классу.


\section{Проблема инвариантности описания трехмерного изображения}

Наличие произвольной пространственной ориентации 3D изображения сильно
осложняет создание его инвариантного описания. В отличие от 2D случая,
поворот пространственного изображения возможен в трех плоскостях, которые
являются взаимозависимыми друг от друга~\cite{9}. Так, любое вращение
в~3D пространстве может быть представлено в~виде композиции поворотов вокруг трех ортогональных декартовых осей, которые задаются матрицами поворота:
\[
{\mathbf {M} }_{x}(\alpha)=\left(\begin{array}{ccc} {1} & {0} & {0} \\ {0} & {\cos \alpha } & {\sin \alpha } \\ {0} & {-\sin \alpha } & {\cos \alpha } \end{array}\right);
\]
\[{\mathbf {M} }_{y} (\beta)=\left(\begin{array}{ccc} {\cos \beta } & {0} & {\sin \beta } \\ {0} & {1} & {0} \\ {-\sin \beta } & {0} & {\cos \beta } \end{array}\right);
\]
\[ {\mathbf {M} }_{z} (\gamma)=\left(\begin{array}{ccc} {\cos \gamma } & {\sin \gamma } & {0} \\ {-\sin \gamma } & {\cos \gamma } & {0} \\ {0} & {0} & {1} \end{array}\right).
\]

Так как матрицы поворота не обладают свойством коммутативности, то перемена матриц местами изменит положение объекта с одного на другое. В общем случае ориентация пространственного объекта, получаемая в результате последовательности конечных поворотов, зависит от порядка выполнения этих поворотов.

Таким образом, необходимо разработать такую схему сканирования 3D изображения,
чтобы результаты его сканирования не зависели бы от пространственной ориентации
анализируемого объекта. Пусть $F$~--- исходная 3D модель. Определим плоскость
$B(\eta,r)=\{x|x^{\mathrm{T}} \eta=r\}$ как касательную к сфере c~центром
в~начале координат и~с~радиусом~$r$ в~точке
$(\eta,r)$, где $\eta=[\cos \phi\cdot \sin \omega,\sin \phi\cdot \sin \omega,
\cos \omega]$~--- единичный вектор в~$R^3$, а~$r$, $\omega$ и~$\phi$~--- сферические координаты.

Чтобы схема сканирования 3D изображения не была привязана к форме
анализируемого объекта и его пространственной ориентации, необходимо
и~достаточно, чтобы при произвольном 3D повороте 3D изображения получаемые плоскостями сечения не изменяли формы. Другими словами, необходимо добиться, чтобы при пространственном повороте 3D изображения все сканирующие сетки параллельных плоскостей под разными углами обзора $\omega $ и $\varphi $ совпадали бы друг с другом.

Стандартный перебор всех пар углов $\omega $ и $\varphi $, которыми
определяется каждая ска\-ни\-ру\-ющая сетка параллельных плоскостей,
в~топологическом смысле для непрерывного случая дает модель концентрических
сфер с~центром в~начале координат. Каждой ска\-ни\-ру\-ющей сетке параллельных плоскостей на единичной сфере сопоставим точку, которая будет являться точкой касания со сферой плоскости, параллельной плоскостям данной сетки. Множество точек на сфере образуют опорную сетку (рис.~\ref{fg:Fed1}).


\begin{figure}
\begin{center}
\includegraphics[bb=0mm 0mm 208mm 296mm, width=78.8mm, height=67.9mm, viewport=3mm 4mm 205mm 292mm]{Fed_image3.eps}
\end{center}
\vspace*{-6pt}
\caption{Опорная сетка на сфере и соответствующие ей сетки сканирующих параллельных плоскостей}
\label{fg:Fed1}
\end{figure}

Стоит отметить, что пара углов $(\omega,\varphi)$ однозначно определяет узел
опорной сетки, соответствующий единственной касательной плоскости и~сетке
сканирующих параллельных плоскостей. Если при повороте сферы вокруг своего
центра опорная сетка перейдет сама в~себя, то соответствующие сетки
сканирующих плоскостей полностью совпадут друг с~другом и~получаемые сечения не изменят своей формы, поэтому вычисляемое значение признака не изменится.

Таким образом, необходимо построить опорную сетку, обладающую равномерным распределением точек на сфере, чтобы плотность плоскостей в пространстве была также равномерной для достижения наименьшей ошибки совмещении узлов опорной сетки при повороте.
%
Равномерное распределение точек опорной сетки на сфере обеспечит отсутствие более плотных скоплений узлов на поверхности сферы в тех или иных местах, определяющих преимущественно сечения под теми или иными углами обзора. Таким образом, в~общем случае при занесении результатов сканирования в матрицу (подробное описание матрицы будет дано ниже) все ее элементы будут принимать равноправное участие при вычислении значения признака 3D изображения без повышения доли влияния определенных значений элементов матрицы, так как частота появления любого элемента матрицы приблизительно одинакова (равномерный обзор
3D тела со всех сторон). Другими словами, значение вычисляемого признака не будет зависеть от ориентации 3D изображения в пространстве и~будет иметь небольшое колебаний значений из-за дискретной сетки на сфере. Наибольшие отклонения будут наблюдаться тогда, когда узлы повернутой сетки будут лежать между узлами исходной сетки.

\section{Математическая модель и техника сканирования гипертрейс-преобразования}

Сканирование исходного пространственного объекта $F$ осуществляется сеткой
параллельных плоскостей с расстоянием $\Delta r$ между плоскостями
и~заданными углами~$\omega $ и~$\varphi$ (см.\ рис.~\ref{fg:Fed1}).
Взаимное положение 3D объекта $F$ и~каж\-дой сканирующей плос\-кости
$B(\eta(\omega,\phi),r)$ характеризуется числом $G$ по некоторому правилу
$\mathrm{HyperT}: G=\mathrm{HyperT}\left(F\bigcap B\left(\eta (\omega ,\varphi),
r\right)\right)$. В~качестве указанной характеристики могут выступать \mbox{число}
пересечений плоскости с исходным объектом, площадь сечения или свойства
окрест\-ности такого сечения и~т.\,п. Другими словами, функционал HyperT
характеризует свойство признака сечения \cite{10} (рис.~\ref{fg:Fed2}).
\begin{figure}[h]
  \subfloat[Одно из сечений 3D объекта]{
  \includegraphics[bb=0mm 0mm 208mm 296mm, width=64.7mm, height=56.9mm, viewport=3mm 4mm 205mm 292mm width=0.5\textwidth]{Fed_image2.eps}}
  \subfloat[Процесс сканирования 3D объекта плоскостями]{
  \includegraphics[bb=0mm 0mm 208mm 296mm, width=102.7mm, height=56.5mm, viewport=3mm 4mm 205mm 292mm width=0.5\textwidth]{Fed_image1.eps}
  }\\
\caption{Особенности сканирования 3D объекта }
\label{fg:Fed2}
\end{figure}

Сканирование сеткой параллельных плоскостей повторяется для каждого нового значения угла обзора, определяемого выражениями $\omega +\Delta\omega$ и $\varphi+\Delta\varphi$, с тем же шагом $\Delta r$ между сканирующими плоскостями. Углы $\omega $ и $\varphi $ меняются согласно узлам опорной сетки.

Результат вычислений HyperT функционала зависит от трех параметров плос\-кости
($r,\omega, \varphi$). Поэтому если каждой 2D фигуре, полученной при сечении
исходной 3D модели сканирующей плоскостью, сопоставить некоторый информативный
признак $\Pi \left(F_{\mathrm{sect}} \right)$ по правилу HyperT,
то при численном анализе результат ги\-пер\-трейс-пре\-обра\-зо\-ва\-ния
удобно представить в~виде 3D гипертрейс-матрицы~3TM, у~которой ось~$0\varphi$
направлена горизонтально, ось~$0\omega$~--- вертикально, ось~$0r$~--- вглубь.

Каждая глубинная строка матрицы содержит элементы-признаки, вычисляемые по фигурам, которые получены в результате пересечения сканирующих плоскостей и исходного объекта для всех значений расстояний $r$ при фиксированных значениях углов $\omega $ и $\varphi $. Если плоскость $B$ не пересекает 3D изображение, т.\,е. $F\bigcap B\left(\eta (\omega ,\varphi ),r\right)=\emptyset$, то значение гипертрейс функционала полагают равным нулю:
$\mathrm{HyperT}\left(F\bigcap B\left(\eta (\omega ,\varphi ),r\right)\right)=0$.

Таким образом, тройке $(\omega_i, \varphi_j,r_k)$ соответствует элемент
матрицы 3TM с номером $(i,j,k)$ и значением $\Pi(F_{\mathrm{sect}})$,
который характеризует информативный признак фигуры, полученной в сечении
объекта $F$ плоскостью $B(\eta (\omega _{i} ,\varphi _{j} ),r_{k})$.
Графическое представление ги\-пер\-трейс-мат\-ри\-цы показано на рис.~\ref{fg:Fed3},
где полученное в~результате сканирования множество чисел $G$ образуют точки
$(\omega_i,\varphi_j,r_k)$ в~системе координат с осями $0\omega $, $0\varphi$
и~$0r$. Чем ближе к~красному и~теплым тонам, тем выше значение элемента
матрицы; чем ближе к~фиолетовому и~холодным тонам, тем ниже значение данного
элемента.

После заполнения 3D гипертрейс-матрицы с помощью гипердиаметрального
функционала HyperP обрабатываются глубинные строки матрицы~3ТM.
Его можно задать, например, как $\mathrm{HyperT} =\int G\left(\omega, \varphi,
r\right)dr $. После обработки данная 3D гипертрейс-матрица 3ТM
становится двумерной матрицей 2ТM, каждый столбец и строка которой
представляет собой $2\pi$-пе\-рио\-ди\-че\-скую кривую. Далее применяется
постолбцовая обработка матрицы 2TM посредством функционала $\mathrm{Hyper}\Omega$,
который можно задать, например, как $\mathrm{Hyper}\Omega =\mathop{\max }\limits_{\varphi } G\left(\omega, \varphi \right)$.
В~результате получается набор чисел 1TM~--- вектор значений, непрерывным
аналогом которого будет $2\pi$-пе\-рио\-ди\-че\-ская кривая. К~полученному
набору чисел применяют гиперкруговой функционал $\mathrm{Hyper}\Theta$,
что приводит к появлению некоторого числа --- признака изображения $\myop{Res}(F)$. Этот функционал можно задать, например, амплитудой второй гармоники разложения в ряд Фурье.

\begin{figure}
\begin{center}
\includegraphics[bb=0mm 0mm 208mm 296mm, width=120.4mm, height=68.4mm,
viewport=3mm 4mm 205mm 292mm]{Fed_image5.eps}
\end{center}
\caption{Пример графического представления гипертрейс-матрицы 3TM}
\label{fg:Fed3}
\end{figure}

Таким образом, гипертриплетный признак 3D изображения $F$ обладает структурой
в~виде композиции четырех функционалов, каждый из которых, кроме
ги\-пер\-трейс-функ\-ци\-о\-на\-ла HyperT, при последовательном применении
сокращает размерность матрицы 3TM на единицу:
\[
\myop{Res}(F)=\mathrm{Hyper}\Theta \circ \mathrm{Hyper}\Omega \circ
\mathrm{HyperP} \circ \mathrm{HyperT}(F_{\mathrm{sect}}).
\]

Каждую 2D фигуру, получившуюся в сечении исходной 3D модели сеткой
параллельных плоскостей под разными углами обзора, необходимо просканировать,
чтобы извлечь какие-нибудь значимые признаки (например, периметр контура фигуры
сечения и~т.\,п.). Для нахождения признака 2D изображения сечения используется трейс-пре\-обра\-зо\-ва\-ние~\cite{11}.

Сканирование получаемых в сечении фигур $F_{\mathrm{sect}}$
осуществляется решеткой параллельных прямых $l\left(\theta ,\rho \right)$
с~расстоянием~$\Delta \rho $ между линиями, где $\rho$ и~$\theta$~---
полярные координаты прямой в плоскости сечения (см.\ рис.~\ref{fg:Fed2}).
Взаимное положение 2D изображения $F_{\mathrm{sect}}$ и~каждой сканирующей
линии $l\left(\theta ,\rho \right)$ характеризуется числом~$g$, вычисляемым
по некоторому правилу $\mathrm{T}:g=\mathrm{T}(F_{\mathrm{sect}} \bigcap l(\theta ,\rho))$.
В~качестве указанной характеристики могут выступать длина части прямой,
лежащей внутри изображения, или свойства окрестности точки пересечения и~т.\,п.
Другими словами, функционал $\mathrm{T}$ характеризует свойство отрезков пересечений прямой 2D фигуры в плоскости сечения.

Затем сканирование производится для нового значения угла $\theta +\Delta\theta $,
получившего дискретное приращение $\Delta \theta $, сеткой параллельных прямых
в~той же плоскости сечения~$F_{\mathrm{sect}}$ и~с~тем же шагом $\Delta \rho$.
К~пересечению новой прямой $l(\theta +\Delta \theta ,\rho )$
и~сечения~$F_{\mathrm{sect}}$ применяется то же ранее выбранное правило $\mathrm{T}$. Сканирование повторяется для каждого нового угла до завершения оборота в~$2\pi$~рад.

\begin{figure}
  \subfloat[Сканирование сечения сеткой параллельных прямых]{
 \includegraphics[bb=0mm 0mm 208mm 296mm, width=70.7mm, height=59.0mm, viewport=3mm 4mm 205mm 292mm width=0.5\textwidth]{Fed_image4.eps}}\hfil
  \subfloat[Пример графического представления трейс матрицы TM]{
    \includegraphics[bb=0mm 0mm 208mm 296mm, width=77.0mm, height=59.3mm, viewport=3mm 4mm 205mm 292mm]{Fed_image6.eps}
  }\\
\caption{Процесс сканирования 2D сечения }
\label{fg:Fed4}
\end{figure}

Результат вычислений трейс функционала $\mathrm{Т}$ зависит от двух параметров прямой:
$\theta $ и~$\rho $. При численном анализе результат трейс-преобразования
удобно представить в~виде 2D трейс матрицы ТМ, у которой ось~$0\theta$
направлена горизонтально, а~ось~$0\rho$~--- вертикально (рис.~\ref{fg:Fed4}).
Каждый вертикальный столбец матрицы ТМ содержит значения, вычисляемые по
всем прямым сканирующей сетки при одинаковом значении угла $\theta $ для
одной и той же 2D фигуры сечения. Каждая горизонтальная строка матрицы ТМ
содержит значения, вычисляемые для одной и той же прямой $l$, имеющей
одинаковое расстояние до начала координат, при разных значениях угла~$\theta$
в~той же плоскости сечения. Если прямая~$l$ не пересекает изображение:
$F_{\mathrm{sect}} \bigcap l(\theta ,\rho )=\emptyset$, то значение трейс
функционала полагают равным нулю: $\mathrm{T}(F_{\mathrm{sect}} \bigcap l(\theta ,\rho))=0$.
Таким образом, паре $(\theta_i,\rho_j)$ соответствует элемент матрицы TM
с~номером $(i,j)$ и значением $\mathrm{T}(F_{\mathrm{sect}} \bigcap l(\theta _{i} ,\rho _{j}))$.

После заполнения 2D трейс матрицы c помощью диаметрального функционала~$\mathrm{P}$
обрабатываются столбцы матрицы TM. Его можно задать, например, как
$\mathrm{T} ={\int g(\theta, \rho)d\rho}/{\mathop{\max }\limits_{\rho } g(\theta, \rho)}$.
После этой обработки данная двумерная матрица ТM становится одномерной
матрицей~--- вектором чисел,  непрерывным аналогом которого будет $2\pi$-пе\-рио\-ди\-че\-ская
кривая. Затем к полученному набору чисел применяют круговой функционал~$\Theta$,
который можно задать как $\Theta =\mathop{\min }\limits_{\theta } g(\theta)$.
В~результате получается некоторое число $\Pi(F_{\mathrm{sect}})$~---
признак 2D фигуры сечения $F_{\mathrm{sect}}$.

Таким образом, триплетный признак 2D изображения $F_{\mathrm{sect}}$
обладает структурой в виде композиции трех функционалов, каждый из которых,
кроме трейс функционала $\mathrm{T}$, при последовательном применении сокращает
размерность матрицы TM на единицу:
\[
\Pi(F_{\mathrm{sect}})=\mathrm{HyperT}(F_{\mathrm{sect}})=
\Theta \circ \mathrm{P} \circ \mathrm{T}(F_{\mathrm{sect}} \bigcap l(\theta ,\rho)).
\]

Объединяя полученные формулы для $\myop{Res}(F)$ и $\Pi(F_{\mathrm{sect}})$,
окончательно получаем следующую аналитическую структуру признака 3D
изображения в виде композиции некоторого множества функционалов:
\[
\myop{Res}(F)=\mathrm{Hyper}\Theta \circ \mathrm{Hyper}\Omega \circ
\mathrm{HyperP} \circ \mathrm{HyperT}(\Theta \circ \mathrm{P} \circ \mathrm{T}(F_{\mathrm{sect}} \bigcap l(\theta ,\rho))).
\]

Благодаря композиционной структуре функционалов, входящих в структуру
$\Pi(F_{\mathrm{sect}})$ и~$\myop{Res}(F)$, возможно получение огромного
числа признаков, причем возможно конструирование признаков, описывающих те или иные геометрические характеристики 3D объекта, что облегчает задачу анализа свойств 3D изображений и построения информативных признаков.

Стоит отметить, что расположение системы координат в плоскости сечения и ее ориентация относительно фигуры сечения совершенно неважны, так как трейс-преобразование полностью инвариантно к группе движений и масштабированию 2D изображения \cite{12}.

Таким образом, данный метод обладает определенной универсальностью, так как схема сканирования не привязана к геометрическим особенностям исходной модели, а благодаря большому числу используемых видов функционалов и их композиционной структуре можно подбирать и конструировать различные признаки, которые будут наиболее эффективны при распознавании заданной базы объектов. Предлагаемая методика ориентирована на объекты любой сложности и конфигурации.

\section{Минимизация размерности признакового пространства}

Как отмечалось выше, подход на основе стохастической геометрии позволяет автоматически генерировать большое количество гипертриплетных признаков, отображающих как геометрические, так и абстрактные характеристики 3D изображения. Однако сформированная таким образом система гипертриплетных признаков, как правило, избыточна. Одни признаки имеют высокую различающую силу, тогда как другие --- нет. При этом для одних классов эффективны одни признаки, а для других классов --- другие. Кроме того, многие признаки могут коррелировать
друг с другом, тем самым снижая общую эффективность распознавания.

Также стоит отметить, что создание излишнего большого количества признаков не только не повышает эффективность распознавания, но и снижает скорость работы распознающей системы.

Таким образом, целесообразно разработать алгоритм, который после генерации признаков минимизирует размерность их пространства для выделения наиболее информативных из них.

Можно выделить два основных подхода к построению эффективного множества признаков изображений \cite{13,14}. Первый подход заключается в том, чтобы строить заранее известное малое количество признаков, обладающих большой информативностью. С позиции второго подхода из большого числа построенных признаков по некоторому правилу отбирается как можно меньшее количество наиболее информативных признаков.

Минусом первого подхода является отсутствие единой логической системы, так как
такие методы основаны, как правило, на эвристике и эмпирике разработчика
рас\-по\-зна\-юще\-го алгоритма, поэтому на практике трудно выявить малое количество информативных признаков, которые будут эффективно распознавать 3D изображения для большинства практических задач, так как геометрия реальных 3D объектов весьма обширна и сложна.

Касательно второго подхода в настоящее время разработано множество различных критериев отбора эффективных и значимых признаков, основанных на методах математической статистики и информатики. Данный подход является более гибким и универсальным, так как в каждом конкретном случае информативность признаков оценивается исходя из представленной базы 3D объектов.

В данном разделе будет описан алгоритм, согласно которому можно сократить большое количество признаков до нескольких наиболее информативных (в русле идей второго подхода). Также благодаря композиционной структуре признака аналитик может заранее создавать определенные признаки, которые с высокой вероятностью будут являться информативными (в русле идей первого подхода), такие
как площадь поверхности 3D объекта, его объем, максимальная площадь и периметр сечения, радиус описанной сферы и~т.\,п.

Количественной мерой для определения информативности отдельного признака
Res$_i$ может служить количество информации $\mathrm{Info}(\mathrm{Res})$,
извлекаемой при распознавании 3D изображения. Она равна разности между энтропией $H(F)$ распределений плотности вероятности образов $F$ и усредненной по всем изображениям неопределенностью решения, которая определяется полной условной энтропией образов $F_i$.

Однако в рассматриваемом случае оценка информативности признака данным
спо\-собом невозможна ввиду огромного объема вычислений. Так, система
способна автоматически генерировать $64^6 = 68\,719\,476\,736$ различных признаков при использовании~$64$~различных видов функций для каждого из $6$ функционалов композиционной структуры призна\-ка~\cite{15}. Очевидно, что задача определения даже небольшого числа информативных из всей совокупности признаков не разрешима за реальное время в рамках определения количественной меры энтропии. Кроме того, не всегда возможно получить численные значения вероятностей, необходимых для определения $H(F)$
и~$\mathrm{Info}(x)$.

Также стоит отметить, что концепция минимальной энтропии основывается на предположении о нормальности распределения образов, составляющих заданные классы, что далеко не всегда верно. Кроме того, в задаче классификации 3D изображений законы распределений плотности вероятности образов не известны, так как базы данных формируются исходя из контекста решаемой задачи, определяемого конкретными условиями деятельности того или иного субъекта.

Поэтому целесообразно использовать подходы, для которых не нужно знать плотность распределения вероятности 3D изображений. Будем определять информативность того или иного признака исходя из данных обучающей выборки 3D объектов.

В основе данного предположения лежит гипотеза компактности: 3D изображения одного и того же класса в признаковом пространстве обычно располагаются в геометрически близкие точки, образуя «компактные» сгустки. Другими словами, схожие объекты гораздо чаще лежат в одном классе, чем в разных, и при этом обладают свойством хорошей отделимости:

\begin{enumerate}[(1)]
\item  множества разных образов соприкасаются в сравнительно небольшом числе точек (или вообще не соприкасаются);

\item  существуют точки в признаковом пространстве, которые не будут принадлежать ни к~одному из классов (или равновероятно принадлежать обоим классам);

\item  границы классов имеют сравнительно плавную форму без глубоких выступов в~пределы других классов.
\end{enumerate}

Таким образом, используемый в данной работе алгоритм минимизации размерности
признакового пространства был разработан исходя из логики сравнения 3D
объектов, учитывая все вышесказанное. Его суть заключается в следующем.

Рассмотрим множество~$M =\mathop{\bigcup }\limits_{i=1}^{m} C_{i} $,
состоящее из $m$ подмножеств (классов) $C_i$, при этом в подмножестве~$C_i$
содержится $h_i$ количество элементов (изображений). Выберем из данного
множества $М$ подмножество $M'\subset M$, мощность которого равна
${\sum _{i=1}^{m} h_{i}}/{2}$ для обуче\-ния системы, т.\,е. $M'=\mathop{\bigcup }\limits_{i=1}^{m} A_{i} $. Оставшиеся подмножества $B_i$ будут нужны для испытания обученной системы, контроля ее качества.

Обозначим через $\mathrm{Res}_{k}^{A_{i}(s)} $ гипертриплетный признак $k$-го вида, вычисленный для $s$-го представителя $i$-го класса
$A_i$. Среднее значение $k$-го вида признака для всех изображений множества $A_{i} $ равно:
\[
\mu_{k}^{A_{i} } =\frac{2}{h_{i} } \sum _{s=1}^{h_{i} }\mathrm{Res}_{k}^{A_{i}(s)}.
\]

Среднеквадратическое отклонение $k$-го признака по множеству $A_i$ равно:
\[
\sigma_{k}^{A_{i} } =\sqrt{\frac{2}{h_{i} } \left(\sum _{s=1}^{h_{i} }
\left(\mathrm{Res}_{k}^{A_{i}(s)} -\mu_{k}^{A_{i} } \right)^{2}  \right)}.
\]

Информативными признаками будут те, которые позволяют различать как можно
больше классов 3D объектов между собой. Другими словами, среднее значение
признака для одного класса будет как можно более удалено от среднего значения
того же признака для любого другого класса. При этом количество совпадений
представителей разных классов должно быть как можно меньше.

В связи с вышеизложенным были разработаны две процедуры: отбор потенциально эффективных признаков по количеству как можно меньшего совпадения представителей разных классов между собой и выделение информативных признаков по удаленности друг от друга их средних значений по классам.

Для отбора потенциально эффективных признаков необходимо внутри каждого класса изображений произвести расчет их усредненных значений, а также статистику расчета их среднеквадратического колебания отдельно по каждому признаку. Для этого рассчитывается показатель $p(A_{i} ,k)$, который определяет меру неподобия $k$-го признака для $i$-го класса $A_i$. Он состоит из двух частей:
\[
p(A_{i} ,k)=\frac{q_1(A_{i} ,k)+q_2(A_{i} ,k)}{h_{i} }.
\]

Первая часть коэффициента учитывает количество 3D изображений, признаки
$\myop{\mathrm{Res}}_{k}^{A_{i}(s)}$ которых не будут попадать
в~соответствующие диапазоны колебания среднего значения \mbox{$k$-го} признака для
своего $i$-го класса $A_i$:
$q_1(A_{i} (s),k)$ увеличивается на~1, если $\myop{Res}_{k}^{A_{j}(s)} \hm<\mu _{k}^{A_{i} } -\sigma _{k}^{A_{i} } \vee \mu _{k}^{A_{i} } +\sigma _{k}^{A_{i} } <\myop{Res}_{k}^{A_{j} (s)}$ для $i=j$.

Показатель $q_1(A_{i}(s),k)$ показывает количество 3D объектов $s$, которые будут неправильно классифицированы, так как слишком далеко отстоят от среднего представителя своего класса.

Вторая часть коэффициента учитывает количество 3D изображений, признаки $\myop{Res}_{k}^{A_{j}(s)} $ которых попадут в соответствующие диапазоны колебания среднего значения $k$-го признака для другого $i$-го класса $A_i$:
$q_2(A_{i}(s),k)$ увеличивается на~1, если $\mu_{k}^{A_{i}}-\sigma_{k}^{A_{i}} \le \myop{Res}_{k}^{A_{j}(s)}\hm \le \mu_{k}^{A_{i}} +\sigma _{k}^{A_{i}} $ для $i\ne j$.

Показатель $q_2(A_{i}(s),k)$ показывает количество 3D объектов $s$, которые будут неправильно классифицированы, так как слишком близко находятся к среднему представителю другого класса.

Коэффициент $p$ представляет собой матрицу весов, рассчитанную для каждого
типа признака~$k$ ($k=1,\ldots , \mathrm{col}$) в~зависимости от класса
объектов $A_i$ ($i=1,\ldots , m$). Данная матрица показывает различающую силу признаков с точки зрения уровня потенциальных ошибок в классификации объектов.

Стоит отметить, что коэффициент $p(A_{i} ,k)$ всегда будет лежать в единичном отрезке: $0\le p(A_{i} ,k)\le 1$. Поэтому данный показатель может рассматриваться как вероятность того, насколько этот признак потенциально неинформативен для данного класса. Чем выше коэффициент неподобия $p(A_{i} ,k)$, тем меньшей различающей силой обладает $k$-й признак для $i$-го класса $A_i$. В связи с этим целесообразно задать некоторый порог $\delta $, чтобы из всей совокупности признаков выделить потенциально эффективные, отсеяв заведомо неинформативные признаки:
\[
\frac{\sum _{i=1}^{m}p(A_{i} ,k) }{m} \le \delta.
\]

Таким образом, данная процедура позволяет не только произвести отбор потенциально эффективных признаков, но и указать их различающую силу по классам.

Далее для учета корреляции признаков друг с другом нужно произвести расчет
элементов матрицы парной корреляции по полученной совокупности средних
значений каждого признака по классам. Выделяются те признаки, которые
имеют значение коэффициента парной корреляции не ниже 0,7.
Среди выделенных пар множества признаков удаляются те, которые
имеют большее значение уже подсчитанной суммы $\sum _{i=1}^{m}p(A_{i} ,k)$.

Дальнейший отбор информативных признаков производится из полученной сокращенной совокупности признаков с учетом распределения их средних значений по классам на всем интервале, чтобы в целом все признаки были удалены как можно дальше друг от друга. Так как колебание дисперсии признаков уже учтено по классам (в матрице весов выделены только наиболее информативные с точки зрения как можно меньшего пересечения границ классов между собой), то далее достаточно для каждого признака произвести сортировку только их усредненных значений по классам:
\[
\mathrm{sort}\left(\mu _{k}^{A_{1} } ,\mu _{k}^{A_{2} } ,\ldots ,\mu _{k}^{A_{m} } \right) \to \left(\xi _{k}^{A_{1} } ,\xi _{k}^{A_{2} } ,\ldots ,\xi _{k}^{A_{m} } \right),
\]
где $\xi _{k}^{A_{i} } $ --- среднее значение $k$-го признака по $i$-му классу $A_i$, отсортированное по возрастанию ($\xi _{k}^{A_{1} } \le \xi _{k}^{A_{2} } \le \cdots \le \xi _{k}^{A_{m} } $).

Далее находится разница между значениями соседних элементов:
\[
\Delta \left(\xi _{k}^{A_{1} } ,\xi _{k}^{A_{2} } ,\ldots ,\xi _{k}^{A_{m} } \right) \to  \left(\xi _{k}^{A_{2} } -\xi _{k}^{A_{1} } ,\xi _{k}^{A_{3} } -\xi _{k}^{A_{2} } ,\ldots ,\xi _{k}^{A_{m} } -\xi _{k}^{A_{m-1} } \right).
\]

Чем меньше значение элемента $\Delta \xi _{k}^{i} =\xi _{k}^{A_{i} } -
\xi _{k}^{A_{i-1} } $ ($i=2,\ldots , m$) и тем больше количество таких элементов, тем хуже различающая сила признака. Чтобы не производить лишний раз сортировку и при этом оценить уровень значения нескольких наиболее худших представителей, достаточно рассчитать, например, нижнюю границу интервала колебания среднего значения признаков $\Delta \xi _{k}^{i} $ ($i=2,\ldots , m$):
\[
\mathrm{border} (k)=\mathrm{mean}\left(\Delta \xi _{k} \right)-
\mathrm{stdev}\left(\Delta \xi _{k} \right),
\]
где $\mathrm{mean}\left(\Delta \xi _{k} \right)=({2}/({m-1}))
\sum _{i=1}^{m-1}\Delta \xi _{k}^{i} =
{2 \left(\xi _{k}^{A_{m} } \hm-\xi _{k}^{A_{1} } \right)}/({m-1}) $~---
среднеарифметическое чисел $\Delta \xi _{k}^{i}$,
а~$\mathrm{stdev}\left(\Delta \xi _{k} \right)=\sqrt{
({2}/({m-1})) \left(\sum _{i=1}^{m-1}\left(\Delta \xi _{k}^{i} -
\mathrm{mean}\left(\Delta \xi _{k} \right)\right)^{2}  \right)} $ --- среднеквадратическое чисел $\Delta \xi _{k}^{i} $.

Критерий отбора признаков следующий: чем выше значение $\mathrm{border}(k)$,
тем выше различающая сила $k$-го признака и его информативность.
Поэтому программа отбирает~$z$~лучших представителей по данному критерию, где порог $z$ признаков задает аналитик машине еще до начала работы исходя из количества классов изображений в базе данных, а также требований к точности результатов и времени их получения.

Вторая предложенная процедура выделяет из всех потенциально информативных некоррелируемых признаков только те, которые дают как можно менее близкий друг ко другу набор средних значений признаков по классам. В этом случае учитывается различающая сила признаков с точки зрения их информативности.

Построенный согласно указанным двум процедурам алгоритм сокращения раз\-мер\-ности
признакового пространства позволяет получать набор информативных признаков
с~указанием для каждого из них его различающей силы с точки зрения потенциального уровня ошибок (значение весового коэффициента неподобия). При необходимости данный набор можно сводить к минимуму, указывая минимальное количество $z$ требуемых признаков, отобранных с точки зрения их потенциальной эффективности.

Вторая предложенная процедура эффективно дополняет первую процедуру, так как они преследуют прямо противоположные цели: первая отбирает информативные признаки с точки зрения уровня их потенциальной неэффективности, тогда как вторая стремится выделять признаки с точки зрения их потенциальной эффективности. В тех случаях, где плохо сработает первая процедура (например, определенные теоретические примеры конструкций), вторая должна дать хорошие результаты, и наоборот.

\section{Решающая процедура}

«Сходство» 3D изображений между собой определяется функцией расстояния
$\rho(\mathrm{desk}(x),\mathrm{desk}(x'))$ между двумя векторами дескрипторов
признаков образов $\mathrm{desk}(x)$ в~пространстве объектов $X$. При выполнении гипотезы компактности класс 3D изображения может быть также определен как класс усредненного изображения множества сходных видов пространственных объектов, являющегося наиболее близким к исходному изображению в смысле расстояния $\rho(x,x')$.

Решающая процедура построена таким образом, что может как учитывать, так и не учитывать весовые коэффициенты для каждого информативного гипертриплетного признака. Ее суть состоит в следующем.

Обозначим через $t$ тестовое 3D изображение из какого-либо подмножества $B_i$.
Тогда его $k$-й признак будет равен $\mathrm{Res}_{k}^{t}$.
Расстояние между тестовым 3D изображением и $i$-м классом (множеством $A_i$) с учетом весовых значений определяется следующим образом:
\[
d(t,A_{i})=\sum_{k}p(A_{i},k) \frac{|\mathrm{Res}_{k}^{t} -\mu_{k}^{A_{i}} |}{\sigma_{k}^{A_{i}} }\,.
\]

Без учета весовых значений данная формула будет выглядеть так:
\[
d(t,A_{i})=\sum_{k}\frac{|\mathrm{Res}_{k}^{t} -\mu_{k}^{A_{i}} |}{\sigma_{k}^{A_{i} } }.
\]

Распознающая система тестовое изображение $t$ относит к классу $A_j$, если

\[
d(t,A_{j})=\mathop{\min }\limits_{i} d(t,A_{i}).
\]

Таким образом, еще один существенный плюс в пользу гипертриплетных признаков заключается в том, что при опоре на большое их количество применяются простые решающие правила для распознавания 3D изображений. При этом, что немаловажно, при определении принадлежности тестового изображения учитываются весовые коэффициенты для каждого информативного признака в зависимости от класса 3D объекта.

\section{Преимущества стохастического способа сканирования трехмерных изображений}

 При анализе и распознавании 2D изображений сканирование со случайными
параметрами улучшает соотношение «на\-деж\-ность--быст\-ро\-дей\-ст\-вие» по сравнению с фиксированной разверткой \cite{12}. Аналогичное свойство справедливо также и при анализе и распознавании 3D изображений.
Покажем преимущество стохастического способа анализа перед детерминированными развертками на простом примере бросания точки на окружность, который очень хорошо раскроет общую идею.

\begin{figure}[b]
\begin{center}
\includegraphics[bb=0mm 0mm 208mm 296mm, width=168.1mm, height=45.6mm, viewport=3mm 4mm 205mm 292mm]{Fed_image8.eps}
\\
\ (\textit{а})\ \ \ \ \hfil\hfil(\textit{б})\ \ \ \hfil\hfil(\textit{в})\hfil\\
\end{center}
\caption{Расстановка точек на окружности стохастическим и детерминированным способом }
\label{fg:Fed5}
\end{figure}

Задача эксперимента состоит в том, чтобы оценить минимальную погрешность
отклонения случайно бросаемой точки на окружность от множества расставленных
на ней точек. Для фиксированной развертки из $N$ точек
(рис.~\ref{fg:Fed5},\,\textit{а}) на окружности образуются~$N$~дуг
равной длины ${2\pi  \mathord{\left/{\vphantom{2\pi  N}}
\right.\kern-\nulldelimiterspace} N}$.
Поэтому минимальное отклонение в худшем случае составит~${\pi  \mathord{\left/{\vphantom{\pi  N}}\right.\kern-\nulldelimiterspace} N} $, когда бросаемая точка будет лежать в центре дуги между двумя точками исходной развертки.

Для стохастического способа расстановки точек дело обстоит иначе
(рис.~\ref{fg:Fed5},\,\textit{б}). Не уменьшая общности, пусть бросаемая точка
попала в место $(0;1)$. Максимальная погрешность равна $\pi $, когда
бросаемая точка и наиболее удаленная точка развертки будут являться
диаметрально противоположными. Так как точки левой и правой половины
окруж\-ности равноудалены от точки $(0; 1)$ и дают одинаковое симметричное
отклонение в пределах до~$\pi $, то анализ минимального отклонения бросаемой
точки от множества построенных точек на окружности равносилен анализу
минимального отклонения для точек только для одной половины окружности,
например, если спроецировать горизонтально точки правой половины окружности
на левую (рис.~\ref{fg:Fed5},\,\textit{в}). В~этом случае для равномерного распределения
ожидаемое минимальное отклонение для $N$ точек будет равно
${\pi  \mathord{\left/{\vphantom{\pi
\left(N+1\right)}}\right.\kern-\nulldelimiterspace} \left(N+1\right)} $,
так как они между точкой $(0; 1)$ и диаметрально удаленной $(0; -1)$
образуют $N+1$ дугу с~ожидаемой средней длиной ${\pi  \mathord{\left/{\vphantom{\pi  \left(N+1\right)}}\right.\kern-\nulldelimiterspace} \left(N+1\right)} $.

Данные рассуждения аналогичны и справедливы для любой бросаемой точки на
окружности, отличной от $(0; 1)$. Так как ${\pi  \mathord{\left/{\vphantom{\pi  \left(N+1\right)}}\right.\kern-\nulldelimiterspace}
\left(N+1\right)} <{\pi  \mathord{\left/{\vphantom{\pi  N}}\right.\kern-\nulldelimiterspace} N} $,
то стохастический способ расстановки точек более эффективен, чем детерминированный. Проведенные
практические эксперименты в среде пакета {MathCAD 15 M030} показали справедливость приведенных выше теоретических оценок. Другие аналогичные теоретические оценки, подтверждающие эффективность и преимущество методов стохастической геометрии, можно найти в \cite{16}.

Ниже приведены результаты эксперимента для доказательства преимуществ
стохастического способа сканирования перед детерминированной разверткой
с~точки зрения соотношения «точ\-ность--быст\-ро\-дей\-ст\-вие».
В~качестве 3D изображения был взят объект «паук» под номером $m_{16}$
из известной базы данных Принстонского университета
\textit{The Princeton Shape Benchmark}~\cite{17}. В~качестве критерия оценки результатов работы алгоритма был использован коэффициент удельной погрешности вычисления признака:
\[
\beta =\frac{|\mathrm{TrueFeat}-\mathrm{CalcFeat}|}{\mathrm{TrueFeat}}\,,
\]
где TrueFeat --- истинное значение признака, а CalcFeat --- вычисленное значение признака.

 В качестве анализируемого признака была выбрана максимальная длина отрезка,
который может быть помещен вовнутрь 3D объекта. Точное значение данного признака можно вычислить для произвольно взятого 3D изображения, перебрав все попарные расстояния между вершинами 3D модели. Описание данного признака приведено ниже:
\[
\myop{Res}(F)=\mathrm{Hyper}\Theta \circ \mathrm{Hyper}\Omega \circ
\mathrm{Hyper P} \circ \mathrm{Hyper T}(\Theta \circ \mathrm{P} \circ \mathrm{T})\,.
\]
Здесь
$$
\mathrm{T}(F_{\mathrm{sect}} \bigcap l(\theta ,\rho ))=\mathop{\max }
\limits_{t}(f(\theta ,\rho ,t));\
\mathrm{P} =\mathop{\max }\limits_{\rho } g(\theta ,\rho);\
\Theta =\mathop{\max }\limits_{\theta } g(\theta);
$$
$$
\mathrm{Hyper T}(F\bigcap B(\eta(\omega,\varphi),r))=\Pi(F_{\mathrm{sect}})=
G(\omega,\varphi ,r);\ \mathrm{Hyper P} ={\mathrm{Row3D}}\cdot \Delta r;
$$
$$
\mathrm{Hyper}\Omega =\mathop{\max }\limits_{\omega } G(\omega,\varphi);\
\mathrm{Hyper}\Theta =\mathop{\max }\limits_{\varphi} G(\varphi),
$$
где
 $f(\theta,\rho ,t)$ ---  длина $t$-го отрезка, высекаемого $\rho $-й
прямой под $\theta$-м углом наклона в плоскости сечения $F_{\mathrm{sect}}$;
$\Pi(F_{\mathrm{sect}})=G(\omega,\varphi,r)$ --- признак сечения (максимальная
длина отрезка), получаемого пересечением $r$-й плоскости $B(\eta(\omega,\varphi),r)$
под парой $(\omega,\varphi)$ углов обзора;
Row3D~--- количество ненулевых элементов глубинных строках матрицы 3TM (ось~$0r$).

Эксперимент состоял из двух блоков. Первый блок оценивал при одинаковых
параметрах сканирования, на сколько процентов увеличится точность распознавания
объекта (точность вычисления признака) при использовании стохастического
сканирования по сравнению с детерминированной разверткой. Второй блок состоял
в~определении таких параметров сканирования, чтобы за меньшее время работы алгоритма (шаг сканирования крупнее) достичь приблизительно тот же уровень точности для стохастического сканирования, как и для детерминированной развертки. Горизонтальная ось показывает результаты экспериментов каждого блока. Положительные значения вертикальной оси показывает преимущество стохастического способа сканирования перед детерминированным, отрицательные значения --- наоборот:
\[
\Delta _{i,j} =\frac{S_{i,j} -D_{i,j} }{S_{i,j} } ,
\]
где $S_{i,j} $ --- значение показателя, вычисленного стохастическим способом
сканирования 3D изображения; $D_{i,j} $ --- значение показателя, вычисленного детерминированным способом сканирования 3D изображения. При $i=1$ показатель определяет время вычисления признака, при $i=2$ --- значение признака. Переменная $j$ определяет блок эксперимента.

\begin{figure}[t]
{  \includegraphics[bb=0mm 0mm 208mm 296mm, width=156.9mm, height=89.8mm, viewport=3mm 4mm 205mm 292mm]{Fed_image7.eps}}
\caption{Сравнительная диаграмма результатов отношений стохастического сканирования и детерминированной развертки }
\label{fg:Fed6}
\end{figure}

Как видно из представленной диаграммы (рис.~\ref{fg:Fed6}), преимущество стохастического сканирования перед детерминированной разверткой очевидно. При этом во втором блоке эксперимента прирост вычисляемого показателя (прирост быстродействия) заметно выше, чем в первом блоке (точность вычислений признака). При этом при упоре на быстродействие прирост эффективности заметно выше, чем при упоре на точность вычислений признака. Это объясняется комбинаторным сокращением числа сканирований из-за композиционной структуры признака. Стоит отметить также, что возможность регулирования такого свойства гипертрейс-преобразования, как выбор между скоростью вычислений и точностью, повышает гибкость стохастического распознавания 3D изображений. Другие эксперименты по проверке свойств гипертрейс-преобразования при анализе и распознавании 3D изображений можно найти в работах \cite{18,19}.


\section{Заключение}

 В настоящей статье для решения задачи анализа и распознавания 3D изображений
впервые был предложен новый подход с позиции стохастической геометрии
и~функционального анализа, который позволяет анализировать пространственные
объекты без предварительного их упрощения и построения проекций на плоскости,
анализируя непосредственно их 3D форму. Данный подход обладает определенной
универсальностью, так как техника сканирования плоскостями не привязана
к~геометрическим особенностям 3D изображения, поэтому гипертрейс-преобразование способно эффективно распознавать 3D объекты любой формы и структуры.

Новое геометрическое гипертрейс-преобразование благодаря описанному методу построения гипертриплетных признаков позволяет не только создавать инвариантное описание 3D изображения, но и анализировать его особенности и геометрию поверхности.

Разработанная процедура минимизации признакового пространства позволяет не только отбирать заданное число информативных признаков, но и присваивать каждому из них весовой коэффициент, обозначающий его различающую силу в зависимости от предъявляемого класса 3D изображения. Также стоит отметить, что цель статьи состояла не в разработке универсальной процедуры минимизации признакового пространства, а в возможности применения данной процедуры при стохастическом методе распознавания, которая бы обладала дополнительным преимуществом: имелась возможность учитывать весовые значения коэффициентов признаков в зависимости от классов 3D изображений. Наличие данного свойства позволяет повысить надежность стохастического распознавания 3D изображений гипертрейс-преобразованием.

Используя особенности конструирования гипертриплетных признаков, можно использовать простую процедуру минимизации признакового пространства и решающее правило. Опора на минимальный набор эффективных признаков значительно сокращает время работы распознающего алгоритма

Ввиду сложности разработки в общем виде единой методологии отбора
информативных некоррелируемых признаков и ее оценки, а также ограниченного
объема статьи, в~данной работе отсутствует сравнение процедуры минимизации признакового пространства с~другими подходами.

Авторы планируют развить данный метод для анализа не только бинарных (контурных) и монохромных 3D изображений \cite{15}, но также и цветных и текстурных 3D изображений. Аналогичные результаты уже были получены при анализе цветных и текстурных 2D изображений в [\citenb{20}--\citenb{22}]. Интеллектуальный уровень гипертрейс-преобразования может быть повышен благодаря развитию метода для интеллектуального анализа и распознавания деформированных и поврежденных 3D объектов, для изучения топологии их поверхности. Уже есть первая публикация в данном направлении \cite{23}.

\renewcommand{\bibname}{Литература}
\begin{thebibliography}{99}
\bibitem{1}
      \BibAuthor{Ferreira M.\,R.\,P., de~Carvalho F.~de~A.\,T.}
{Kernel-based hard clustering methods in the feature space with automatic variable weighting}~//
{Original Research Article Pattern Recognition}, 2014. Vol.\,47. Iss.\,9. P.\,3082--3095.

\bibitem{2}
      \BibAuthor{Vasil'ev\;K.\,K., Dement'ev\;V.\,E.,  Andriyanov\;N.\,A.}
{Doubly stochastic models of images}~//
{Pattern Recognition Image Anal. Adv. Math. Theory Appl.}, 2015. Vol.\,25. No.\,1. P.\,105--110.

\bibitem{4}  %3
      \BibAuthor{Mairal\;J., Bach\;F., Ponce\;J., Sapiro\;G.}
{Online dictionary learning for sparse coding}~//
{26th Annual  Conference (International)
on Machine Learning (ICML) Proceedings}, 2009. P.\,689--696.

\bibitem{3} %4
      \BibAuthor{Rubinstein\;R., Peleg\;T., Elad\;M.}
{Analysis K-SVD: A dictionary-learning algorithm for the analysis sparse model}~//
{IEEE Trans. Signal Processing}, 2013. Vol.\,61, No.\,3. P.\,661--677.

\bibitem{5} %5
      \BibAuthor{Xie L., Li D., Simske S.\,J.}
{Feature dimensionality reduction for example-based image super-resolution}~//
   {J.~Pattern Recognition Res.}, 2011. Vol.\,6. No.\,2. P.\,130--139.

\bibitem{6} %6
      \BibAuthor{Yildiz O.\,T.}
{On the feature extraction in discrete space}~//
{Original Research Article Pattern Recognition}, 2014. Vol.\,47. Iss.\,5. P.\,1988--1993.

\bibitem{7}
      \BibAuthor{Zhang\;Y., Song\;S., Tan\;P., Xiao\;J.}
{PanoContext: A whole-room 3D context model for panoramic scene understanding}~//
{13th European Conference on Computer Vision (ECCV 2014) Proceedings}.
Zurich, Switzerland, 2014. Part~IV. Vol.\,8694. P.\,668--686.

\bibitem{8}
      \BibAuthor{Федотов\;Н.\,Г., Семов\;А.\,А., Курносов\;А.\,А.}
{Проблемы распознавания 3D изображений у машин и людей: сравнительная характеристика}~//
{Проблемы информатики в образовании, управлении, экономике и технике: Сб.
статей XIV Междунар. науч.-технич. конф}.~--- Пенза: Изд-во АННОО «Приволжский
дом знаний», 2014. C.\,185--193.

\bibitem{9}
      \BibAuthor{Liu\;K., Skibbe\;H., Schmidt\;T., Blein\;T., Palme\;K., Brox\;T., Ronneberger\;O.}
 {Rotation-invariant HOG descriptors using fourier analysis in polar and spherical coordinates}~//
 {Int. J.~Computer Vision}, 2014. Vol.\,106. Iss.\,3. P.\,342--364.

\bibitem{10}
      \BibAuthor{Fedotov\;N.\,G., Ryndina\;S.\,V., Syemov\;А.\,А.}
{Trace transform of spatial images}~//
{11th Conference (International) on Pattern Recognition and Image Analasis:
New Information Technologies (PRIA-11) Proceedings}.~--- Samara: IPSI RAS, 2013.
Vol.~I. P.\,186--189.

\bibitem{11}
      \BibAuthor{Fedotov\;N.\,G.}
{The theory of image-recognition features based on stochastic geometry}~//
{Pattern Recognition Image Anal. Adv. Math. Theory Appl.}, 1998. Vol.\,8.
No.\,2. P.\,264--266.

\bibitem{12}
      \BibAuthor{Федотов\;Н.\,Г.}
     Теория признаков распознавания образов на основе стохастической геометрии и функционального анализа.~---
       М.: Физматлит, 2009. 304~с.

\bibitem{13}
      \BibAuthor{Айвазян\;С.\,А., Бухштабер\;В.\,М., Енюков\;И.\,С., Мешалкин\;Л.\,Д.}
      Прикладная статистика: классификация и снижение размерности. ---
      М.: Финансы и статистика, 1989. 607~с.

\bibitem{14}
      \BibAuthor{Hastie,\;T., Tibshirani\;R., Friedman\;J.}
      The elements of statistical learning: Data mining, inference and
prediction.~--- 2nd ed.~--- Springer-Verlag, 2009. 746~p.

\bibitem{15}
     \BibAuthor{Федотов\;Н.\,Г., Семов\;А.\,А.}
   Программный комплекс анализа и распознавания 3D изображений на основе пространственного трейс-преобразования со случайными параметрами сканирования.
     Свидетельство об официальной регистрации программ для ЭВМ \No\,2015612257 Роспатента от~16.02.15.

\bibitem{16}
      \BibAuthor{Santalo\;L.\,A.}
      Integral geometry and geometric probability.~--- 2nd ed.~---
New York, NY, USA:  Cambridge University Press, 2004. 428~p.

\bibitem{17}
Princeton Shape Benchmark of 3D models database.
{\sf http://shape.cs.princeton.edu/benchmark/}.


\bibitem{18}
      \BibAuthor{Семов\;А.\,А.}
{Экспериментальная проверка свойств 3D трейс-преобразования}~//
XXI~век: итоги прошлого и проблемы настоящего плюс.
Научно-методический журнал. Серия: технические науки.
Информационные технологии,  2014.
Вып.~03(19). С.\,83--89.

\bibitem{19}
     \BibAuthor{Fedotov\;N.\,G., Ryndina\;S.\,V., Semov\;А.\,А.}
{Trace transform of three-dimensional objects: Recognition, analysis and database search}~//
{Pattern Recognition Image Anal. Adv. Math. Theory  Appl.}, 2014. Vol.\,24.
No.\,4. P.\,566--574.

\bibitem{20}
       \BibAuthor{Fedotov\;N.\,G., Mokshanina\;D.\,A.}
     {Recognition of halftone textures from the standpoint of stochastic geometry and functional analysis}~//
     {Pattern Recognition Image Anal. Adv. Math. Theoryd Appl.},
2010. Vol.\,20. No.\,4. P.\,551--556.

\bibitem{21}
       \BibAuthor{Fedotov\;N.\,G., Mokshanina\;D.\,A.}
{Recognition of images with complex half-tone texture}~//
{Measurement Techniques}, 2011. Vol.\,53. No.\,11. P.\,1226--1232.

\bibitem{22}
     \BibAuthor{Fedotov\;N., Romanov\;S., Goldueva\;D.}
{Application of triple features theory to the analysis of half-tone images and colored textures. Feature construction along stochastic geometry and functional analysis}~//
{Computer Inform. Sci.}, 2013. Vol.\,6. No.\,4. P.\,17--24.

\bibitem{23}
       \BibAuthor{Федотов\;Н.\,Г., Семов\;А.\,А., Моисеев\;А.\,В.}
{Интеллектуальные возможности гипертрейс-пре\-обра\-зо\-ва\-ния: конструирование признаков с заданными свойствами}~//
{Машинное обуче\-ние и~анализ данных}, 2014. T.\,1. №\,9. C.\,1200--1214.

\end{thebibliography}


\renewcommand{\bibname}{References}
\begin{thebibliography}{99}
\bibitem{1}
{Ferreira,~M.\,R.\,P., and F.~de~A.\,T.~de\;Carvalho}. 2014.
e{Kernel-based hard clustering methods in the feature space with automatic variable weighting.}
      \BibJournal{Original Research Article Pattern Recognition} 47(9):3082--3095.

\bibitem{2}
{Vasil'ev,~K.\,K., V.\,E.~Dement'ev, and N.\,A.~Andriyanov.} 2015.
{Doubly stochastic models of images.}
      \BibJournal{Pattern Recognition Image Anal. Adv. Math. Theory Appl.}
25(1):105--110.

\bibitem{4}   %3
{Mairal,~J., F.~Bach, J.~Ponce, and G.~Sapiro.} 2009.
{Online dictionary learning for sparse coding.}
      \BibJournal{26th Annual  Conference (International) on Machine
Learning (ICML) Proceedings}. 689--696.

\bibitem{3} %4
      {Rubinstein,~R., T.~Peleg, and M.~Elad.} 2013.
{Analysis K-SVD: A dictionary-learning algorithm for the analysis sparse model.}
      \BibJournal{IEEE Trans. Signal Processing} 61(3):661--677.

\bibitem{5}
{Xie,~L., D.~Li, S.\,J.~Simske}. 2011.
{Feature dimensionality reduction for example-based image super-resolution.}
      \BibJournal{J.~Pattern Recognition Res.} 6(2):130--139.

\bibitem{6}
{Yildiz, O.\,T.} 2014.
{On the feature extraction in discrete space}.
      \BibJournal{Original Research Article Pattern Recognition} 47(5):1988--1993.

\bibitem{7}
{Zhang,~Y., S.~Song, P.~Tan, and J.~Xiao.} 2014.
{PanoContext: A whole-room 3D context model for panoramic scene understanding}
      \BibJournal{13th European Conference on Computer Vision (ECCV 2014) Proceedings}. Zurich, Switzerland.
8694(IV):668--686.

\bibitem{8}
{Fedotov,~N.\,G., A.\,A.~Syemov, and A.\,A.~Kurnosov.} 2014.
{Three-dimensional images recognition problems at machines and peoples: Comparative characteristic}.
      \BibJournal{14th
Scientific and Technical Conference (International) on
Problems of Informatics in Education, Management,
Economics and Technology Proceedings}.
Penza: Privolzskiy Dom Znaniy Publs. 185--193.

\bibitem{9}
{Liu,~K., H.~Skibbe, T.~Schmidt, T.~Blein, K.~Palme, T.~Brox, and O.~Ronneberger.} 2014.
{Rotation-invariant HOG descriptors using fourier analysis in polar and spherical coordinates}.
      \BibJournal{Int. J.~Computer Vision} 106(3):342--364.

\bibitem{10}
{Fedotov,~N.\,G., S.\,V.~Ryndina, and A.\,A.~Syemov.} 2013.
{Trace transform of spatial images}.
      \BibJournal{11th Conference (International)
on Pattern Recognition and Image Analasis: New Information Technologies
Proceedings}. Samara: IPSI RAS. I:186--189.

\bibitem{11}
{Fedotov,~N.\,G.} 1998.
{The theory of image-recognition features based on stochastic geometry}.
\BibJournal{Pattern Recognition Image Anal. Adv. Math. Theory Appl.}
8(2):264--266.

\bibitem{12}
{Fedotov,~N.\,G.} 2009.
\BibTitle{The theory of patterns recognition features  based on stochastic geometry and functional analysis}.
       Moscow: Fizmatlit. 304~p.

\bibitem{13}
{Ayvazyan,~S.\,A., V.\,M.~Bukhshtaber, I.\,S.~Enyukov, and L.\,D.~Meshalkin.} 1989.
\BibTitle{Applied statistics: Classification and dimension reduction}.
Moscow: Finance and Statistics. 607~p.

\bibitem{14}
{Hastie,~T., R.~Tibshirani, and J.~Friedman.} 2009.
\BibTitle{The elements of statistical learning: Data mining, inference and
prediction}. 2nd ed.   Springer-Verlag. 746~p.

\bibitem{15}
{Fedotov,~N.\,G., and A.\,A.~Syemov.} February~16, 2015.
Software for 3D images analysis and recognition based on the spatial
trace transform with random scan parameters. Official registration
certificate for computer programs No.\,2015612257 of the Rospatent.

\bibitem{16}
{Santalo,~L.\,A.} 2004.
\BibTitle{Integral geometry and geometric probability}.
2nd ed. New York, NY: Cambridge University Press. 428~p.

\bibitem{17}
Princeton Shape Benchmark of 3D models database.
Available at: {\sf http://shape.cs.princeton.edu/ benchmark/}
(accessed December~11, 2015).

\bibitem{18}
{Syemov,~A.\,A.} 2014.
{Experimental verification of the 3D trace-transform properties}.
      \BibJournal{XXI century: Past results and present problems~--- plus.
Scientific-Methodical~J. Ser.: Engineering Science. Information Technology}
03(19):83--89.

\bibitem{19}
{Fedotov,~N.\,G., S.\,V.~Ryndina, and A.\,A.~Semov.} 2014.
{Trace transform of three-dimensional objects:
 Recognition, analysis and database search}.
     \BibJournal{Pattern Recognition Image Anal. Adv. Math. Theory Appl.}
24(4):566--574.

\bibitem{20}
      {Fedotov,~N.\,G., and D.\,A.~Mokshanina.} 2010.
{Recognition of halftone textures from the standpoint of stochastic geometry and functional analysis}.
     \BibJournal{Pattern Recognition Image Anal. Adv. Math. Theory Appl.}
20(4):551--556.

\bibitem{21}
      {Fedotov,~N.\,G., and D.\,A.~Mokshanina.} 2011.
{Recognition of images with complex half-tone texture}.
     \BibJournal{Measurement Techniques} 53(11):1226--1232.

\bibitem{22}
{Fedotov,~N., S.~Romanov, and D.~Goldueva.} 2013.
{Application of triple features theory to the analysis of half-tone images and colored textures. Feature construction along stochastic geometry and functional analysis.}
     \BibJournal{Computer Inform. Sci.}
6(4):17--24.

\bibitem{23}
       %\BibAuthor
       {Fedotov, N.\,G., A.\,A.~Syemov, and A.\,V.~Moiseev.} 2014.
{Intelligent capabilities hypertrace transform: Constructing features with predetermined properties}.
       \BibJournal{Machine Learning Data Anal.} 1(9):1200--1214.

\end{thebibliography}

\end{document}


