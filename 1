\documentclass[12pt, twoside]{article}
\usepackage{jmlda}
\newcommand{\hdir}{.}

\newcommand{\w}{\mathbf{w}}
\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\m}{\mathfrak{m}}
\newcommand{\n}{\mathfrak{n}}

\newtheorem{theorem}{Теорема}
\newtheorem{lemm}{Лемма}
\newtheorem{defin}{Определение}

\newcommand{\dom}{\text{dom}}
\newcommand{\cod}{\text{cod}}
\newcommand{\id}{\text{id}}

%\NOREVIEWERNOTES
\title
    [Методы трансформации моделей]
    {Методы трансформации моделей в~задачах~нелинейной регрессии}
\author
    {Р.\,А.~Сологуб}
\thanks
    {Работа выполнена при финансовой поддержке РФФИ, проект \No\,14-07-31326.}
\email
    {roman.sologub@yahoo.com}
\organization
    {Вычислительный центр им.\ А.\,А.~Дородницына Российской академии наук}
\abstract
    {Решается проблема автоматического построения и упрощения нелинейных
ре\-грес\-си\-он\-ных моделей. Модели предназначены для описания результатов измерений
и~про\-гно\-зи\-ро\-ва\-ния экспериментов, составляющих неотъемлемую часть ес\-те\-ст\-вен\-но-на\-уч\-ных
исследова\-ний. Порождаемые модели предназначены для аппроксимации, анализа и прогнозирования
результатов измерений. При порождении учитываются требования, предъ\-яв\-ля\-емые
экспертами-специалистами в предметной области к порождаемым  моделям. Это дает
возможность получения экс\-перт\-но-ин\-тер\-пре\-ти\-ру\-емых моделей, адекватно описывающих результат измерения.

		\bigskip
\noindent
		\textbf{Ключевые слова}: \emph {анализ данных;
регрессионная модель; нелинейная регрессия; порождение моделей;
построение суперпозиций}}
\titleEng
    {Methods of the nonlinear regression model transformation}
\authorEng
    {R.\,A.~Sologub}
\organizationEng
    {A.\,A.~Dorodnicyn Computing Centre of RAS}
    \abstractEng{\noindent
The problem of the nonlinear regression models automatic
construction and simplification has been addressed. The models describe
the results of measurements and forecasting experiments. The generated
models are designed for the approximation, analysis, and forecasting of the
experimental results. To generate the models, the expert requirements in the
subject field have been considered. This approach allows to get the interpretable models, adequately describing the given measurements.
    The goal of the paper is to investigate the problem of generation and simplification of the nonlinear regression models.
The models are supposed to be the superpositions of the
given parametric functions.
A~method of the function superposition transformation has been suggested.
The superpositions category defined over the set of directed acyclic graphs
corresponding to the superpositions have been considered.
The isomorphic superpositions notion have been introduced
and  a~method of their detection has been developed.
An algorithm of finding the isomorphic subgraphs corresponding to the generated superpositions
has been developed.

    \bigskip
\noindent
	\textbf{Keywords}: \emph {data analysis; regression model;
nonlinear regression; model generation; superposition construction}}

\begin{document}
 \maketitle
%\linenumbers
\section{Введение}
Для создания адекватной модели измеряемых данных используются
экс\-перт\-но-за\-дан\-ные порождающие функции и набор правил порождения. Модель задается в виде суперпозиции порождающих функций. Правила порождения определяют допустимость суперпозиции и исключают порождение изоморфных моделей.

В работе предлагается развить существующие методы автоматического порождения
моделей~\cite{sologub2009, sologub2013}. Исследуются методы и алгоритмы упрощения моделей и их свойства. Анализируется проблема возникновения различных топологически, но при этом равных функционально моделей. Предлагаются новые методы поиска изоморфных суперпозиций,
осно\-ван\-ные на поиске изоморфных подграфов и подстановке подграфов по правилам.

Использование нелинейной регрессии для решения прикладных задач описывается
в~работах Дж.~Себера~\cite{seber2005nonlinear, seber2009collected}.
В~них описывается построение и оценка параметров нелинейных моделей.
Для оценки параметров моделей используется алгоритм Ле\-вен\-бер\-га--Марк\-вад\-та~\cite{Levenberg44}.
Критерием качества при этом, как и в случае обычной линейной регрессии, остается среднеквадратичная
ошибка. В работах~\cite{ivakhnenko1992,madala1994inductive} индуктивное порождение моделей строится с помощью метода группового учета аргументов. В линейной модели предлагается порождать новые признаки с помощью операции произведения. С помощью полиномов Кол\-мо\-го\-ро\-ва--Га\-бо\-ра алгоритм целенаправленно порождает и перебирает мо\-де\-ли-пре\-тен\-ден\-ты различной сложности согласно ряду критериев. В результате находится модель оптимальной структуры в виде одного уравнения или системы уравнений~\cite{madala1994inductive}. Для индуктивного порождения моделей в работах Дж.~Козы~\cite{koza1992genetic,Koza:2003:GPI:945774}, связанных с генетическим программированием~\cite{Banzhaf:1998:GPI:280485,michell1998introduction}, осуществляется переход от строковой записи моделей к~префиксной записи, таким образом вводится построение модели в~виде гра\-фа-де\-рева.

Работа~\cite{KominkovaOplatkova:2013:APT:2494662.2494678}, продолжающая
работы Дж. Козы, связана с аналитическим программированием~--- дальнейшим
алгебраическим развитием методов генетического программирования. Авторы
используют строковое представление и цепочки логических предикатов в~качестве элементов модели.
В~процессе построения моделей отсекаются циклические,
а~также имеющие комплексные или бесконечные значения.

Построение прогностической модели в виде суперпозиции заданных функций,
предложенное в работе~\cite{Rudoy2012Generation} позволяет получать интерпретируемые модели, а предложенный метод штрафования суперпозиций за сложность порождает менее точные, но более простые суперпозиции. Метод преобразования и упрощения суперпозиций по правилам, рассмотренный в работе \cite{Rudoy2012Generation}, позволяет разделить построенные суперпозиции на классы эквивалентности и~выбрать из каждого класса наиболее простую (т.\,е.\ имеющую наименьшее число структурных элементов) суперпозицию, что также позволяет обосновать возможность экспертной интерпретации.  Методы построения комбинаций прогностических моделей описаны в работах \cite{KominkovaOplatkova:2013:APT:2494662.2494678,Koza:2003:GPI:945774}.
{\looseness=-1

}

Для упрощения структуры моделей используются методы теории трансформации
графов, предложенные в работе~\cite{3540311874}. Для трансформации деревьев
выделяются некоторые элементарные гра\-фы-шаб\-ло\-ны, для которых строятся оболочки
изоморфных им графов более сложной структуры. Для упрощения модели производится
рекурсивный поиск подграфов, изоморфных гра\-фам-шаб\-ло\-нам, с их заменой на более
простые подграфы. Задача упрощения моделей, представленных в виде графов,
рассматривается в работе~\cite{Mori:2009:dcaibscaal}. Авторы рассматривают
два различных метода упрощения моделей. В первом анализируется структура моделей и выделяются элементы-подграфы, которые подходят под шаблоны упрощения (например, двойное отрицание). Альтернативным методом является вычисление значений элемента модели на исходной выборке. Если значения функции совпадают со значениями более простого шаблона, осуществляется замена элемента модели шаблоном.


Цель работы --- исследование проблемы построения и~упрощения нелинейных регрессионных моделей как суперпозиций заданных параметрических функций.
Предлагается метод трансформации суперпозиций, представленных в виде категории на множестве направленных ациклических графов без самопересечений, соответствующих суперпозициям.
{\looseness=-1

}

\section{Постановка задачи}
Пусть задана выборка $D=\{(\mathbf{x}_n,y_n)\}_{n=1}^N$, $\mathbf{x}\in \mathbb{R}^m$.
Требуется построить функцию регрессии $\varphi(\mathbf{x}, \mathbf{w}) \mapsto \y$. Из множества функций $F$ требуется выбрать модель $f$~--- отображение из декартова произведения множества свободных переменных $\mathbf{x} \in \mathbb{R}^n$ и множества параметров $\mathbf{w} \in \mathbb{R}^m$ в $\mathbb{R}^1$. Сужение модели есть функция регрессии $\varphi$ с заданными значениями $\w=\w_0$. Требуется оценить набор параметров $\mathbf{w}_0$, доставляющих минимум внешнему критерию качества модели --- квадратичной ошибке:
$$
S(\mathbf{w}|D,f) = ||f(\mathbf{x}, \mathbf{w}) - y||\,.
$$
Выражение $S(\mathbf{w}|D,f)$ означает значение функции ошибки $S$, которое зависит от набора параметров $\mathbf{w}$ при заданной выборке $D$ и модели $f$. Такая модель называется оптимальной при условии, что ее сложность $C(f)$ не превышает заданную. Сложность определяется как количество элементов во всех поддеревьях, которые можно выделить из дерева, представляющего модель.
Искомую модель $f$ будем искать среди множества суперпозиций функций $g \in G$. При этом накладываются ограничения на структуру суперпозиции.
\begin{defin}
Допустимой называется суперпозиция, удовлетворяющая следующим требованиям.
\end{defin}
\begin{enumerate}
  \item Элементами суперпозици $f$ могут являться только порождающие функции $g_j$ и свободные перменные $\x$.
  \item Количество аргументов элемента суперпозиции равно арности соответствующей ему функции $g_j$.
  \item Порядок аргументов элемента суперпозиции соотвествует порядку аргументов соответствующей функции $g_j$.
  \item Для элемента $s_i$, аргументом которого является элемент $s_j$, область определения соответствующей порождающей функции $g_i$ содержит область значений порождающей функции аргумента $g_j$: $\dom(g_i) \supseteq \cod(g_j)$.
\end{enumerate}

Порождается множество моделей $f \in F$~--- допустимых
суперпозиций, состоящих из функций $g_i\in G$. Требуется выбрать
модель, доставляющую минимум $S(f|\mathbf{w}_\text{ML}^*,\frak{D})$ при условии,
накладываемом на сложность $C(f)<C^*$. Различные методы определения сложности модели будут рассмотрены в следующем разделе.

Следует заметить, что выборка вместе с суперпозициями составляет
категорию $\mathfrak{F}$, так как для данной конструкции выполняются все аксиомы теории категорий:
\begin{enumerate}
\item $\mathfrak{F}$-объектами данной категории являются множества независимых перменных $x$ и зависимых переменных $y$.
\item $\mathfrak{F}$-стрелками в данной категории являются суперпозиции $f_i$.
\item Функции $\dom(f)$ и $\cod(f)$ для суперпозиции $f$ определяются естественным образом как область определения и область значений соответствующей суперпозиции.
\item Если для пары суперпозиций $\langle f_1,f_2 \rangle$ выполняется
условие $\cod(f_1)=\dom(f_2)$, то суперпозиция $f_2$ имеет область
определения $\dom(f_2) \in \mathbb{R}^1$. Суперпозиция, в которой вместо
независимых переменных из $f_2$ будет использоваться суперпозиция $f_1$,
будет допустимой, т.\,е.\ композиция существует и входит в множество $\mathfrak{F}$-стрелок. Ассоциативность следует из того факта, что замена в суперпозиции одного аргумента на другой является ассоциативной операцией. Вообще все множество $\mathfrak{F}$-стрелок состоит из элементов~$G$ и их композиций.
\item Наличие единицы обеспечивается обязательным существованием в $G$ функции $\id(\mathbf{x})$. Для этой функции выполняется закон тождества по определению.
\end{enumerate}

\paragraph{Описание структуры модели}
Условимся считать, что каждой суперпозиции $f$ сопоставлено дерево $\Gamma_f$, эквивалентное этой суперпозиции и~строящееся следующим образом:
\begin{itemize}
  \item в~вершинах $v_i$ дерева $\Gamma_f$ находятся соответствующие порождающие функции $g_j$;
  \item число дочерних вершин у некоторой вершины $v_i$ равно арности соответствующей ей функции $g_j$;
  \item порядок дочерних вершин вершины $v_i$ соотвествует порядку аргументов соответствующей функции $g_j$;
  \item листьями дерева $\Gamma_f$ являются свободные переменные $x_i$ либо числовые параметры $w_i$.
\end{itemize}

Таким образом, вычисление значения выражения $f$ в~некоторой точке с данным вектором параметров $\mathbf{w} = \{ w_1, w_2, \dots, w_k \}$ эквивалентно подстановке соответствующих значений свободных переменных $x_i$ и параметров $w_i$ в~дерево $\Gamma_f$, где $x_i$ --- элементы вектора свободных переменных $\mathbf{x}$.

Заметим важное свойство таких деревьев: каждое поддерево $\Gamma'_f$ дерева $\Gamma_f$, корнем которого является вершина $v_i$, также соответствует некоторой суперпозиции, являющейся составляющей исходной суперпозиции~$f$.

Предложим определение сложности суперпозиции, позволяющее штрафовать суперпозиции с большим числом вложенных функций. Введем понятие сложности вершины.
\begin{defin}
Сложность $C$ суперпозиции $f$ равна сложности дерева $\Gamma$, соответствующего ей, и определяется как сумма количества элементов во всех поддеревьях дерева~$\Gamma$.
\end{defin}

Таким образом штрафуется суперпозиция, содержащая большое число вложенных функций. Определение позволяет вычислять сложность, производя обход дерева снизу вверх обратно обходу дерева <<в глубину>>~---~сложность родительской вершины равна удвоенной сложности вершин потомков плюс единица. Сложность корня и будет сложностью всей суперпозиции, $C(1,1)=C(f)$.

\section{Трансформация моделей}
 При порождении моделей в общем случае одному и тому же отображению соответствуют суперпозиции различной сложности, например одно и то же отображение соответствует моделям $x$ и $\sqrt[3]{x^3}$. Также возможны случаи порождения деревьев, некоторые ветви которых не оказывают влияния на значение функции (например, умножаются на 0). Данная проблема оказывается важной для многих классов задач,
например для построения логических функций или для задачи угадывания функции \cite{350006}. Для понимания, как упрощать подобные суперпозиции, следует ввести понятие эквивалентности моделей.
\begin{defin} Модель $f_2$ с вектором параметров $\w_2$ называется обобщающей
для модели $f_1$ с вектором параметров $\w_1$, если для любого вектора $\w_1$
найдется такой вектор~$\w_2$, что для любого $\x \in D$  значения функций $f_1(\w_1,\x)$ и $f_2(\w_2,\x)$ равны:
$$
    \x \in D \Rightarrow f_1(\w_1,\x)=f_2(\w_2,\x)\,.
$$
\end{defin}

\begin{defin}
Модели $f_1$ и $f_2$ с векторами параметров $\w_1$ и $\w_2$ называются
эквивалентными, если каждая из них является обобщающей для другой.
\end{defin}

Для построения оптимальной модели $f$ ограниченной сложности $C(f)<C_0$ необходимо найти способ трансформации модели $f$ большей структурной сложности в модель меньшей сложности $f'$ с помощью специального алгоритма  упрощения. Алгоритм упрощения модели $f(\w,\x)$ минимизирует сложность суперпозиции, соответствующей ее дереву, при условии, что результирующая модель $f'(\w',\x)$ является обобщающей моделью для исходной модели $f(\w,\x)$. При проведении данной операции какие-либо вершины и ребра из дерева, соответствующего трансформируемой модели $f$, будут удалены и будут построены другие вершины и ребра вместо них. Обобщим алгоритм упрощения на орграфы любого вида, а не только на деревья. Далее для каждого графа подразумевается, что это орграф.
\begin{defin}
Подграф $L$, удаляемый из графа $G$ в алгоритме упрощения, будет называться заменяемым подграфом.
\end{defin}
\begin{defin}
Создаваемый подграф $R$, помещаемый в граф $G$ в алгоритме упрощения, называется замещающим подграфом.
\end{defin}

Существуют по меньшей мере два широко используемых метода упрощения моделей: <<алгебраическое упрощение>>, являющееся частным случаем алгебраической трансформации графов, и <<упрощение эквивалентным решением>> \cite{Mori:2009:dcaibscaal}.

\paragraph{Алгебраический подход к трансформации графов}

Определение трансформации графа как замены одного подграфа на другой является интуитивно понятным, однако нестрогим. Для использования математического аппарата теории категория следует строго определить трансформацию графа.
\begin{defin}
Трансформацией $\mathfrak{f}$ на множестве графов $\Gamma$ является пара гиперсхем $H_1$ и $H_2$, функция поиска $\mathfrak{m}$, ставящая в соответствие гиперсхеме $H_1$ подграф $\Gamma$, соответствующий этой гиперсхеме, и взаимно
однозначное отображение $f$, ставящее в соответствие корню и листьям $H_1$ корень и листья $H_2$. При этом порождающие функции, соответствующие этим вершинам, должны совпадать.
\end{defin}

Каждой трансформации, таким образом, может быть поставлена в соответствие обратная трансформация $\mathfrak{f}^{-1}$.

В рамках алгебраического подхода к трансформации графов следует ввести категорию трансформаций графов $\mathfrak{G}$, объектами которой являются графы $\Gamma$, а стрелками --- трансформации графов $\mathfrak{f}$. Рассмотрим аксиомы категории.
\begin{enumerate}
\item $\mathfrak{G}$-объектами в данной категории являются множества графов $\Gamma$.
\item $\mathfrak{G}$-стрелками в данной категории являются трансформации графов $\mathfrak{f}_i$.
\item Функции $\dom(\mathfrak{f})$ и $\cod(\mathfrak{f})$ для трансформаций графов определяются с помощью функции поиска $\mathfrak{m}$. $\cod(\mathfrak{f})$ может быть найден как $\dom(\mathfrak{f}^{-1})$.
\item Ассоциативность следует из наличия обратной функции.
\item Единицей является трививальная трансформация с гиперсхемами $H_1=H_2=\#$.
\end{enumerate}

Алгебраический подход к трансформации графов основывается на конструкции кодекартова квадрата морфизмов.
\begin{defin}
Кодекартов квадрат морфизмов $f: Z \to Y$ и $g: Z \to X$ — это объект $P$ и два морфизма $i : X \to P$ и $j : Y \to P$, для которых следующая диаграмма коммутативна:
\end{defin}

\noindent
\vspace*{-12pt}
\begin{equation}
\begin{centering}
\xymatrix{
P & X\ar[l]^{i}\\
Y\ar[u]^{j} & Z\ar[l]^{f}\ar[u]^{g}
}
\label{cosquare}
\end{centering}
\end{equation}
Кодекартов квадрат $(P, i, j)$ является универсальным среди объектов, для которых диаграмма \eqref{cosquare} коммутативна,
т.\,е.\ для любой $(Q, i', j')$, такого что предыдущая диаграмма коммутирует, существует единственный морфизм $u : P \to Q$, делающий следующую диаграмму коммутативной: %\\[-24pt]
\begin{equation}
\begin{centering}
\xymatrix{
Q & &\\
& P\ar@{-->}[ul]^u & X\ar[l]^{i}\ar@/_10pt/[llu]_{i'}\\
& Y\ar[u]^{j}\ar@/^10pt/[luu]^{j'} & Z\ar[l]^{f}\ar[u]^{g}
}
\label{cosquare2}
\end{centering}
\end{equation}
Как и любой универсальный оператор, кодекартов квадрат определен с точностью до изоморфизма.


\begin{defin}Кодекартов квадрат морфизмов $f: Z\to X $ и $g: Z\to Y$~--- это копредел диаграммы $X\leftarrow Z\to Y$.
\end{defin}

В контексте категории графов, используемой в данной работе, кодекартов квадрат
является дизъюнктивной суммой множеств графов $X$ и $Y$, при этом элементы
с общим прообразом в множестве  $Z$ склеиваются, т.\,е.\
для каждого графа~--- элемента множества~$Z$~---
образы его вершин и ребер относительно преобразований $i \cdot g$ и $j \cdot f$ будут совпадать. В~рамках данной работы вместо термина <<кодекартов квадрат>> также будет использоваться тер\-мин-си\-но\-ним <<склейка>>. Трансформация графа может строиться сразу как два кодекартовых квадрата. Данный подход называется двойной склейкой в противоположность к~однократной склейке.
Оба подхода описаны ниже. В процессе трансформации графов каждый граф~$\Gamma_1$~---
элемент множества~$X$~--- является заменяемым и заменяющим подграфом, каждый граф $\Gamma_2$~--- элемент множества $Y$~--- неизменной частью этого графа, а элементы $Z$~--- общей частью заменяемого и заменяющего подграфов. Естественным образом вводится операция соединения графов $\Gamma_1$ и $\Gamma_2$, результатом которой является объединение множеств, при этом соответствующие вершины и ребра накладываются друг на друга.
{\looseness=-1

}

\paragraph{Трансформация двойной склейкой}

Для рассмотрения трансформации графов необходимо ввести понятие правила,
построенного в виде кодекартова квадрата морфизмов. Множества
графов $\Lambda$ и $\Phi$ являются в схеме кодекартова квадрата множеством $X$,
множество граф $\Psi$~--- множеством $Z$, а множеству $Y$ соответствует $\Delta$. Множеству $P$ для двух квадратов соответствуют начальный и конечный графы $\Gamma$ и $\Omega$.
\begin{defin} Правило~--- это тройка $p=(\Lambda,\Psi,\Phi)$, где $\Lambda$
и $\Phi$ являются заменяемым и замещающим подграфами и граф $\Psi$ является
общей частью подграфов $\Lambda$ и $\Phi$, т.\,е.\ их пересечением.
Заменяемый, или начальный, подграф $\Lambda$ называется условием применения
правила; замещающий, или конечный, подграф $\Phi$ --- итогом его применения. Подграф $\Psi$ описывает часть графа, необходимую для применения правила, но неизменную в процессе применения. Множество $\Lambda \setminus \Psi$ является удаляемой частью графа, вместо нее создается множество $\Phi\setminus \Psi$.
\end{defin}
\begin{defin}
Процедура поиска $\m$~--- отображение из $\Lambda$ в $\Gamma$, ставящая в соответствие заменяемому графу эквивалентный ему подграф. При этом процедура $\mathfrak{m}$ сохраняет структуру графа $\Gamma$.
\end{defin}
\begin{defin}
Трансформация графа~--- это пара, элементами которой являются правило $p$ и процедура поиска $\mathfrak{m}$. Процедура трансформации графа $\Gamma$ в граф $\Omega$ с помощью правила $p$ и процедуры поиска $\mathfrak{m}$ будет также обозначаться как $\Gamma \overset{p,\m}{\to} \Omega$.
\end{defin}

Процедура трансформации графа правилом $p$ и процедурой поиска $\mathfrak{m}$ состоит из двух шагов. На первом шаге все ребра и вершины, соответствующие множеству $\Lambda\setminus \Psi$, удаляются из графа $\Gamma$. Удаляемая часть может не являться графом, но оставшаяся структура $\Delta=\{\Gamma\setminus \mathfrak{m}(\Lambda)\} \bigcup \mathfrak{m}(\Psi)$ должна оставаться графом, т. е. в ней не должно быть подвешенных ребер. Таким образом, процедура поиска $\mathfrak{m}$ должна удовлетворять условию соединения графов, т.\,е.\
результатом соединения $\Lambda\setminus \Psi$ и $\Delta$ является граф $\Gamma$
(см. диаграмму~(\ref{trans1})). На втором шаге трансформации граф $\Delta$
соединяется с графом $\Phi\setminus \Psi$ для образования производного графа
$\Omega$ (см. диаграмму~(\ref{trans1})). Так как подграфы $\Lambda$ и~$\Phi$
могут иметь пересечение~$\Psi$, подграф~$\Psi$ существует и в начальном
графе~$\Gamma$ и не удаляется на первом шаге, т.\,е.\ существует
и~в~промежуточном графе~$\Delta$. Для присоединения новых ребер и вершин
к~графу~$\Delta$ используется граф~$\Psi$. Таким образом определяются
присоединенные вершины, с~по\-мощью которых граф~$\Phi$ присоединяется к графу $\Delta$. Для получения графа оптимальной структуры процедура одиночной трансформации графа может быть выполнена несколько раз.

Формально трансформация графа задается следующим образом. Пусть даны правило
$$p = ( \Lambda \leftarrow \Psi \rightarrow \Phi)$$
и промежуточный граф $\Delta$, который включает в себя $\Psi$, тогда исходный
граф $\Gamma$ трансформации $\Gamma \rightarrow \Omega$  с помощью правила $p$~---
 это соединение $\Lambda$ и $\Delta$ с помощью $\Psi$:
$$\Gamma= \Lambda + _\Psi \Delta\,,$$
а результирующий граф $\Omega$ определяется как соединение $\Phi$ и $\Delta$ с помощью~$\Psi$:
$$\Omega= \Phi + _\Psi \Delta\,.$$
Более точно используются морфизмы
\[r:\Psi\rightarrow \Lambda\,; \qquad l:\Psi \rightarrow \Phi\,; \qquad k:\Psi \rightarrow \Delta\]
для того, чтобы показать, каким образом $\Psi$ входит в $\Lambda$,
$\Phi$ и $\Delta$ соответственно. Данный способ построения начального
графа $\Gamma$ и конечного графа $\Omega$ позволяет определить конструкции
соединения $\Gamma= \Lambda + _\Psi \Delta$ и $\Omega= \Phi + _\Psi \Delta$
как конструкции склейки (см. диаграмму~(\ref{trans1})). Таким образом,
диаграмма~(\ref{trans1}) является двойным кодекартовым квадратом. Ре\-зуль\-ти\-ру\-ющий
морфизм $\n: \Phi \rightarrow \Omega$ называется ко-поиском трансформации $\Gamma \rightarrow \Omega$. Данная функция является функцией поиска в графе $\Omega$ подграфа, изоморфного заменяющему подграфу $\Phi$. Коммутативная диаграмма для трансфомации графа строится следующим образом:
%
%\noindent
\begin{equation}
\begin{centering}
\xymatrix{\Lambda\ar[dd]^\m&&\Psi\ar[ll]_r\ar[rr]^l\ar[dd]^k&&\Phi\ar[dd]^\n\\
&(1)&&(2)\\
\Gamma&&\Delta\ar[ll]_g\ar[rr]^h&&\Omega}
\label{trans1}
\end{centering}
\end{equation}
Для применения правила $p$ с процедурой поиска $\mathfrak{m}$ подграфа $\Lambda$ в графе $\Gamma$, при заданном морфизме $\mathfrak{m}: \Lambda \rightarrow \Gamma$, как показано на коммутативной диаграмме~\eqref{trans1}, в первую очередь необходимо построить промежуточный граф $\Delta$
такой, что соединение $\Lambda+_\Psi \Delta$ даст результатом граф $\Gamma$.
На следующем шаге строим соединение $\Phi + _\Psi \Delta$ графов $\Phi$
и~$\Delta$ с~по\-мощью графа~$\Psi$, получая граф~$\Omega$, и,~таким образом,
получаем процедуру двойной склейки $\Gamma \hm\rightarrow \Omega$ с~по\-мощью
правила~$p$ и процедуры поиска~$\mathfrak{m}$. Для первого шага необходимо
выполнение условия соединения графов, что позволяет нам построить~$\Delta$
из условия $\Gamma= \Lambda \hm+ _\Psi \Delta$. Для процедуры $\mathfrak{m}$
условие соединения означает, что все подвешенные вершины~$\Lambda$, т.\,е.\
вершины $v \in \Lambda$, такие, что~$\mathfrak{m}(v)$ является начальной или конечной вершиной некоторого
ребра~$e$, принадлежащего $\Gamma\setminus \Lambda$, должны быть в~$\Psi$.

Рассмотрим пример двойной склейки:
\begin{equation}
\begin{centering}
\shorthandoff{"}
\def\p#1{\save
[].[dddrr]!C="p#1"*++[F]\frm{}\restore}%
\xymatrix @C-40Pt@R-25Pt@!C@!R{
 \p1& (4)\ar[dr]  &   &    &   &\p2&    &   &   &    &\p3&  &    \\
 (1)\ar[ur]\ar[dr]&   &(2)&    &   &(1)&    &(2)&   &    &(1)\ar[rr]\ar[dr]&   &(2) \\
    &(5)\ar[ur]&   &    &   &   &    &   &   &    &   &(3)\ar[ur]&    \\
    &   &\;\;\;\;\;&    &   &   &    &\;\;\;\;\;&   &    &   &   &\;\;\;\;\; \\
 \Lambda  &   &   &    &   & \Psi &    &   &   &    & \Phi &   &    \\
    &   &   &    &(PO1)& &    &   &   &(PO2)&  &   &    \\
 \Gamma  &   &   &    &   & \Delta &    &   &   &    & \Omega &   &    \\
 \p4&(4)\ar[dr]   &   &    &   &\p5&    &   &   &    &\p6& &    \\
 (1)\ar[ur]\ar[dr]\ar[dd]&   &(2)\ar[dd]&    &   &(1)\ar[dd]&    &(2)\ar[dd]&   &    &(1)\ar[rr]\ar[dr]\ar[dd]&   &(2)\ar[dd] \\
    &(5)\ar[ur]&   &    &   &   &    &   &   &    &   &(3)\ar[ur]&    \\
 (6)\ar[rr]&   &(7)&    &   &(6)\ar[rr]&    &(7)&   &    &(6)\ar[rr]&   &(7)
 \ar@{}"p2";"p1"^(.27){}="t12"^(.73){}="t21" \ar "t12";"t21"
 \ar@{}"p2";"p3"^(.27){}="t23"^(.73){}="t32" \ar "t23";"t32"
 \ar@{}"p2";"p5"^(.27){}="t25"^(.73){}="t52" \ar "t25";"t52"
 \ar@{}"p1";"p4"^(.27){}="t14"^(.73){}="t41" \ar "t14";"t41"
 \ar@{}"p3";"p6"^(.27){}="t36"^(.73){}="t63" \ar "t36";"t63"
 \ar@{}"p5";"p4"^(.27){}="t54"^(.73){}="t45" \ar "t54";"t45"
 \ar@{}"p5";"p6"^(.27){}="t56"^(.73){}="t65" \ar "t56";"t65"
 }
\shorthandon{"}
\label{trans3}
\end{centering}
\end{equation}




Данная диаграмма соответствует общей схеме~(\ref{trans1}).
Следует заметить, что в диаграмме~(\ref{trans1}) граф $\Gamma$ является соединением графов $\Lambda$ и $\Delta$ с помощью $\Psi$, причем обозначения вершин показывают, как вершины размечаются при применении морфизмов.

Рассмотрим условие корректности построения структуры графа $\Delta$.
Разметка ребер может быть единственным образом выведена из разметки вершин.
Условие соединения вершин выполнено на диаграмме~(\ref{trans3}), потому что
подвешенные вершины (1) и (2), принадлежащие $\Lambda$, также являются
соединительными вершинами. Таким образом, не остается подвешенных ребер,
выходящих из вершин (1) и (2). При этом граф $\Omega$ является соединением
графов $\Phi$ и $\Delta$ вместе с $\Psi$, что приводит к трансформации
$\Gamma \rightarrow \Omega$ с~по\-мощью правила~$p$. Фактически диаграммы~(\ref{trans1})
 и~(\ref{trans3}) являются кодекартовыми квадратами в категории графов, состоящей из графов и морфизмов на них.

Сформулируем точное условие соединения графов при трансформации графа. Для этого вводим следующие определения.

\begin{defin}
Точки соединения~--- вершины и ребра в $\Lambda$, которые не удаляются при применении правила $p$.
\end{defin}
\begin{defin}
Точки обнаружения~--- вершины и ребра в $\Lambda$, образы которых относительно $\m$ имеют более одного прообраза.
\end{defin}
\begin{defin}
Подвешенные вершины~--- вершины в $\Lambda$, образы которых относительно $\m$ в $\Gamma$ имеют входящие или выходящие ребра, не содержащиеся в $\Lambda$.
\end{defin}

В данных определениях условие соединения графа выглядит следующим образом.

\begin{theorem}{\textbf{\cite{3540311874}}} %[14]}
Пусть даны правило $p = (\Lambda \leftarrow \Psi \to \Phi)$, граф $\Gamma$
и процедура поиска $\m:\Lambda \to \Gamma$. Вершины графов обозначаются
буквой $V$, ребра~--- $E$. Тогда правило~$p$ с~процедурой поиска~$\m$
удовлетворяет условию соединения, если все точки обнаружения и~подвешенные вершины также являются точками соединения.
\end{theorem}

Докажем данную теорему от противного. Пусть существует подвешенная вершина $v_0$, не являющаяся точкой соединения. Данная вершина удаляется из $\Gamma$ при применении правила $p$. Однако в $\Gamma$ существуют ребра, не содержащиеся в $\Lambda$ и присоединенные к $v_0$. Таким образом, полученный граф будет недопустимым, потому что у некоторых ребер не будет начала или конца. Точки обнаружения являются точками соединения, так как иначе правило будет внутренне противоречивым.$\Box$

Ограничения, накладываемые естестенным образом на трансформации двойной склейкой, не позволяют удобно производить многие операции с графами, используемые на практике. Так, операция замены вершины поддерева $v_i$ не может быть описана в виде заменяемого и замещающего графов, состоящих из одной вершины, так как если в заменяемом графе всего одна вершина $v_i$, эта вершина не будет являться подвешенной, только если весь граф состоит из одной вершины. Таким образом, для применения трансформаций предлагается метод, сопоставляющий неудовлетворяющей условиям трансформации набор допустимых трансформаций.

\begin{theorem}
Любой трансформации $t=(\Lambda_t,\Psi_t,\Phi_t)$ графа соответствует набор правил $p_t=(\Lambda_{p_t},\Psi_{p_t},\Phi_{p_t})$, удовлетворяющих условию соединения, такой, что любое применение трансформации $t$ аналогично применению одного из правил $p_t$.
\end{theorem}

Данная теорема доказывается конструктивно~--- рассматриваются все возможные наборы количеств ребер, которые могут иметь точки соединения $v_c$, и для каждого набора создаются заменяемый и замещающий подграфы, в который добавляются вершины типа $ \# $ на концах всех ребер, выходящих из $v_c$ и не содержавшихся ранее в заменяемом подграфе $\Lambda$.$\Box$

Морфизмы $\Psi \rightarrow \Lambda$ и $\Psi \rightarrow \Phi$ в произведениях
могут быть ограничены как инъективные морфизмы~--- каждому образу в $\Lambda$
и~$\Phi$ соответствует только один проообраз из $\Psi$. Тем не менее возможны
неинъективные варианты процедур поиска $\mathfrak{m} : \Lambda \rightarrow
\Gamma$ и ко-по\-ис\-ка $\mathfrak{n} : \Phi \hm\rightarrow \Omega$.
Это может быть особенно важным, когда рассматривается параллельное применение правил:
 $$p_1 \bigoplus p_2:\Lambda_1 \bigoplus \Lambda_2 \leftarrow \Psi_1 \bigoplus \Psi_2 \rightarrow \Phi_1 \bigoplus \Phi_2\,,$$
где $\bigoplus$ означает дизъюнктивное объединение. Даже для инъективных
вариантов $\mathfrak{m}_1: \Lambda_1\hm\rightarrow \Gamma$ c помощью $p_1$ и $\mathfrak{m}_2: \Lambda_2\rightarrow \Gamma$ с помощью $p_2$, итоговая операция $\mathfrak{m} : \Lambda_1 + \Lambda_2 \rightarrow \Gamma$ не является инъективной, если образы процедур поиска $\mathfrak{m}_1(\Lambda_1)$ и $\mathfrak{m}_2(\Lambda_2)$ имеют непустое пересечение в~$\Gamma$.
\begin{theorem} Существует набор трансформаций $(p_1,\m_1)$ и $(p_2,\m_2)$, такой, что их параллельное применение имеет неинъективную функцию поиска $\m=\m_1 \bigoplus \m_2$.
\end{theorem}

Построим пример таких трансформаций. Пусть трансформация преобразует
дерево~$\Gamma_0$, соответствующее функции
$f_0=(x+1)*(x-1 + x^2-x+1),$
и есть два правила
$$p_1=\{(x+1)(x-1),x^2-1\}\,;\quad p_2=\{(x+1)(x^2-x+1),x^3+1\}\,.$$
В обоих этих правилах подграф $\Psi$ является пустым. Обе процедуры поиска $\m_1$ и $\m_2$ будут находить часть суперпозиции $(x+1)$. Из этого следует, что при объединении $\Lambda_1$ и $\Lambda_2$
у~одного образа из $\Gamma$ будет более одного прообраза, т.\,е.\
объединенное правило $p_{12}$ дважды найдет в графе $\Gamma_0$ подграф, соотвествующий суперпозиции $(x+1)\cdot$.$\Box$

Для рассмотрения случаев применения нескольких трансформаций необходимо определить условие, при котором трансформации могут применяться последовательно и параллельно. Введем понятия параллельно и последовательно независимых трансформаций.

\begin{defin}
Две трансформации графов $\Gamma \overset{p_1,m_1}{\to} \Omega_1$ и $\Gamma \overset{p_2,m_2}{\to} \Omega_2$ являются параллельно независимыми, если все вершины и ребра, попадающие в образ обоих морфизмов поиска, являются соединительными:
$$
    \m_1(\Lambda_1)\bigcap \m_2(\Lambda_2) \subseteq \m_1(l_1(\Psi_1))\bigcap \m_2(l_1(\Psi_2)).
$$

Две трансформации графов $\Gamma \overset{p_1,m_1}{\to} \Omega_1$ и $\Omega_1 \overset{p_2,m_2}{\to} \Omega_2$ являются последовательно независимыми, если все вершины и ребра, попадающие в пересечение морфизмов $\n_1$ и $m_2$, являются соединительными:
$$
    \n_1(\Phi_1)\bigcap \m_2(\Lambda_2) \subseteq \n_1(r_1(\Psi_1))\bigcap \m_2(l_2(\Psi_2)).
$$
\end{defin}

Следует заметить, что для графов-деревьев возникает простой достаточный критерий пареллельной и последовательной независимости трансформаций, если их замещаемые графы $\Lambda$ являются односвязными.
\begin{theorem}
Две трансформации графов-деревьев $\Gamma \overset{p_1,m_1}{\to} \Omega_1$ и $\Gamma \overset{p_2,m_2}{\to} \Omega_2$ являются параллельно и последовательно независимыми, если образы корней $v_1$ и $v_2$ деревьев $\m_1(\Lambda_1)$ и $\m_2(\Lambda_1)$ не принадлежат друг другу:
%
\begin{equation}
    v_1 \not\in \m_2(\Lambda_2) \,;\quad v_2 \not\in \m_1(\Lambda_1)\,.
    \label{treeindep}
\end{equation}
\end{theorem}

Данная теорема простым образом доказывается от противного.
Пусть условие~(\ref{treeindep}) выполняется и существует вершина~$v_0$,
принадлежащая пересечению множеств $\m_1(\Lambda_1)$ и~$\m_2(\Lambda_1)$.
Тогда в графе будет цикл, проходящий через вершины $v_1$, $v_0$, $v_2$
и~корень дерева. Но в дереве не может быть циклов.$\Box$

 Определение независимости оказывается неудобным для применения, так как оно слабо формализовано. Определим необходимое и достаточное условие, при котором графы являются параллельно или последовательно независимыми через существование соответствующих морфизмов.

\begin{theorem}{\textbf{\cite{3540311874}}}
Две трансформации графов $\Gamma \overset{p_1,m_1}{\to} \Omega_1$ и $\Gamma \overset{p_2,m_2}{\to} \Omega_2$ являются параллельно независимыми, если существуют морфизмы $i:\Lambda_1 \to \Delta_2$ и $j:\Lambda_2 \to \Delta_1$, такие, что $f_2 \circ i = \m_1$ и $f_1 \circ j = \m_2$:
\end{theorem}
%
\begin{equation*}
\begin{centering}
\xymatrix{
\Phi_1\ar[d]|-{\n_1}&\Psi_1\ar[l]_{r_1}\ar[r]^{l_1}\ar[d]|-{k_1}&\Lambda_1\ar[dr]|-{\m_1}\ar@/^1pc/@{-->}[drrr]|-(.75){i}&   &\Lambda_2\ar[dl]|-{\m_2}\ar@/_1pc/@{-->}[dlll]|-(.75){j}&\Psi_2\ar[l]_{l_2}\ar[r]^{r_2}\ar[d]|-{k_2}&\Phi_2\ar[d]|-{\n_2}\\
\Omega_1&\Delta_1\ar[l]_{g_1}\ar[rr]^{f_1}&   &\Gamma  &   &\Delta_2\ar[ll]_{f_2}\ar[r]^{g_2}&\Omega_2
}
%\label{indep1}
\end{centering}
\end{equation*}

\begin{theorem}
Две трансформации графов $\Gamma \overset{p_1,m_1}{\to} \Omega$ и $\Omega \overset{p_2,m_2}{\to} \Gamma'$ являются последовательно независимыми, если существуют морфизмы $i:\Phi_1 \to \Delta_2$ и $j:\Lambda_2 \to \Delta_1$, такие, что $f_2 \circ i = \n_1$ и $g_1 \circ j = \m_2$:
\end{theorem}
%
\begin{equation*}
\begin{centering}
\xymatrix{
\Lambda_1\ar[d]|-{\n_1}&\Psi_1\ar[l]_{l_1}\ar[r]^{r_1}\ar[d]|-{k_1}&\Phi_1\ar[dr]|-{\n_1}\ar@/^1pc/@{-->}[drrr]|-(.75){i}&   &\Lambda_2\ar[dl]|-{\m_2}\ar@/_1pc/@{-->}[dlll]|-(.75){j}&\Psi_2\ar[l]_{l_2}\ar[r]^{r_2}\ar[d]|-{k_2}&\Phi_2\ar[d]|-{\n_2}\\
\Gamma&\Delta_1\ar[l]_{f_1}\ar[rr]^{g_1}&   &\Omega  &   &\Delta_2\ar[ll]_{f_2}\ar[r]^{g_2}&\Gamma'
}
%\label{indep2}
\end{centering}
\end{equation*}

\textbf{Доказательство.} Рассмотрим необходимость и достаточность критерия для параллельной независимости. Для последовательной независимости доказательство будет строиться аналогичным образом. Вершина $v \in \Lambda_1$ или принадлежит множеству $\m_2(\Lambda_2)$, или лежит вне его. Рассмотрим оба случая.
\begin{enumerate}
\item Множество $\m_1(v) \not\in \m_2(\Lambda_2)$. Все вершины графа $\Gamma$ являются образами при применении отображений $\m_2$ или $f_2$. Отсюда $\m_1(v) \in f_2(\Delta_2)$.
\item Множество $\m_1(v) \in \m_2(\Lambda_2)$. Тогда $\m_1(v) \in \m_1(\Lambda_1)\cap \m_2(\Lambda_2)\subseteq \m_1(l_1(\Psi_1))\cap \m_2(l_2(\Psi_2))$. При этом из коммутативной диаграммы следует, что $\m_2(l_2(\Psi_2))=f_2(k_2(\Psi_2))$. Отсюда $\m_1(v) \in f_2(\Delta_2).$
\end{enumerate}

В обоих случаях оказывается, что $\m_1(x) \in f_2(\Delta_2)$, так что инъективность $f_2$ позволяет нам определить $i(x)=f_2^{-1} \circ \m_1(x)$. Аналогично, $j$ определяется из условия $f_1 \circ j = \m_2$.

При данных $i,j$ с $f_2 \circ i =m_1$ и $f_1 \circ j =m_2$
пусть $y \in \m_1(\Lambda_1) \bigcap \m_2(\Lambda_2)$. Тогда $y \hm\in \m_1(L_1) \bigcap f_1(j(\Lambda_2))$.
Из условия кодекартова квадрата следует, что существует $z_1 \in \Psi_1$, такое, что $y=\m_1(l_1(z_1))=f_1
(k_1(z_1))$. Значит, $y \in \m_1(l_1(\Psi_1))$, аналогично $y \in \m_2(l_2(\Psi_2))$, откуда следует условие независимости $\m_1(\Lambda_1)\bigcap \m_2(\Lambda_2) \subseteq \m_1(l_1(\Psi_1))\bigcap \m_2(l_1(\Psi_2))$.$\Box$

С использованием данных критериев можно определить, как связаны друг с другом независимые параллельно и последовательно трансформации. Данная теорема является частным случаем теоремы Черча--Россера. %\cite{Kozen_church–rossermade}.

\paragraph{Трансформация одиночной склейкой}
Как было отмечено, конструкции соединения в алгебраическом подходе являются кодекартовыми квадратами в смысле морфизмов категории графов. С другой стороны, правило $p = ( \Lambda \leftarrow \Psi \rightarrow \Phi)$ может быть также рассмотрено как частичный морфизм графов $p: \Lambda \rightarrow \Phi$, доменом которого является множество $\dom(p)=\Psi$. Более того, диаграмма $(\Gamma \leftarrow \Delta \rightarrow \Omega)$ может быть рассмотрена как частичный морфизм графов $s:\Gamma \rightarrow \Omega$ с~доменом $\dom(s)=\Delta$. Таким образом, получается следующая диаграмма: %\\[-36pt]
%
%\noindent
\begin{equation}
\shorthandoff{"}
\def\p#1{\save
[].[dddrr]!C="p#1"*++[F]\frm{}\restore}%
\xymatrix @C-20Pt@R-15Pt{
  \p1&   &   &   &&&   & \p2&(4)\ar[dr]&   \\
 (1)\ar[rr]\ar[dr]&   &(2)&&&  &   &(1)\ar[dr]\ar[ur]&   &(2)\\
    &(3)\ar[ur]&   &&&   &   &   &(5)\ar[ur]&   \\
    &   &\;\;\;\;\;&&&   &   &   &   &\;\;\;\;\;\\
 L  &   &   &&&   &   &R  &   &   \\
    &   &   &&&   &   &   &   &   \\
 G  &   &   &&&   &   &H  &   &   \\
  \p3&   &   &&&   &   & \p4&(4)\ar[dr]&   \\
 (1)\ar[rr]\ar[dr]\ar[dd]&   &(2)\ar[dd]^e&&&   &   &(1)\ar[ur]\ar[dr]\ar[dd]&   &(2)\ar[dd]^e\\
    &(3)\ar[ur]&   &&&   &   &   &(5)\ar[ur]&   \\
 (6)\ar[rr]&   &(7)&&&   &   &(6)\ar[rr]&   &(7)
  \ar@{}"p1";"p2"^(.32){}="t12"^(.68){}="t21" \ar "t12";"t21"^p
 \ar@{}"p1";"p3"^(.28){}="t13"^(.70){}="t31" \ar "t13";"t31"
 \ar@{}"p2";"p4"^(.28){}="t24"^(.70){}="t42" \ar "t24";"t42"
 \ar@{}"p3";"p4"^(.32){}="t34"^(.68){}="t43" \ar "t34";"t43"^s
 }
\shorthandon{"}
\label{trans4-0}
\end{equation}

%\vspace*{-18pt}
\noindent
На данной диаграмме горизонтальные морфизмы являются частичными,
а вертикальные~--- полными морфизмами графов. По сути, диаграмма~(\ref{trans4-0})
является кодекартовым квадратом в расширенной категории графов, которая состоит из графов и частичных морфизмах на графах и показывает, что трансформации графов могут быть выражены как одиночные кодекартовы квадраты в расширенной категории графов. Данный подход развивался Раулем~\cite{Raoult19841} и был полностью разработан Лёве~\cite{raey}, итогом их работы является подход однократного вытеснения.


С точки зрения прикладного использования подход с одиночным вытеснением отличается от подхода с двойным вытеснением в одном главном отношении, которое касается удаления вспомогательных элементов графа в процессе трансформации графа. Процедура поиска $m:\Lambda \rightarrow \Gamma$ не удовлетворяет условию соединения по отношению к правилу $p = ( \Lambda \leftarrow \Psi \rightarrow \Phi)$, поэтому данное правило не применимо в подходе с двойным вытеснением. Но оно может быть применимо в подходе с однократным вытеснением, которое позволяет появляться подвешенным ребрам после удаления подграфа $\Lambda\setminus \Psi$ из $\Gamma$. Следует заметить, что подвешенные ребра из $\Gamma$ также удаляются для создания допустимого графа~$\Omega$.

Если на диаграмме~(\ref{trans3}) вершина (2) была бы удалена из $\Psi$,
то конструкция соединения не удовлетворяла бы подходу с двойным вытеснением.
В подходе с однократным вытеснением это значило бы, что вершина~(2)
не находится в домене $p$, что ведет к~подвешенному ребру в~$\Gamma$
после удаления $\Lambda \setminus \dom(p)$ на диаграмме: %\\[-24pt] %~(\ref{trans4}).
\begin{equation*}
\begin{centering}
\shorthandoff{"}
\def\p#1{\save
[].[ddrr]!C="p#1"*++[F]\frm{}\restore}%
\xymatrix @C-40Pt@R-25Pt@!C@!R{
 \p1& +\ar@{-}[dl] &   &    &   &\p2& + &   &   &    &\p3& +\ar@{-}[dl]  &    \\
 \ast\ar@{-}[d]\ar@{-}[dr]&   & &    &   & &    & &   &    &\text{sqr}\ar@{-}[d]&   & \\
 x_2 &x_2 &   &    &   & x_2 &    &   &   &    & x_2  & &    \\
 \Lambda  &   &   &    &   & \Psi &    &   &   &    & \Phi &   &    \\
    &   &   &    &(PO1)& &    &   &   &(PO2)&  &   &    \\
 \Gamma  &   &   &    &   & \Delta &    &   &   &    & \Omega &   &    \\
 \p4& +\ar@{-}[dl]\ar@{-}[dr] &   &    &   &\p5& +\ar@{-}[dr] &   &   &    &\p6& +\ar@{-}[dl]\ar@{-}[dr]  &    \\
 \ast\ar@{-}[d]\ar@{-}[dr]&   &\text{lin}\ar@{-}[d] &    &   & &    &\text{lin}\ar@{-}[d] &   &    &\text{sqr}\ar@{-}[d]&   &\text{lin}\ar@{-}[d] \\
 x_2 &x_2 & x_3  &    &   & x_2 &    & x_3  &   &    & x_2  & &x_3
 \ar@{}"p2";"p1"^(.27){}="t12"^(.73){}="t21" \ar "t12";"t21"
 \ar@{}"p2";"p3"^(.27){}="t23"^(.73){}="t32" \ar "t23";"t32"
 \ar@{}"p2";"p5"^(.27){}="t25"^(.73){}="t52" \ar "t25";"t52"
 \ar@{}"p1";"p4"^(.27){}="t14"^(.73){}="t41" \ar "t14";"t41"
 \ar@{}"p3";"p6"^(.27){}="t36"^(.73){}="t63" \ar "t36";"t63"
 \ar@{}"p5";"p4"^(.27){}="t54"^(.73){}="t45" \ar "t54";"t45"
 \ar@{}"p5";"p6"^(.27){}="t56"^(.73){}="t65" \ar "t56";"t65"
 }
\shorthandon{"}
%\label{trans4}
\end{centering}
\end{equation*}
В~результате ребро~$e$ удялется из~$\Omega$.

Более подобное описание и сравнение данных подходов разобрано в~\cite{Ehrig:1999:HGG:320647}.

\paragraph{Прикладная задача упрощения суперпозиций}



При последовательном порождении моделей зачастую оказывается так, что некоторые части модели становятся рудиментарными. Упрощение Соула~\cite{soule:2002:GPEM} является вариантом алгебраического упрощения, в котором объектами упрощения являются элементы моделей, параметры которых не влияют на значение функции. Область применения подобных методов ограничена~\cite{soule:2002:GPEM}, однако они показывают хороший результат на некоторых задачах, например
при обнаружении функции. В данном типе задачи восстановления регрессии дисперсия случайной ошибки равна нулю
и~выборка генерируется в соответствии с~ка\-кой-ли\-бо эталонной функцией $f_0$, которая должна быть обнаружена алгоритмом.

Упрощение эквивалентным решением заключается в сравнении значений моделей,
а~не структур. Эквивалентность моделей проверяется не по структуре деревьев,
со\-от\-вет\-ст\-ву\-ющих им, а численно. В таком случае два выражения, дающие равные значения на области определения независимых переменных модели, считаются равными.

\begin{defin}
Шаблон $\theta$ --- гиперсхема, обладающая наименьшей сложностью среди всех гиперсхем, таких, что при их взаимном замещении получаемые модели оказываются эквивалентными. Сложность гиперсхемы определяется как сложность суперпозиции при замещении всех символов $\{=\}$ и $\{ \# \}$, означающих соответственно произвольную независимую переменную и произвольное поддерево, на константы.
\end{defin}

Экспертно выбирается некоторый набор шаблонов $\Theta$. Процедура упрощения состоит из двух шагов.
\begin{enumerate}
\item  Все поддеревья $\Gamma_j$ в выбранном дереве $\Gamma$ проверяются на эквивалентность шаблонам из $\Theta$ согласно заданным правилам.

\item  Если какое-либо поддерево $\Gamma_j$ в дереве эквивалентно дереву из $\Theta$, данное поддерево заменяется соответствующим элементом из $\Theta$.
\end{enumerate}

Процедура повторяется до тех пор, пока после вышеперечисленных итераций
дерево~$\Gamma$ не останется неизменным. При наличии в множестве порождающих
функций коммутативных функций вводится алфавитное упорядочение для ветвей,
выходящих из вершины~$\gamma_i$ дерева~$\Gamma$, соответствующей коммутативной порождающей функции~$g_i$.

Эквивалентное упрощение является альтернативой алгебраическому упрощению, позволяя упрощать некоторые модели за меньшее количество операций.

Рассмотрим сложность алгоритма, упрощающего поддерево высоты $l$ с вершинами арности не более $m$. Количество вершин в таком дереве ограничивается сверху как $m^l$. Рассмотрим дерево с максимальным количеством вершин~--- для такого дерева все вершины, кроме листьев, будут иметь арность $m$.
Для сравнения всех возможных поддеревьев с~шаблонами из~$\Theta$
необходимо рассмотреть поддеревья любой высоты с корнем в каждой из
вершин дерева. Подсчитаем количество поддеревьев всех возможных высот
в~таком дереве. Обозначим высоту данного дерева $l=\log_m k+1$. Тогда
для вершины, находящейся на расстоянии~$x$ от корня,
количество поддеревьев с корнем в этой вершине составляет не менее чем $l-x$. Тогда искомое количество поддеревьев:
$$
  \sum_{x=0}^{l-1} (l-x) m^x = \frac{m (m^l-1)-lm+l}{(m-1)^2}\,.
$$
Данное выражение пропорционально $m^l$, т.\,е.\ количеству элементов в дереве,
все вершины которого (кроме листьев) имеют максимальное число потомков.
Сложность алгоритма, упрощающего дерево, состоящее из $k$ вершин, оказывается
порядка не менее чем~$k$. В~случае если алгоритм проверки правил эквивалентности имеет значительную сложность, подсчет значений оценок зависимых переменных $\hat{y}$ на множестве независимых переменных $x \in D$ и сравнение этих значений с получаемыми при использовании шаблонов $\Theta$ имеет значительно меньшую сложность. Данный метод может применяться в случае, если независимые и зависимые переменные принимают ограниченное число значений. Для такого поддерева, вне зависимости от количества элементов $k$ в нем, область определения соответствующей функции содержит $2^t$ точек, где $t$ --- количество независимых переменных, являющихся листьями данного поддерева.
При небольших~$t$ число $2^t$ не превосходит~$k$, и~в~таком случае алгоритм сравнения по значениям оказывается менее сложным, чем алгоритм сравнения структур поддеревьев с шаблонами.

Важным частным случаем использования алгоритма упрощения по значениям является случай равенства функций на области определения независимых переменных при необязательном равенстве вне этой области. Для решения прикладной задачи функции, дающие равные значения на области определения, будут равны, и подобная замена будет корректна.

\section{Заключение}
В работе предложены методы направленного порождения, модификации и упрощения нелинейных регрессионных моделей. Описаны условия существования решений, получаемых в результате порождения, доказаны необходимые теоремы.
Разработан метод последовательного направленного порождения суперпозиций, введено понятие изоморфных суперпозиций, исследованы свойства порождаемых суперпозиций.
Предлагаемые в работе методы упрощения моделей предназначены непосредственно для применения на практике. Создана базовая библиотека правил порождения экспертно-интерпретируемых моделей.

\renewcommand{\bibname}{Литература}
\begin{thebibliography}{99}

\bibitem{sologub2009} %1
    \BibAuthor{Стрижов~В.\,В., Сологуб~Р.\,А.}
    Индуктивное порождение поверхности волатильности опционных торгов~//
Вычислительные технологии, 2009. №\,5. С.~102--113.

\bibitem{sologub2013} %2
    \BibAuthor{Сологуб~Р.\,А.}
    Алгоритмы порождения нелинейных регрессионных моделей~//
Информационные технологии, 2013. №\,5. С.~8--12.

\bibitem{seber2005nonlinear} %3
    \BibAuthor{Seber~G., Wild~C.\,J.}
    Nonlinear regression.~--- Wiley ser. in probability and statistics.~--- John Wiley \& Sons, 2005. 2907 p.

\bibitem{seber2009collected}        %4
   \BibAuthor{Seber~G.}
    The collected works of George A.\,F.~Seber.~--- Wiley ser. in
probability and statistics.~--- Wiley, 2009. 792 p.

\bibitem{Levenberg44}
    \BibAuthor{Levenberg~K.}
    A method for the solution of certain non-linear problems in least squares~//
Quart. J. Appl. Math., 1944. Vol.~II. No.\,2. P.~164--168.

\bibitem{ivakhnenko1992}
    \BibAuthor{Ивахненко А.\,Г.}
    Индуктивный метод самоорганизации моделей сложных систем.~--- Киев: Наукова думка, 1982. 296 с.

\bibitem{madala1994inductive}
    \BibAuthor{Madala~H.\,R., Ivakhnenko~A.\,G.}
    Inductive learning algorithms for complex systems modeling.~---
CRC Press, 1994. 384 p.

\bibitem{koza1992genetic}
    \BibAuthor{Koza~J.\,R.}
    Genetic programming: On the programming of computers by means of natural selection.~---
 Complex adaptive systems ser.~--- 1st ed.~--- Cambridge, MA\,--\,London:
The MIT Press, 1992. 840~p.

\bibitem{Koza:2003:GPI:945774}
    \BibAuthor{Koza~J.\,R., Keane M.\,A., Streeter~M.\,J., \textit{et al}.}
    Genetic programming IV: Routine human-competitive machine intelligence.~--- Norwell, MA, USA: Kluwer Academic Publs., 2003. 590 p.

\bibitem{Banzhaf:1998:GPI:280485}
    \BibAuthor{Banzhaf~W., Francone F.\,D.,  Keller R.\,E., Nordin~P.}
    Genetic programming~--- an introduction:
On the automatic evolution of computer programs and its applications.~---
San Francisco, CA, USA: Morgan Kaufmann Publs. Inc., 1998. 490~p.

\bibitem{michell1998introduction}
    \BibAuthor{Michell M.}
    An introduction to genetic algorithms.~--- Cambridge, MA\,--\,London: The
MIT Press, 1998. 164~p.

\bibitem{KominkovaOplatkova:2013:APT:2494662.2494678}
    \BibAuthor{Kominkova Oplatkova Z.,  Senkerik R.,  Zelinka I.,  Pluhacek M.}
    Analytic programming in the task of evolutionary synthesis of a controller
for high order oscillations stabilization of discrete chaotic systems~//
Comput. Math. Appl., 2013. Vol.~66. No.\,2. P.~177--189.

\bibitem{Rudoy2012Generation}
    \BibAuthor{Рудой~Г.\,И., Стрижов~В.\,В.}
    Алгоритмы индуктивного порождения суперпозиций для аппроксимации
измеряемых данных~// Информатика и её применения, 2013. Т.~7. Вып.~1. С.~17--26.

\bibitem{3540311874}
    \BibAuthor{Ehrig H., Ehrig K., Prange U., Taentzer G.}
   Fundamentals of algebraic graph transformation.~--- Berlin: Springer, 2006. 390 p.

\bibitem{Mori:2009:dcaibscaal}
    \BibAuthor{Naoki M., McKay B., Xuan N., \textit{et al.}}
   A new method for simplifying algebraic expressions in genetic programming
called equivalent decision simplification~// Distributed computing,
artificial intelligence, bioinformatics, soft computing, and ambient assisted
living~/ Eds. S.~Omatu, M.\,P.~Pocha, J.~Bravo, \textit{et al}.~---
Lecture notes in computer science ser.~---
Salamanca, Spain: Springer, 2009. Vol.~5518. P.~171--178.

\bibitem{350006}
    \BibAuthor{D'haeseleer~P.}
   Context preserving crossover in genetic programming //
1st IEEE Conference on Computational Intelligence Proceedings:
Evolutionary Computation, 1994. Vol.~1. P.~256--261.

\bibitem{Raoult19841}
    \BibAuthor{Raoult~J.\,C.}
   On graph rewritings~// Theor. Comput. Sci., 1984. Vol.~32. No.\,1. P.~1--24.

\bibitem{raey}
    \BibAuthor{L\"{o}we~M., Ehrig~H.}
   Algebraic approach to graph transformation based on single pushout
derivations~// Graph-theoretic concepts in computer science~/
Ed. R.~M\"{o}hring.~--- Lecture notes in computer science ser.~---
Berlin--Heidelberg: Springer, 1991. Vol.~484. P.~338--353.

\bibitem{Ehrig:1999:HGG:320647}
    Handbook of graph grammars and computing by graph transformation.
Vol.~3: Concurrency, parallelism, and distribution~/
Eds. H.~Ehrig, H.-J.~Kreowski, U.~Montanari, G.~Rozenberg.~--- River Edge,
NJ, USA: World Scientific Publishing Co., Inc., 1999. 572 p.

\bibitem{soule:2002:GPEM}
    \BibAuthor{Soule~T., Heckendorn~R.\,B.}
    An analysis of the causes of code growth in genetic programming~//
Genet. Program. Evol. M., 2002. Vol.~3. No.\,3. P.~283--309.

\end{thebibliography}

\renewcommand{\bibname}{References}
\begin{thebibliography}{99}


\bibitem{sologub2009}
{Strijov,~V.\,V., and R.\,A.~Sologub.} 2009.
    Inductive generation of the regression models for option volatility.
\BibJournal{Russ. J.~Computational Technologies} 5:102--113. (In Russian.)

\bibitem{sologub2013}
    {Sologub,~R.\,A.} 2013.
    Algorithms for the nonlinear regression models generation.
\BibJournal{Russ. J.~Information Technologies} 5:8--12. (In Russian.)

\bibitem{seber2005nonlinear}
{Seber,~G., and C.\,J. Wild.} 2005.
\BibTitle{Nonlinear regression}. Wiley ser. in probability and statistics.
John Wiley \& Sons. 2907 p.


\bibitem{seber2009collected}
{Seber,~G.} 2009.
  \BibTitle{The collected works of George A.\,F. Seber}.
Wiley ser. in probability and statistics. Wiley. 792 p.


\bibitem{Levenberg44}
{Levenberg,~K.} 1944.
    A method for the solution of certain non-linear problems in least squares.
\BibJournal{Quart. J. Appl. Math.} II(2):164--168.

\bibitem{ivakhnenko1992}
    {Ivakhnenko, A.\,G.} 1982.
\BibTitle{Inductive method of self-organized complex models system}.
Kiev: Naukova Dumka. 296 p. (In Russian.)

\bibitem{madala1994inductive}
{Madala,~H.\,R., and A.\,G.~Ivakhnenko.} 1994.
\BibTitle{Inductive learning algorithms for complex systems modeling}.
CRC Press. 384 p.

\bibitem{koza1992genetic}
{Koza,~J.\,R.} 1992.
\BibTitle{Genetic programming: On the programming of computers by means of natural selection}.
1st ed.
Complex adaptive systems ser. Cambridge, MA\,--\,London: The MIT Press. 840~p.

\bibitem{Koza:2003:GPI:945774}
    {Koza, J.\,R., M.\,A.~Keane, M.\,J.~Streeter, \textit{et al.}} 2003.
\BibTitle{Genetic programming IV: Routine human-competitive machine
intelligence}. Norwell, MA: Kluwer Academic Publs. 590 p.

\bibitem{Banzhaf:1998:GPI:280485}
    {Banzhaf, W., F.\,D.~Francone, R.\,E.~Keller, and P.~Nordin.} 1998.
\BibTitle{Genetic programming~--- an introduction: On the automatic evolution
of computer programs and its applications}.
San Francisco, CA: Morgan Kaufmann Publs. Inc. 490~p.

\bibitem{michell1998introduction}
    {Michell, M.} 1998.
    \BibTitle{An introduction to genetic algorithms}.
%Complex Adaptive Systems Series.
Cambridge, MA\,--\,London: The MIT Press. 164~p.

\bibitem{KominkovaOplatkova:2013:APT:2494662.2494678}
{Kominkova Oplatkova,~Z.,  R. Senkerik, I. Zelinka, and M.~Pluhacek}. 2013.
    Analytic programming in the task of evolutionary synthesis of a controller
for high order oscillations stabilization of discrete chaotic systems.
\BibJournal{Comput. Math. Appl.} 66(2):177--189.

\bibitem{Rudoy2012Generation}
{Rudoy,~G.\,I., and V.\,V.~Strijov.} 2013.
    Algorithms for inductive generation of superpositions for approximation
of experimental data. \BibJournal{Informatika i~ee Primeneniya}~---
\textit{Inform. Appl}. 7(1):17--26.

\bibitem{3540311874}
{Ehrig, H., K. Ehrig, U. Prange, and G.~Taentzer.} 2006.
\BibTitle{Fundamentals of algebraic graph transformation}.
Berlin: Springer. 390 p.

\bibitem{Mori:2009:dcaibscaal}
{Naoki, M., B. McKay, N.~Xuan, \textit{et al}.} 2009.
   A new method for simplifying algebraic expressions in genetic programmingc
alled equivalent decision simplification.
\BibTitle{Distributed computing, artificial intelligence, bioinformatics,
soft computing, and ambient assisted living}. Eds.\ S.~Omatu, M.\,P.~Rocha,
J.~Bravo, \textit{et al.} Lecture notes in
computer science ser. Salamanca, Spain: Springer. 5518:171--178.

\bibitem{350006}
{D'haeseleer,~P.} 1994.
   Context preserving crossover in genetic programming.
\BibJournal{1st IEEE Conference on Computational Intelligence Proceedings:
Evolutionary Computation}. 1:256--261.

\bibitem{Raoult19841}
{Raoult,~J.\,C.} 1984.
 On graph rewritings. \BibJournal{Theor. Comput. Sci.} 32(1):1--24.

\bibitem{raey}
{L\"{o}we,~M., and H.~Ehrig.} 1991.
\BibTitle{Algebraic approach to graph transformation based on single pushout
derivations}. Ed. R.~M\"{o}hring. Lecture notes in computer science ser.
 Berlin--Heidelberg: Springer. 484:338--353.

\bibitem{Ehrig:1999:HGG:320647}
Ehrig,~H.,  H.-J.~Kreowski, U. Montanari, and G.~Rozenberg, eds.  1999.
\BibTitle{Handbook of graph grammars and computing by graph transformation.
Vol.~3: Concurrency, parallelism, and distribution}.
River Edge, NJ: World Scientific Publishing Co., Inc. 572 p.

\bibitem{soule:2002:GPEM}
{Soule,~T., and R.\,B.~Heckendorn.} 2002.
    An analysis of the causes of code growth in genetic programming.
\BibJournal{Genet. Program. Evol. M.} 3(3):283--309.
\end{thebibliography}


\end{document}

