\documentclass[12pt,twoside]{article}
\usepackage{jmlda}
\usepackage{cite}
\usepackage{graphicx, epsfig}
\usepackage{subfig}
%\usepackage{multicol}
\usepackage{tikz}

\newcommand{\hdir}{./eps/}

\newcommand*{\vect}[1]{\overrightarrow{#1}}
\newcommand*{\egref}[1]{(\ref{#1})}
%\graphicspath{ {eps/} }
\def\bblsep{sep}
\def\bbloct{oct}
%\NOREVIEWERNOTES
\title
%    [Определение области затенения радужки классификатором локальных текстурных признаков % Краткое название; не нужно, если полное название влезает в~колонтитул
    {Определение видимой области радужки классификатором локальных текстурных признаков}
\author
   % [Автор~И.\,О.] % список  авторов для колонтитула; не нужен, если основной список влезает в колонтитул
    {И.\,А. Соломатин, И.\,А. Матвеев} % основной список авторов, выводимый в оглавление
   % [Автор~И.\,О.$^1$, Соавтор~И.\,О.$^2$, Фамилия~И.\,О.$^2$] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\organization
    {МФТИ; ВЦ РАН, Москва, Россия}
\thanks
    {Работа выполнена при финансовой поддержке РФФИ, проект \No\,15-01-05552.
%   Научный руководитель:  Стрижов~В.\,В.
%   Задачу поставил:  Матвеев~И.\,А.
%   Консультант:  Матвеев~И.\,А.
}
\email
    {ivan.solomatin@phystech.edu}
%\organization
%    {$^1$Организация; $^2$Организация}
\abstract
    {Распознавание человека по изображению радужной оболочки ~--- актуальная
задача в~биометрических системах. Помимо выделения радужки как кольцевой
области для повышения точности распознавания определяют области затенения
(блики, веки, ресницы и~т.\,д.). Задача выделения затенений радужки может
быть поставлена как классификация пикселей кольцевой области на два класса:
<<радужка>> и <<затенение>>. В кольцевой об\-ласти определяется сектор
с~минимальной дисперсией яркости, который, как правило, не содержит
затенений (в данной работе этот сектор не вычисляется, а рассматривается
как часть входных данных алгоритма). Далее строится классификатор на основе
многомерного гауссиана, который обучается на выборке,  задаваемой
 по пикселям этого сектора. Параметры классификатора были оптимизированы с помощью генетического алгоритма. Проблема шума и ошибок с классификацией некоторых участков изображения решается с помощью применения морфологической постобработки. Был проведен вычислительный эксперимент,
и~получено распределение функционала качества алгоритма.
%    Это задача классификации по 2-м классам. Использования ручной разметки для обучения классификатора можно избежать, если помимо изображения радужки и окружностей, аппроксимирующих границы радужки, алгоритму подается на вход некоторый сектор радужки S, не содержащий областей затенения. Данная статья посвящена задаче выделения областей затенения без тренировки на размеченных вручную изображениях, но с учетом сектора S.
\newline

\bigskip
\noindent
\textbf{Ключевые слова}: \emph {обработка изображений; распознавание образов;
биометрическая идентификация по радужке}}
\titleEng
    {Detecting visible areas of iris by qualifier of~local~textural~features}
\authorEng
    {I.\,A. Solomatin, I.\,A. Matveev}
\organizationEng
    {MIPT; CC RAS, Moscow, Russia}
\abstractEng
    {\noindent
A person recognition by the image of the iris is an actual problem.
To increase the accuracy of recognition, usually areas of occlusion are
detected in addition to locating of the iris as an annular region. The
problem of occlusion detection can be set as the classification of pixels
from annular region into two classes: ``iris'' and ``occlusion.''
 In the annular region, the segment with minimum dispersion of brightness
is selected, which usually contains no occlusion (in this article,
 this segment is not calculated and supposed to be a part of the input data).
 Then, a~classifier based on multivariate Gaussian is built and
after that, it is trained on the training set, which is
 set by local textural features of the pixels from this sector. The parameters of the classifier were optimized using genetic algorithm. The problems with noise and errors of classification in particular areas of the image are solved by applying morphological
postprocessing. A~computational experiment was carried out and it allowed to obtain the distribution of the functional of quality of the algorithm.

    \bigskip
\noindent
    \textbf{Keywords}: \emph{image processing; pattern recognition;
biometric identification by iris}}
\begin{document}
\maketitle
%\linenumbers
\newpage
\section{Введение}
\renewcommand{\labelitemi}{$\bullet$}
Необходимый этап биометрической идентификации по радужной оболочке ~---
сегментация радужки, т.\,е.\ выделение области изображения, содержащей
только радужку. В сегментацию помимо выделения окружностей, аппроксимирующих
внешнюю и внутреннюю границы радужной оболочки, входит выделение областей
затенения. Последняя задача достаточно важна для распознавания человека по
радужке, так как ее решение задает конечную эффективную область для
распознавания. В англоязычной литературе эта задача называется
EES  (Eyelids, Eyelashes, Shadows) localization.
Существуют различные подходы к~ее решению.
В \cite{conf/icip/Daugman02} осуществляется выделение области век
с использованием ин\-теграль\-но-диф\-фе\-рен\-циальных операторов, граница века аппроксимируется некоторой кривой. В \cite{bb95018} для локализации век используется преобразование Хафа. В \cite{bb94769} граница века аппроксимируется параболой. В \cite{bb94887} для обнаружения затенений используется мера качества радужки, вводится вероятностная мера качества радужки, основанная на смеси многомерных гауссианов, которая сравнивается с мерой, основанной на преобразовании Фурье. Для распознавания ресниц в \cite{bb95039} применяется статистическая оценка. В \cite{bb94767} описан метод распознавания век, использующий горизонтальный медианный фильтр и распознавание границ. В \cite{bb94813} для распознавания ресниц используется оператор Собеля, затем ресницы удаляются с изображения с помощью медианного фильтра.
Существуют решения, выделяющие все затенения сразу (без разделения на веки, ресницы, блики
и~т.\,п.). Одно из таких решений описано в \cite{conf/icassp/LiS09}, в нем применяется классификатор, основанный на смесях гауссианов, разделяющий точки на два класса: <<радужка>> и <<затенение>>. Для обучения классификатора используются изображения, размеченные вручную.

Недостатками метода \cite{conf/icassp/LiS09} являются необходимость в ручной разметке и использование одного и того же классификатора для всех изображений. Единый классификатор для всех изображений является сомнительным решением вследствие того, что изображения разных радужных оболочек могут иметь значительные вариации текстурных признаков (разная структура, разное освещение
и~т.\,д.), что при обучении на большой выборке порождает очень широкий класс <<радужка>>, обладающий малой разделяющей способностью, а при обучении на малой выборке ~--- узкий класс, не пригодный для многих изображений.

В данной работе предлагается использовать классификатор на основе многомерного гауссиана, обучающийся на незатененном секторе $S$. Использование сектора $S$ для обучения позволяет избежать использования обучающей выборки, размеченной вручную,
т.\,е. построить полностью автоматический метод.
Таким образом, содержание работы~--- реализация алгоритма поиска областей
затенения с использованием сектора $S$ вместо ручной разметки. В качестве сектора $S$ используется сектор с минимальной дисперсией яркости с фиксированным углом раствора. Важно заметить, что в данной работе прежде всего ставился вопрос о принципиальной работоспособности метода распознавания затенений на основе классификатора, обучающегося на элементе того же изображения. Вопрос максимальной оптимизации пока не ставился. В дальнейшем, в частности, будет подробнее изучен вопрос нахождения сектора~$S$
и~вопрос выбора признаков, по которым строится классификатор.

\section{Постановка задачи}
На вход подается черно-белое изображение $I$, которое является прямоугольной
матрицей $W{\times}H$ из целых беззнаковых однобайтовых чисел $I(i, j) \in
[0; 255]$,  задающих яркость каждого пикселя изображения. Также на вход подаются координаты центров и радиусы двух окружностей, аппроксимирующих внешнюю и внутреннюю границу радужки (вычисленные, например, методами \cite{IrisSeg}), и незатененный сектор $S$, задаваемый серединным углом $\alpha$ и раствором \nolinebreak $\Delta\alpha$.
%Последнее число задает сектор следующим образом: углы измеряются в \textit{отсчетах}. Один отсчет = $\frac1{512}$ полной окружности, т.е. $\frac{\pi}{256}$ (отсчет ведется от оси абсцисс по часовой стрелке). Считается, что задаваемый сектор всегда имеет один и тот же раствор ~--- $40$ \textit{отсчетов}. Число, подаваемое на вход ~--- это полярный угол серединного луча задаваемого сектора, выраженный в \textit{отсчетах}.

Требуется выделить области затенения, т.\,е.\ области изображения, на которых
изображена не радужка, а веко, ресница, блик и т.\,п.
Строго говоря, нужно классифицировать все точки изображения,
лежащие внутри кольца, аппроксимирующего радужку по двум классам~---
<<радужка>> и <<затенение>>, т.\,е.\ получить бинарное изображение $J$:
\begin{equation}
\label{output}
J(i, j) \in \{0, 1\};\quad i \in [1; H];\enskip j \in [1, W],
\end{equation}
где $J(i,j) = 1 \Leftrightarrow $ точка $(i, j)^\mathrm{T}$ классифицирована как затенение.\\
\vspace{-0.3cm}
\section{Метод решения}
Рассмотрим точки, находящиеся внутри сектора $S = \{\vec{x_n}\}_{n=1}^{N}$,
где $N$ --- число точек, принадлежащих $S$. Локальные текстурные признаки
этих точек будут являться обуча\-ющей выборкой для классификатора.
На рис.~\ref{fig:Sectors} приведены примеры сектора $S$ для различных изображений радужки.\\
\begin{center}
\begin{figure}[h]
\centering
\subfloat[$S$ не содержит затенений]{\includegraphics[width=0.3\textwidth]{\hdir/gamma_iris1.eps}}
\hfill
\subfloat[$S$ не содержит затенений]{\includegraphics[width=0.3\textwidth]{\hdir/gamma_iris2.eps}}
\hfill
\subfloat[$S$ содержит затенения]{\includegraphics[width=0.3\textwidth]{\hdir/gamma_iris0.eps}}
\caption{Примеры секторов с минимальной дисперсией яркости (выделены светлым)}
\label{fig:Sectors}
\end{figure}
\end{center}
\vspace{-0.5cm}

Стоит заметить, что в качестве сектора $S$ выбирается сектор с фиксированым
 раствором $\Delta \alpha$ такой, что его дисперсия минимальна, и, строго
говоря, этот сектор может содержать затенения. В таких случаях точность
распознавания не может быть высокой. Пример того, как наличие затенений
в секторе $S$ влияет на точность распознавания, рассмотрен в разд.~5
(пример 3, рис.~\ref{fig:samp3}). В данном примере сектор $S$ содержит ресницы;
 таким образом, классификатор, обученный по этому сектору, не считает ресницы затенениями, что уменьшает точность. В дальнейшем планируется написать более точный алгоритм поиска незатененного сектора радужки.


В качестве локальных текстурных признаков выбираются следующие $K = 8$ признаков:
\begin{enumerate}[1.]

\item $B(\vec{x_n})$ ~--- яркость в точке $\vec{x_n} = (x, y)^\mathrm{T}$:
\begin{equation*}
B(\vec{x_n}) = I(x, y)\,.
\end{equation*}

\item $\overline{B}(\vec{x_n})$ ~--- средняя яркость в окрестности точки $\vec{x_n}$ (в окне размера $a$).\\
В качестве окна размера $a$ будем использовать квадрат со стороной $2a+1$.
Тогда количество точек в окне размера $a$ равно $(2a+1)^2$.\\
Обозначим момент яркости в окрестности размера $a$ точки $\vec{x_n}$:
\begin{equation*}
M^{(z)}_a = \cfrac1{(2a+1)^2} \sum\limits_{i = -a}^{a} \sum\limits_{j = -a}^{a} I^z(x+i, y+j).
\end{equation*}
Тогда
\begin{equation} \label{param2}
\overline{B}(\vec{x_n}) = M_a^{(1)}.
\end{equation}

\item $\sigma(\vec{x_n})$ ~--- среднеквадратичное отклонение яркости в окрестности точки $\vec{x_n}$ (в окне размера $b$):
\begin{equation} \label{param3}
\sigma(\vec{x_n}) = \sqrt{ M_b^{(2)} - \left( M_b^{(1)} \right)^2 }\,.
\end{equation}
%\sigma(\vec{x_n}) = \sqrt{ \left( \cfrac1{(2b+1)^2} \sum\limits_{j = -b}^{b} \sum\limits_{k = -b}^{b} I^2[x+j, y+k] \right) - \left(\cfrac1{(2b+1)^2} \sum\limits_{j = -b}^{b} \sum\limits_{k = -b}^{b} I[x+j, y+k] \right)^2 }

\item $\vec{C}(\vec{x_n})$ ~--- вектор из пяти компонент дискретного косинусного преобразования в окрестности точки $\vec{x_n}$.

Как правило, дискретное косинусное преобразование считается в окне $w{\times}h$, где $w=h=8$, но так как в данном случае, из соображений симметрии, желательно, чтобы окно было симметрично центрированным, используется окно $7{\times}7 \;\; (w=h=7)$. Двумерное дискретное косинусное преобразование в окне $w{\times}h$ при $w=h=7$
c~центром в~точке $(x, y)^\mathrm{T}$:
\begin{multline*} %\label{param4}
\widehat{C}_{p, q}(x, y) =  \alpha_p \alpha_q \sum\limits_{i=-3}^{3} \sum\limits_{j=-3}^{3} I(x+i, y+j) \cos\cfrac{\pi(2i+7)p}{2h} \cos\cfrac{\pi(2j+7)q}{2w}\,,
\\
0\leq p \leq h-1; \quad 0\leq q \leq w-1,
\end{multline*}
где
\begin{equation*}
\alpha_p = \left\{ \begin{aligned} &\cfrac1{\sqrt{w}}, p = 0\,; \\ &
\cfrac{\sqrt2}{\sqrt{w}}, 1 \leq p \leq h-1\,; \end{aligned} \right.  \;\;\;\;\;\;
\alpha_q = \left\{ \begin{aligned} &
\cfrac1{\sqrt{h}}, q = 0\,; \\ &\cfrac{\sqrt2}{\sqrt{h}}, 1 \leq q \leq w-1\,. \end{aligned} \right.
\end{equation*}
Из полученной матрицы коэффициентов $7{\times}7$ берутся первые 5 коэффициентов
за исключением $\widehat{C}_{0, 0}$ (рис.~\ref{fig:DCT}), так как коэффициент $\widehat{C}_{0, 0}$ равен средней яркости в окрест\-ности, которая уже используется в качестве признака:
\begin{figure}[H]
\begin{center}
\begin{tikzpicture}
\filldraw[fill=black!20!white, draw=black] (0-1,-1+1) -- (1-1,-1+1) -- (1-1,-2+1) -- (0-1,-2+1) -- (0-1,-1+1);
\filldraw[fill=black!20!white, draw=black] (0-1,-2+1) -- (1-1,-2+1) -- (1-1,-3+1) -- (0-1,-3+1) -- (0-1,-2+1);
\filldraw[fill=black!20!white, draw=black] (1-1,-0+1) -- (2-1,-0+1) -- (2-1,-1+1) -- (1-1,-1+1) -- (1-1,-0+1);
\filldraw[fill=black!20!white, draw=black] (1-1,-1+1) -- (2-1,-1+1) -- (2-1,-2+1) -- (1-1,-2+1) -- (1-1,-1+1);
\filldraw[fill=black!20!white, draw=black] (2-1,-0+1) -- (3-1,-0+1) -- (3-1,-1+1) -- (2-1,-1+1) -- (2-1,-0+1);
\draw [->, ultra thick] (4, -1) -- (4.6, -1);
\foreach \x in {0,...,3}
    \foreach \y in {0,...,3}
    {
        \draw (\x ,-\y ) +(-1,+1) rectangle ++(0, 0);
        \draw (\x  - 0.5,-\y  +0.5 ) node{(\x,\y)};
    }

    \draw [-, thin] (4-1 , 1 ) -- (4.5-1, 1) ;
    \foreach \y in {0,...,3}
    {
        \draw [-, thin] (3 ,-\y ) -- (3.5, -\y) ;
        \draw (4  - 0.5,-\y  +0.5 ) node{$\ldots$};
    }
    \draw [-, thin] (-1 ,-3 ) -- (-1, -3.5) ;
    \foreach \x in {0,...,3}
    {
        \draw [-, thin] (\x ,-3 ) -- (\x, -3.5) ;
        \draw (\x  - 0.5,-4  +0.5 ) node{$\vdots$};
    }
    \draw (4  - 0.5,-4  +0.5 ) node{$\ddots$};

\filldraw[fill=black!20!white, draw=black] (6-1,-1+1) -- (6  ,-1+1) -- (6  ,-2+1) -- (6-1,-2+1) -- (6-1,-1+1);
\filldraw[fill=black!20!white, draw=black] (6-1,-2+1) -- (6  ,-2+1) -- (6  ,-3+1) -- (6-1,-3+1) -- (6-1,-2+1);
\filldraw[fill=black!20!white, draw=black] (6  ,-0+1) -- (6+1,-0+1) -- (6+1,-1+1) -- (6  ,-1+1) -- (6  ,-0+1);
\filldraw[fill=black!20!white, draw=black] (6  ,-1+1) -- (6+1,-1+1) -- (6+1,-2+1) -- (6  ,-2+1) -- (6  ,-1+1);
\filldraw[fill=black!20!white, draw=black] (6+1,-0+1) -- (6+2,-0+1) -- (6+2,-1+1) -- (6+1,-1+1) -- (6+1,-0+1);
\draw (6+0  - 0.5,-1  +0.5 ) node{$C_1$};
\draw (6+0  - 0.5,-2  +0.5 ) node{$C_3$};
\draw (6+1  - 0.5,-0  +0.5 ) node{$C_2$};
\draw (6+1  - 0.5,-1  +0.5 ) node{$C_4$};
\draw (6+2  - 0.5,-0  +0.5 ) node{$C_5$};
\foreach \x in {0,...,3}
    \foreach \y in {0,...,3}
    {
        \draw (6+\x ,-\y ) +(-1,+1) rectangle ++(0, 0);
%        \draw (5+\x  - 0.5,-\y  +0.5 ) node{(\x,\y)};
    }
    \draw [-, thin] (9 , 1 ) -- (9.5, 1) ;
    \foreach \y in {0,...,3}
    {
        \draw [-, thin] (9 ,-\y ) -- (9.5, -\y) ;
        \draw (10 - 0.5,-\y  +0.5 ) node{...};
    }
    \draw [-, thin] (5 ,-3 ) -- (5, -3.5) ;
    \foreach \x in {6,...,9}
    {
        \draw [-, thin] (\x ,-3 ) -- (\x, -3.5) ;
        \draw (\x  - 0.5,-4  +0.5 ) node{$\vdots$};
    }
    \draw (10  - 0.5,-4  +0.5 ) node{$\ddots$};

\end{tikzpicture}
\caption{Используемые коэффициенты дискретного косинусного преобразования} \label{fig:DCT}
\end{center}
\end{figure}
\begin{equation*}
\vec{C}(\vec{x_n}) = (\widehat{C}_{0, 1}, \widehat{C}_{1, 0}, \widehat{C}_{0, 2}, \widehat{C}_{1, 1}, \widehat{C}_{2, 0})^\mathrm{T}.
\end{equation*}
\end{enumerate}

В формулах \egref{param2} и \egref{param3} размеры окрестностей $a$ и $b$ выступают в качестве параметров алгоритма.\\

Каждой точке сектора $S: \vec{x_n} = (x, y)^\mathrm{T}$ сопоставляем вектор из признаков:
\begin{equation*}
\vec{p_n} = (B(\vec{x_n}), \overline{B}(\vec{x_n}), \sigma(\vec{x_n}), (\vec{C}(\vec{x_n}))^\mathrm{T})^\mathrm{T}\,.
\end{equation*}
Находим средний вектор:
\begin{equation*}
\vec{\mu} = \cfrac1N \sum \limits_{n = 1}^N \vec{p_n}\,;
%\end{equation}
%\begin{equation}
\qquad \vec{\hat{p}_n} = \vec{p_n} - \vec{\mu}\,.
\end{equation*}
Из векторов $\vec{\hat{p}_n}$ составляется матрица объект-признак $M$ размерности $K{\times}N$:
\begin{equation*}
M = \left( \begin{matrix}
\vec{\hat{p}_1} 			& \vec{\hat{p}_2} & \cdots & \vec{\hat{p}_n}
\end{matrix} \right)\,.
\end{equation*}
Предполагаем, что объекты в пространстве, задаваемом данными параметрами,
 распределены по многомерному гауссиану. Гипотезу о принадлежности каждого пикселя классу <<радужка>> принимаем или отвергаем, основываясь на расстоянии Махаланобиса.

Матрица ковариаций, нормированная на средний вектор, задается следующей формулой:
\begin{equation*}
C = MM^\mathrm{T}.
\end{equation*}
Расстояние Махаланобиса от $\vec{x}$ до $\vec{\mu}$:
\begin{equation*}
D(\vec{x}) = \sqrt{(\vec{x}-\vec{\mu})^\mathrm{T}C^{-1}(\vec{x}-\vec{\mu})}\,.
\end{equation*}
Считаем, что пиксель $\vec{x}$ лежит в классе <<радужка>>, если
\begin{equation} \label{Prob}
\exp{(-D^2(\vec{x})) } > P_{\text{порог}}\,.
\end{equation}\\
Таким образом, алгоритм задается следующими параметрами: $a, b,
P_{\text{порог}}$, где $a$ и $b$ ~--- размеры окон (окрестностей) для
расчета 1-го и 2-го признаков \egref{param2} и~\egref{param3}, а $P_{\text{порог}}$ ~--- пороговое значение в формуле \egref{Prob}. Для определения оптимальных значений указанных параметров был использован генетический алгоритм.

\section{Подбор параметров}
Важно заметить, что применение генетического алгоритма для подбора
параметров является не обучением, а настройкой алгоритма, т.\,е.
параметры выбираются единожды и~фиксируются.

Для применения генетического алгоритма нужно ввести функцию ошибки алгоритма для оценки качества решения для конкретных параметров. Пусть результат работы алгоритма равен $J$, а экспертная разметка областей затенения равна $\hat{J}$, где $J$ и $\hat{J}$ --- бинарные изображения вида \egref{output}.

Пусть $N_0$ ~--- общее количество классифицируемых точек, лежащих внутри
заданной границы радужки, а $\hat{N}_0$ ~--- количество точек, классифицируемых
как затенения в экспертной разметке. Обозначим через $\delta_{\mathrm{Iris}}
(i, j)$ индикаторную функцию множества точек, лежащих внутри кольца, аппроксимируещего область радужки. Тогда
\begin{equation*}
N_0 = | \{(i, j) \; | \; \delta_{\mathrm{Iris}}(i, j) = 1\} | ;
\;\;\; \hat{N}_0 = | \{(i, j) \; | \; \delta_{\mathrm{Iris}}(i, j) \hat{J}(i, j) = 1\} |.
\end{equation*}
Тогда относительная ошибка первого рода равна
\begin{equation*}
E_1 = \cfrac1{\hat{N}_0} \sum_{i=1}^{H} \sum_{j=1}^{W} \hat{J}(i, j)(1 - J(i, j)) \delta_{\mathrm{Iris}}(i, j),
\end{equation*}
а относительная ошибка второго рода равна
\begin{equation*}
E_2 = \cfrac1{N_0 - \hat{N}_0} \sum_{i=1}^{H} \sum_{j=1}^{W} J(i, j)(1 - \hat{J}(i, j)) \delta_{\mathrm{Iris}}(i, j).
\end{equation*}
Функция ошибки определяется как сумма относительных ошибок первого и второго рода:
\begin{equation*}
E= E_1 + E_2\,.
\end{equation*}

В данном генетическом алгоритме особь --- это вектор, состоящий из трех
параметров алгоритма: $v = (a, b, P_{\text{порог}})^\mathrm{T}$. Оценка
качества особи производилась на наборе из $M = 10$ изображений с экспертной
разметкой затенений: $\mathcal{I} = \{I_m\}_{m = 1}^{M}$, т.\,е.
функция качества особи определялась
как средняя точность алгоритма на изображениях из $\mathcal{I}$:
\begin{equation*}
f(v) = f \left( \begin{matrix} a \\ b \\ P_{\text{порог}} \end{matrix} \right)  = \cfrac1M\sum\limits_{m = 1}^{M} \left(1-E(I_m, a, b, P_{\text{порог}})\right),
\end{equation*}
где $E(I, a, b, P)$~--- значение функции ошибки алгоритма с параметрами
$(a, b, P)$ на изображении $I$. Селекция выполнялась методом рулетки, т.\,е.
вероятность выбора особи $v$ в~качестве родителя пропорциональна $f(v)$.

В генетическом алгоритме использовались следующие генетические операторы:
\begin{itemize}
\item cкрещивание:
\begin{equation*}
v \otimes w = \left( \begin{matrix} a_1 \\ b_1 \\ P_1 \end{matrix} \right) \otimes \left( \begin{matrix} a_2 \\ b_2 \\ P_2 \end{matrix} \right) = \left( \begin{matrix} r(a_1, a_2) \\ r(b_1, b_2) \\ r(P_1, P_2) \end{matrix} \right)\,,
\end{equation*}
где $r(x, y)$ ~--- случайная величина (распределенная по Бернулли):
\begin{equation*}
r(x, y) = \left\{ \begin{aligned}
&x& \text{ с вероятностью } p = \frac13 \,;            \\
&y& \text{ с вероятностью } p = \frac13 \,;            \\
&\cfrac{x+y}2& \text{ с вероятностью } p = \frac13 \,; \\
\end{aligned} \right.
\end{equation*}
\item мутация:
\begin{equation*}
M(v) = M \left( \begin{matrix} a \\ b \\ P \end{matrix} \right) =
\left\{ \begin{aligned}
&v& \text{ с вероятностью } p = \frac23              \,;  \\
&(r_1, b, P)^\mathrm{T}& \text{ с вероятностью } p = \frac19 \,;  \\
&(a, r_1, P)^\mathrm{T}& \text{ с вероятностью } p = \frac19\,;  \\
&(a, b, r_2 )^\mathrm{T}& \text{ с вероятностью } p = \frac19 \,,  \\
\end{aligned}\right.
\end{equation*}
где $r_1$ --- дискретная случайная величина, равномерно распределенная
на [1, 15]; $r_2$ --- непрерывная случайная величина, равномерно
распределенная на [0{,}6, 1]. Было проведено вычисление 15 поколений при размере популяции в 10 особей. На рис. \ref{fig:gen} приведен график зависимости максимальной функции качества в популяции от номера поколения в процессе выполнения генетического алгоритма. Лучшей особью в начальной популяции является вектор $v_0 = (5, 5, 0{,}7)^\mathrm{T}$.
\end{itemize}
\begin{figure}[H]
\center{\includegraphics[height=8cm]{\hdir/genetics_graph.eps}}
\caption{Зависимость максимальной функции качества в популяции от номера поколения}
\label{fig:gen}
\end{figure}

В результате работы генетического алгоритма получены следующие параметры:
\begin{equation*}
v^* = \left( \begin{matrix} a \\ b \\ P \end{matrix} \right) = \left( \begin{matrix} 10 \\ 7 \\ 0{,}85 \end{matrix} \right); \;\;\; f(v^*) = 0{,}664.
\end{equation*}
Строго говоря, утверждать, что данные параметры являются оптимальными,
нельзя, однако на рис. \ref{fig:gen} видно, что $f(v^*)$ больше, чем
$f(v_0)$, т.\,е. подбор параметров генетическим алгоритмом улучшил результат. Это так же видно на гистограммах на рис.~\ref{fig:hist}
(см.\ разд.~5).
\begin{center}
\begin{figure}[t]
\centering
\subfloat [Параметры $v_0$] {\includegraphics[width = 0.3\textwidth]{\hdir/gamma_res0bad.eps}}
\hspace{0.1\textwidth}
\subfloat [Параметры $v^*$] {\includegraphics[width = 0.3\textwidth]{\hdir/gamma_res0good.eps}}
\caption {Результат работы алгоритма на различных наборах параметров} \label{fig:res0}
\end{figure}
\end{center}

\section{Вычислительный эксперимент}
Метод был реализован в системе Matlab, код реализации находится в общем
доступе~\cite{Code}. К сожалению, возможности сравнить результаты
с~результатами других методов пока нет, ввиду отсутствия размеченных баз,
на которых получены результаты других методов. Данная реализация метода
была протестирована на базе изображений CASIA \cite{CASIA} с~экспертной
разметкой границ радужки, незатененного сектора и областей затенения (для
оценки ошибки). Алгоритм запускался c параметрами: $v_0 =
(5, 5, 0{,}7)^\mathrm{T}$ и~$v^*$. 

Примеры вывода алгоритмов с параметрами $v_0$ и $v^*$ на одном и том же изображении приведены на рис. \ref{fig:res0}. На рис. \ref{fig:res0} показаны две проблемы алгоритма:
\begin{enumerate}[1)]
\item на изображениях виден шум (некоторые отдельные точки радужки классифицируются как затенения и наоборот);
\item существует проблема с распознаванием век ~--- часть верхнего века мало отличается от радужки.
\end{enumerate}
Для компенсации данных недостатков алгоритма применялась
морфологическая пост\-об\-ра\-бот\-ка. К логическому изображению вывода алгоритма применялись фильтры замыкания и размыкания. Фильтры считались в окнах $7{\times}7$. Точность алгоритма увеличилась после применения фильтра, это видно на рис.~\ref{fig:hist}--\ref{fig:samp3}.
\nopagebreak

На рис. \ref{fig:hist} представлены гистограммы распределения функционалов
качества $E$ для каждой из исследуемых модификаций алгоритмов
на 500 изображениях из базы CASIA~\cite{CASIA}.
%\nopagebreak
\begin{figure}[h]
\centering
\subfloat [Параметры $v_0$; $\overline{E} = 0{,}524$] {\includegraphics[width = 0.33\textwidth]{\hdir/Bad_hist0.eps}}
\hfill
\subfloat [Параметры $v^*$; $\overline{E} \!=\! 0{,}344$] {\includegraphics[width = 0.33\textwidth]{\hdir/Good_hist0.eps}}
\hfill
\subfloat [Параметры $v^*$ + фильтр; $\overline{E} = 0{,}286$] {\includegraphics[width = 0.33\textwidth]{\hdir/Dil_hist0.eps}}
\caption {Гистограммы ошибок для различных модификаций алгоритма} \label{fig:hist}
\end{figure}

Стоит также заметить, что в экспертной разметке затенений не учитываются блики, в то время как данный алгоритм классифицирует блики как затенения. На некоторых изображениях это приводит к заведомо заниженной оценке точности распознавания.

Далее приведены три примера работы алгоритма с параметрами $v^*$ и применением фильтра.\\
\noindent \textbf{Пример 1.} На рис. \ref{fig:samp1} показаны результаты
работы алгоритмов на файле 2003R05.bmp из базы CASIA, изображенном на
рис.~\ref{fig:samp1},\,\textit{a}. Результат до применения фильтра изображен
на рис.~\ref{fig:samp1},\,\textit{б}. Результат после применения фильтра
изображен на рис.~\ref{fig:samp1},\,\textit{в}. Время работы: $ t = 12{,}7~\text{с.}$ Функция ошибки: $E = 0{,}102$.\\
\begin{figure}[h]
\centering
\subfloat [Исходное изображение] {\includegraphics[width = 0.33\linewidth]{\hdir/gamma_samp1_inp.eps}}
\hfill
\subfloat [Результат без фильтра] {\includegraphics[width = 0.33\linewidth]{\hdir/gamma_samp1_unfilt.eps}}
\hfill
\subfloat [Результат с фильтром] {\includegraphics[width = 0.33\linewidth]{\hdir/gamma_samp1_filt.eps}}
\caption {Результаты работы на изображении 2003R05.bmp из базы CASIA \cite{CASIA}} \label{fig:samp1}
\end{figure}

\noindent\textbf{Пример 2.} На рис. \ref{fig:samp2} показаны результаты
работы алгоритмов на файле 2007R01.bmp из базы CASIA, изображенном на
рис.~\ref{fig:samp2},\,\textit{a}. Результат до применения фильтра изображен
на рис. \ref{fig:samp2},\,\textit{б}. Результат после применения фильтра
изображен на рис.~\ref{fig:samp2},\,\textit{в}.
Время работы: $ t = 10{,}3$~с. Функция ошибки: $E = 0{,}156$.\\
\begin{figure}[H]
\centering
\subfloat [Исходное изображение] {\includegraphics[width = 0.33\linewidth]{\hdir/gamma_samp2_inp.eps}}
\hfill
\subfloat [Результат без фильтра] {\includegraphics[width = 0.33\linewidth]{\hdir/gamma_samp2_unfilt.eps}}
\hfill
\subfloat [Результат с фильтром] {\includegraphics[width = 0.33\linewidth]{\hdir/gamma_samp2_filt.eps}}
\caption {Результаты работы на изображении 2007R01.bmp из базы CASIA \cite{CASIA}} \label{fig:samp2}
\end{figure}
\noindent \textbf{Пример 3.} На рис.~\ref{fig:samp3} показаны результаты
работы алгоритмов на файле 2015R11.bmp из базы CASIA, изображенном на
рис.~\ref{fig:samp3},\,\textit{a}. Результат до применения фильтра изображен
на рис.~\ref{fig:samp3},\,\textit{б}. Результат после применения фильтра
изображен на рис.~\ref{fig:samp3},\,\textit{в}. Время работы: $ t =
10{,}7~\text{с.}$ Функция ошибки: $E = 0{,}484$. В этом примере сектор $S$ содержит затенения и, как следствие, алгоритм не распознал ресницы, однако тем не менее распознал веки.\\
\begin{figure}[H]
\centering
\subfloat [Исходное изображение] {\includegraphics[width = 0.33\linewidth]{\hdir/gamma_samp3_inp.eps}}
\hfill
\subfloat [Результат без фильтра] {\includegraphics[width = 0.33\linewidth]{\hdir/gamma_samp3_unfilt.eps}}
\hfill
\subfloat [Результат с фильтром] {\includegraphics[width = 0.33\linewidth]{\hdir/gamma_samp3_filt.eps}}
\caption {Результаты работы на изображении 2015R11.bmp из базы CASIA \cite{CASIA}} \label{fig:samp3}
\end{figure}

\section{Заключение}
Представлен метод, позволяющий с высокой точностью выделять области затенения радужки. Основное преимущество метода состоит в том, что он является полностью автоматическим и не требует ручной разметки для обучающей выборки. Также отличительной чертой является тот факт, что метод строит новый классификатор для каждого изображения, что обеспечивает стабильность работы на изображениях с разной структурой радужки и с разной освещенностью. Скорость работы метода невелика (среднее время работы на одном изображении на выборке CASIA \cite{CASIA} составляет 10~с), однако
это время можно уменьшить, используя более быстрые языки программирования.

%\bibliographystyle{jmlda_rus.bst}
%\bibliography{MyBase}
\renewcommand{\bibname}{Литература}
\begin{thebibliography}{10}
\def\selectlanguageifdefined#1{
\expandafter\ifx\csname date#1\endcsname\relax
\else\selectlanguage{#1}\fi}

\bibitem{conf/icip/Daugman02}
\selectlanguageifdefined{english}
\emph{Daugman~J.}
How iris recognition works~//
Conference (International) on Image Processing Proceedings. IEEE, 2002. Vol.~1. P.~33--36.

\bibitem{bb95018}
\selectlanguageifdefined{english}
\emph{Wildes~R.\,P.}
Iris recognition: An emerging biometric technology~//
Proc. IEEE, 1997. Vol.~85. No.\,9. P.~1348--1363.

\bibitem{bb94769}
\selectlanguageifdefined{english}
\emph{He~Z.\,F., Tan~T.~N., Sun~Z.~A., Qiu~X.\,C.}
Robust eyelid, eyelash and shadow localization for iris recognition~//
15th IEEE Conference (International) on Image Processing Proceedings. IEEE, 2008. P.~265--268.

\bibitem{bb94887}
\selectlanguageifdefined{english}
\emph{Krichen~E., Garcia-Salicetti~S., Dorizzi~B.}
A new probabilistic iris quality measure for comprehensive noise detection~//
1st IEEE Conference (International) on Biometrics: Theory, Applications, and Systems. IEEE, 2007.
P.~1--6.

\bibitem{bb95039}
\selectlanguageifdefined{english}
\emph{Daugman~J.}
New methods in iris recognition~//
IEEE Trans. Syst. Man Cyb., 2007.
Vol.~37.                    No.\,5. P.~1167--1175.

\bibitem{bb94767}
\selectlanguageifdefined{english}
\emph{He~Z.~F., Tan~T.~N., Sun~Z.~A., Qiu~X.~C.}
Toward accurate and fast iris segmentation for iris biometrics~//
IEEE Trans. Pattern Anal.,
2009.
Vol.~31. No.\,9. P.~1670--1684.

\bibitem{bb94813}
\selectlanguageifdefined{english}
\emph{Zhang~D., Monro~D.~M., Rakshit~S.}
Eyelash removal method for human iris recognition~//
Conference (International) on Image Processing Proceedings. IEEE, 2006. P.~285--288.

\bibitem{conf/icassp/LiS09}
\selectlanguageifdefined{english}
\emph{Li~Y., Savvides~M.}
A pixel-wise, learning-based approach for occlusion estimation of iris images
  in polar domain~//
ICASSP. IEEE, 2009.
P.~1357--1360.

\bibitem{IrisSeg}
\selectlanguageifdefined{russian}
\emph{Ганькин~К.~А., Гнеушев~А.~Н., Матвеев~И.~А.}
Сегментация изображения радужки глаза, основанная на приближенных методах с
  последующими уточнениями~//
Известия РАН. Теория и системы управления,
2014.   №\,2. С.~80--94.

\bibitem{Code}
\selectlanguageifdefined{russian}
\emph{Соломатин~И.~А.}
Реализация алгоритма выделения областей затенения радужки классификатором
  локальных текстурных признаков.
2015.
  \url{http://svn.code.sf.net/p/mlalgorithms/code/Group274/Solomatin2015EESLocalization/code/}.

\bibitem{CASIA}
\selectlanguageifdefined{english}
Chinese Academy of Sciences Institute of Automation. CASIA-IrisV3:
  CASIA-Iris-Lamp image database.
\url{http://www.cbsr.ia.ac.cn/IrisDatabase.htm}.

\end{thebibliography}

\renewcommand{\bibname}{References}
\begin{thebibliography}{10}
\def\selectlanguageifdefined#1{
\expandafter\ifx\csname date#1\endcsname\relax
\else\selectlanguage{#1}\fi}

\bibitem{conf/icip/Daugman02}
\selectlanguageifdefined{english}
Daugman, J.
2002.
How iris recognition works.
\textsl{Conference (International) on Image Processing Proceedings}. IEEE. 1:33--36.

\bibitem{bb95018}
\selectlanguageifdefined{english}
Wildes, R.~P.
1997.
Iris recognition: An emerging biometric technology.
\textsl{IEEE Proc.}
85(9):1348--1363.

\bibitem{bb94769}
\selectlanguageifdefined{english}
He, Z.~F., T.~N. Tan, Z.~A. Sun,  and X.~C. Qiu.
2008.
Robust eyelid, eyelash and shadow localization for iris recognition.
\textsl{15th IEEE Conference (International) on Image Processing Proceedings}. IEEE.
265--268.

\bibitem{bb94887}
\selectlanguageifdefined{english}
Krichen, E., S.~Garcia-Salicetti,  and B.~Dorizzi.
2007.
A new probabilistic iris quality measure for comprehensive noise detection.
\textsl{1st IEEE Conference (International) on Biometrics: Theory, Applications, and Systems.}
1--6.

\bibitem{bb95039}
\selectlanguageifdefined{english}
Daugman, J.
2007.
New methods in iris recognition.
\textsl{IEEE Trans.\ Syst.\ Man Cyb.}
37(5):1167--1175.

\bibitem{bb94767}
\selectlanguageifdefined{english}
He, Z.~F., T.~N. Tan, Z.~A. Sun,  and X.~C. Qiu.
2009.
Toward accurate and fast iris segmentation for iris biometrics.
\textsl{IEEE Trans. Pattern Anal.}
31(9):1670--1684.

\bibitem{bb94813}
\selectlanguageifdefined{english}
Zhang, D., D.~M. Monro,  and S.~Rakshit.
2006.
Eyelash removal method for human iris recognition.
\textsl{Conference (International) on Image Processing Proceedings}.
285--288.

\bibitem{conf/icassp/LiS09}
\selectlanguageifdefined{english}
Li, Y.,  and M.~Savvides.
2009.
A pixel-wise, learning-based approach for occlusion estimation of iris images
  in polar domain.
\textsl{ICASSP}.
IEEE.
1357--1360.

\bibitem{IrisSeg}
\selectlanguageifdefined{english}
Gankin, K., A.~Gneushev,  and I.~Matveev.
2014.
Iris image segmentation based on approximate methods with subsequent
  refinements.
\textsl{J.~Comput.\ Sys.\ Sc.\ Int.}
53(2):224--238.

\bibitem{Code}
\selectlanguageifdefined{english}
Solomatin, I.~A.
2015.
Algorithm, detecting visible areas of iris by qualifier of local textural
  features.
Available at:
  \url{http://svn.code.sf.net/p/mlalgorithms/code/Group274/Solomatin2015EESLocalization/code/} (accessed January 11, 2016).

\bibitem{CASIA}
\selectlanguageifdefined{english}
CASIA.
Chinese Academy of Sciences Institute of Automation. CASIA-IrisV3:
  CASIA-Iris-Lamp image database.
Available at: \url{http://www.cbsr.ia.ac.cn/IrisDatabase.htm}  (accessed January 11, 2016).

\end{thebibliography}



% Решение Программного Комитета:
%\ACCEPTNOTE
%\AMENDNOTE
%\REJECTNOTE
\end{document}

