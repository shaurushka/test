\documentclass[12pt,twoside]{article}
\usepackage{jmlda}
\usepackage[linesnumbered,boxed,algo2e]{algorithm2e}
\usepackage{amssymb, amsmath}
\setcounter{page}{1369}
%\NOREVIEWERNOTES
\title
    [Помехоустойчивый Морфологический Алгоритм] % Краткое название; не нужно, если полное название влезает в~колонтитул
    {Помехоустойчивый Морфологический Алгоритм Обнаружения Вилочного Погрузчика на Видео}
\author
    %[Автор~И.\,О. и др.] % список авторов для колонтитула; не нужен, если основной список влезает в колонтитул
    {Черноусов~В.\,О., Савченко~А.\,В.} % основной список авторов, выводимый в оглавление
\thanks{Работа выполнена за счет средств гранта Российского научного фонда (проект №14-41-00039)}
\email
    {v.chernousov@mail.ru}
\organization
    {НИУ Высшая Школа Экономики, Москва, Россия}
\abstract
    {Исследуется задача обнаружения движущегося вилочного погрузчика на видео при наличии помех, в которой точность традиционного сопоставления локальных дескрипторов (SURF, SIFT, FAST, ORB) не достаточна. Предложен новый алгоритм, на первом этапе которого на кадре выделяются движущиеся объекты, после чего на передней части объекта находится потенциальная область вил и груза. На втором этапе выделяются контуры, затем с помощью морфологических преобразований вычисляются элементарные геометрические признаки объекта. Показано, что такой подход позволяет на 7\% и 50\% понизить вероятности ложной тревоги и пропуска события, соответственно, при детектировании пустого погрузчика по сравнению с методом FAST, является устойчивым к аддитивному шуму, а обработка одного кадра происходит в среднем на 30 мс быстрее.

\bigskip
\textbf{Ключевые слова}: \emph {Обнаружение объектов на видео, зашумленная среда, motion history image, морфология.}
}

\titleEng
    {A Noise-Resistant Morphological Algorithm of Video-Based Moving Forklift Truck Detection}
\authorEng
    {Chernousov~V.\,O., Savchenko~A.\,V.}
\organizationEng
    {National Research University Higher School of Economics, Moscow, Russian Federation}
\abstractEng
    {	
    	\textbf{Background}: The problem of video-based detection of the moving forklift truck is explored. It is shown that the detection quality of the state-of-the-art local descriptors (SURF, SIFT, FAST, ORB) is not satisfactory if the resolution is low and the lighting is changed dramatically.

		\textbf{Methods}: In this paper we propose to use a simple mathematical morphological algorithm to detect the presence of a cargo on the forklift truck. At first, the movement direction is estimated by the updating motion history image method and the front part of the moving object is obtained. Next, contours are detected and binary morphological operations in front of the moving object are used to estimate simple geometric features of empty forklift.

		\textbf{Results}: Our experimental study shows that the best results are achieved if the bounding rectangles of empty forklift contours are used as an object validation rule. Namely, FAR and FRR of empty cargo detection is 7\% and 50\% lower than FAR and FRR of the FAST descriptor. The proposed method is much more resistant to the effect of additive noise. The average frame processing time for our morphological algorithm is 5 ms (compare with 35 ms of FAST method).

		\textbf{Conclusions}: The proposed morphological method is task specific and can be used only for forklift truck detection. Additional detection principles need to be added to adopt algorithm for other moving object detection in noisy environment.

		\textbf{Keywords}:
		\emph{
			Video-based object detection, noisy environment, motion history image, binary morphology.
		}
	}


\begin{document}

\maketitle


\section{Введение}
В настоящее время все актуальнее становится исследование способов применения алгоритмов машинного зрения в прикладных задачах автоматического контроля состояния производства. Например, в данной работе рассматривается прикладная задача обнаружения движущегося вилочного погрузчика и выделение его основных атрибутов (направление движения, наличие/отсутствие груза на вилах) для автоматизации производственных линий в существующей автоматизированной системе управления.

Классический подход для решения задачи детектирования текстурированного объекта основывается на использовании популярных алгоритмов компьютерного зрения SIFT \cite{lowe}, SURF \cite{bay}, ORB \cite{ethan}, FAST \cite{rosten} и пр. \cite{savchenko1}. Эти алгоритмы ищут ключевые точки на эталонном изображении объекта, вычисляют их дескрипторы и сравнивают их с дескрипторами кадра, полученными аналогичным образом. К сожалению, такой подход существенно зависит от качества изображения и часто показывают высокие вероятности ошибок I (False Reject Rate, FRR) и/или II рода (False Accept Rate, FAR), особенно при наличии на изображении помех (вариативное освещение, частичное выпадение объекта из кадра и т.п.).

Целью проведенного исследования является снижение влияния фактора зашумленности изображения на точность обнаружения движущегося объекта на видео \cite{savchenko2} при помощи использования морфологических операций \cite{chien}. В этом случае силуэт движущегося объекта может быть получен методом MHI (Motion History Image) \cite{ahad}, после чего, на основе полученной информации об объекте можно вычислить его ключевые характеристики, применяя дополнительные морфологические преобразования изображения \cite{shapiro, najman}

Работа организована следующим образом: во втором разделе формулируется задача обнаружения пустого движущегося погрузчика. В третьем разделе проводится экспериментальное сопоставление традиционных методов обнаружения и разработанного морфологического алгоритма и анализируется устойчивость точности к аддитивному шуму. В заключительном разделе представлены основные выводы, сделанные по результатам проведенного исследования.

\section{Материалы и Методология}
Пусть имеется база данных (БД) модельных изображений детектируемых объектов и заданы их атрибуты (размер, предполагаемая скорость движения и пр.). Задача распознавания состоит в том, чтобы на входящем потоке видеоданных определить положение движущегося объекта, отчертив его ограничивающим прямоугольником и путем определения его ключевых признаков, отнести его к одному из искомых классов \cite{savchenko2}. Нами рассматривается прикладной вариант такой задачи, в котором необходимо обнаружить движущийся вилочного погрузчик и определить его тип: пустой (рис.~\ref{fg:Fig1}а) или с грузом (рис.~\ref{fg:Fig1}б) \cite{iss1}. Для указанной задачи известны следующие условия:

1) погрузчик движется в кадре горизонтально или вертикально с небольшими возможными отклонениями;

2) погрузчик является самым большим (занимает более половины кадра), но не единственным движущимся объектом на видео;

3) существуют два типа погрузчиков: вилочный и с одним длинным шестом для груза.

\begin{figure}[t]
\subfloat[Пустой вилочный погрузчик]{\includegraphics[width=0.5\textwidth]{Empty_upd}}
 \subfloat[Погрузчик с грузом]{\includegraphics[width=0.5\textwidth]{Cargo_upd}}\\
\caption{Примеры изображений детектируемого объекта. }
\label{fg:Fig1}
\end{figure}

Поставленная задача традиционно решается методом поиска ключевых точек (алг.~\ref{alg:loc_descr}) на каждом изображении видеопоследовательности и сравнением их локальных дескрипторов с искомым изображением (SIFT \cite{lowe}, SURF \cite{bay}). Данный метод подразумевает устойчивость искомого объекта к аффинным преобразованиям, однако, исходя из особенностей задачи, где погрузчик движется только под углами $0^{\circ}$ и $180^{\circ}$, сравнение дескрипторов производится только с учетом горизонтальной или вертикальной ориентации объекта (в функции Compare).
%Описание параметров Loc_desc алгоритма
У данного алгоритма имеются следующие параметры: $M_0$ - количество совпадений дескрипторов эталонного и найденного на видео объектов, при котором эти объекты признаются идентичными; $M_1$ - порог количества кадров видео (в \% от общего числа), на которых должен быть обнаружен объект, при достижении которого он считается найденным на видео; $N_f$ - количество кадров с обнаруженным движущимся объектом. $N_m$ - количество кадров, на которых был обнаружен искомый объект в процессе работы алгоритма. Функция Area отвечает за расчет площади переданной ей области.
К сожалению, точность этого подхода (алг.~\ref{alg:loc_descr}) существенно зависит от качества входного видеосигнала. Поэтому уже небольшие помехи могут значительно ухудшить точность распознавания.

\begin{figure}[t]
	\center{\includegraphics[width=0.5\linewidth]{Kpts}}
\caption{Искомое изображение пустых вил с выделенными ключевыми точками}
\label{fg:Fig2}
\end{figure}

%Псевдокод описания алгоритма локальных дескрипторов
\begin{algorithm2e}[h]
\SetAlgoLined
\KwData{Последовательность кадров $\{X(t)\}$, $t=\overline{1,T}$, изображение пустых вил $X_{trn}$,\\ Порог совпадений дескрипторов $M_0$, Порог количества кадров с обнаруженным объектом на видео $M_1$}
\KwResult{$True$ если пустые вилы найдены, $False$ иначе}
$kpts\_trn := DetectAndCalc(X_{trn})$; // поиск ключевых точек и расчет их дескрипторов для $X_{trn}$\\
$N_m := 0$, $N_f := 0$;\\
\For{$t=1,\dots,T$}
{
	// проверка области движения на соответствие минимальному размеру в 0.5 кадра\\
	\If{$Area(frame\_moving\_region) > 0.5 * Area(frame)$}
	{
		$N_f:= N_f+1$;
		$kpts\_t:= DetectAndCalc(t)$; // поиск ключевых точек и расчет их дескрипторов для $t$\\
		$match:= Compare(kpts\_t, kpts\_trn)$; // рассчитаем количество совпадающих дескрипторов\\
		\If{$match > M_0$}
		{
			$N_{match}:= N_{match}+1$;
		}
	}
}
\eIf{$(N_{match} / N_f) > M_1$}
{
	return $True$;
}{
	return $False$;
}
\caption{Принцип работы алгоритма локальных дескрипторов}
\label{alg:loc_descr}
\end{algorithm2e}

Для повышения качества обнаружения на зашумленных данных в настоящей работе предложено учитывать специфику задачи для разработки менее универсального, но более точного алгоритма. Используется информация о минимальном размере погрузчика относительно размера кадра (больше половины) - площадь также рассчитывается функцией Area, об отсутствии других объектов подобного размера и данные о том, что погрузчик движется на видео горизонтально или вертикально лишь с небольшими отклонениями. Предложенный алгоритм (алг.~\ref{alg:morph}) состоит из двух частей. В первой части производится определение наличия движущегося объекта и направления его движения на видео: последовательно идущий кадр $X(t)$ сравнивается с предыдущим $X_{bg}$ методом MHI (применяется адаптивное пороговое преобразование методом Гаусса, где пороговое значение $T(x,y)$ есть взвешенная сумма $blocksize{\times}blocksize$ окрестности пикселя $(x,y)$ - C)(рис.~\ref{fg:Fig4}а) \cite{ahad}. Затем для обнаруженной движущейся области строится ограничивающий прямоугольник. Заметим, что для традиционного алгоритма, основанного на поиске ключевых точек и сравнении их дескрипторов, задача обнаружения движения не является необходимой, поскольку оно может быть извлечено из матрицы аффинного преобразования, получаемой вследствие работы алгоритма RANSAC \cite{shapiro}.

\begin{algorithm2e}[h]
\KwData{Последовательность кадров $\{X(t)\}$, $t=\overline{1,T}$}
\KwResult{$True$ если пустые вилы найдены, $False$ иначе}
$X_{bg}:= X(1)$; // Считаем самый первый кадр фоновым\\
$rectangles:= 0$, $object\_found:= False$, $contours:= 0$;\\
\For{$t=2,\dots,T$}
{
	$X_{cur}:= X(t)-X_{bg}$;\\
	$Filter(X_{cur})$; \\
	//применяем адаптивное пороговое преобразование к $X_{cur}$;\\
	$X_g:= ToGrayscale(X_{cur})$; \\
	$Filter(X_g)$; \\
	$UpdateMotionHistory(X_g)$; //обновляем историю движений изображением $X_g$;\\
	$bound\_rect = BoundingBox(X_g)$; // ищем контур движущегося силуэта и строим его ограничивающий прямоугольник\\
	// проверка области движения на соответствие минимальному размеру\\
	\If{$Area(bound\_rect) > 0.5 * Area(frame)$}
	{
		$DetectMoveDirection(X_g, X_{bg})$;
		$contours:= Canny(X_g)$; //ищем всевозможные контуры в движущейся области\\
		$MorphClosure(X_g, rect, contours)$; //выполняем морфологическое замыкание контуров с прямоугольным элементом\\
		\For{\textbf{each} $cont$ \textbf{in} $contours$}
		{
			// размер контура должен быть больше определенного порога\\
			\If{$Size(cont) > threshold$}
			{
				$rect:= BoundingBox(cont)$;\\
				\If{$motion.isHorizontal\ AND\ rect.width > rect.height\ OR\ motion.isVertical\ AND\ rect.width < rect.height$}
				{
					$rectangles += BoundingBox(cont)$;
				}
			}
		}
		//производим выборку ограничивающих прямоугольников по заданным критериям\\
		\If{$\forall i \in \{1, ..., 5\} C_i = true$}
		{
			$object\_found:= True$;
		}
	}
	$X_{bg}:= X(t)$;
}
\eIf{$object\_found$}
{
	return $True$;
}{
	return $False$;
}
\caption{Принцип работы морфологического алгоритма}
\label{alg:morph}
\end{algorithm2e}

На втором этапе выполняются операции обнаружения контуров в передней части обнаруженного движущегося объекта (который был отмечен ограничивающим прямоугольником) с помощью оператора Кэнни \cite{canny} (рис.~\ref{fg:Fig4}б). После этого строятся ограничивающие прямоугольники для больших контуров (размер определяется исходя из размера кадра и найденной на нем движущейся области, чтобы отсеять контуры помех), среди которых затем выбирается пара прямоугольников при помощи определенных критериев сравнения. Они классифицируются как ограничивающие прямоугольники пустых вил погрузчика (рис.~\ref{fg:Fig4}в).

Алгоритм требует установки следующих параметров: тип фильтрации, используемый при предварительной обработке изображения и размерность ядра этого фильтра; минимальный размер движущегося сегмента кадра на видео (по условиям технического задания - не менее половины кадра). Также требуется выбрать критерии отбора ограничивающих прямоугольников, которые проверяются на завершающем этапе работы алгоритма. Были реализованы следующие критерии отбора: ($C_1$) - минимальная длина и ширина прямоугольника должна быть больше $W_1=const$ и $H_1=const$, соответственно; ($C_2$) - максимальное расстояние между прямоугольниками (вилы не могут быть расставлены слишком широко) не больше фиксированной величины $D=const$ ; ($C_3$) - максимальная разность площадей прямоугольников (поправка на небольшое отклонение вил от горизонтального/вертикального расположения) должна быть меньше $A=const$; ($C_4$) - максимальное и минимальное отклонение расположения по осям (разница в расположении верхних левых углов по оси $X$ при горизонтальном движении и оси $Y$ при вертикальном движении) находится в диапазоне между числами $R_1=const$ и $R_2=const$; ($C_5$) - максимальная разность длин меньше $W=const$ (поправка на небольшой поворот либо частичное выпадение вил из кадра).

\begin{figure}[t]
  \subfloat[]{\includegraphics[width=0.2\textwidth]{{min_w_h}}}
  \subfloat[]{\includegraphics[width=0.17\textwidth]{distance}}
  \subfloat[]{\includegraphics[width=0.2\textwidth]{area_diff}}
  \subfloat[]{\includegraphics[width=0.2\textwidth]{l_corner}}
  \subfloat[]{\includegraphics[width=0.2\textwidth]{width_diff}}
\caption{Критерии отбора ограничивающих прямоугольников: а)$Width > W_1\ AND\ Height > H_1$; б)$Distance(Rect1, Rect2) < D$; в)$|Area(Rect1) - Area(Rect2)| < A$; г)$R_2<|Rect1.x - Rect2.x| < R_1$; д)$|Width1-Width2| < W$}
\label{fg:Fig3}
\end{figure}

\begin{figure}[t]
  \subfloat[Результат вычитания двух последовательных кадров]{\includegraphics[width=0.3\textwidth]{{NoiseFrameDiff}}}
  \subfloat[Погрузчик с грузом]{\includegraphics[width=0.3\textwidth]{Canny}}\\
  \subfloat[Кадр с погрузчиком после морфологической обработки с обнаруженными вилами (помечены белыми прямоугольниками)]
{\includegraphics[width=0.3\textwidth]{Morph_det}}\\
\caption{Обработка кадра в алгоритме}
\label{fg:Fig4}
\end{figure}

\section{Результаты экспериментальных исследований}
Популярные текстурные алгоритмы (SURF, SIFT, ORB и FAST), а также предложенный морфологический алгоритм были реализованы в прототипе программного продукта обнаружения вилочного погрузчика на видео для проведения сравнительного эксперимента. Для реализации использовалась библиотека OpenCV 2.4 \cite{opencv}. На вход программе подается набор видеоданных, который затем обрабатывается любыми из указанных алгоритмов по выбору пользователя, после чего результаты работы программы выводятся в файл или непосредственно на экран. Агрегация результатов в процессе работы алгоритмов производится отдельно для каждого видео. Итоговая оценка качества работы алгоритмов определяются из показателей FRR и FAR обнаружения пустого погрузчика. Детектирование проводится независимо для каждого кадра. При оценке верного обнаружения (true detection) объекта для текстурных алгоритмов берется порог количества кадров $M_1$ по отношению к общему количеству кадров видео (алг.~\ref{alg:loc_descr}). Для морфологического алгоритма такой порог не используется - если объект был обнаружен хотя бы на одном кадре, он считается присутствующим на видео.

Пользовательский интерфейс разработанной программы позволяет выбирать различные типы фильтрации изображения и размер ядра накладываемого фильтра, задействовать или отключать любой из пяти заложенных алгоритмов при обработке видео, также есть возможность выбора любого количества видеоданных, как с указанием конкретных файлов, так и загрузкой папок.

Для проведения эксперимента было выбрано 24 видеофайла, с разрешением $1280{\times}720$, на каждом их которых имеется движущийся в определенном направлении вилочный погрузчик (рис.~\ref{fg:Fig1}) (загружены из БД компании Intelligent Security Systems) \cite{iss2}. На 10 видео погрузчик движется без груза, на 14 оставшихся - с грузом. Камера, с которой записывалось видео, расположена строго перпендикулярно к плоскости пола, где движется погрузчик. Съемка велась со стационарных камер видеонаблюдения в больших складских помещениях во время процессов загрузки/отгрузки товара, в разное время суток. Этим обусловлено наличие таких помех, как резкое изменение освещения и затенения, частичное выпадение объекта из кадра, наличие множества иных движущихся в разные стороны объектов. Продолжительность видео - от 15 до 25 секунд, средняя частота кадров в секунду - 25. Погрузчик (с грузом или без него) является самым крупным движущимся объектом на видео.

Эксперимент был разбит на три части. В первой было оценено качество работы алгоритма, основанного на сравнении локальных дескрипторов ключевых точек. Было использовано четыре метода вычисления и сравнения дескрипторов (SURF, SIFT, ORB, FAST). FAR определяется как $\frac{N_{fork\_miss}}{N_{fork}}$, а FRR как $\frac{N_{false\_det}}{N_{no\_fork}}$, где $N_{fork\_miss}$ - количество видео, содержащих вилы с грузом, ошибочно распознанных как пустые, $N_{fork}$ - количество видео с грузами, $N_{false\_det}$ - число видео, на которых пустые вилы ошибочно не были обнаружены, $N_{no\_fork}$ - количество видео с пустыми вилами. В эксперименте использовались различные значения параметров для каждого текстурного метода. Разрешение исходных видео данных: $1280{\times}720$ и $800{\times}465$ (искусственно уменьшено с исходного), разрешение изображения искомого объекта - $303{\times}205$ (вырезано из исходных данных).

В результате проведения первой части эксперимента были определены оптимальные значения параметров первого алгоритма, при которых алгоритмы показывают наименьшее количество FAR и FRR обнаружения пустых вил. Порог совпадений при сравнении дескрипторов $M_0$: SURF – 25, SIFT – 19, ORB – 40, FAST – 30. Рассмотренные значения порогов для SURF \{16, 20, 25\}, для SIFT \{16, 20, 25\}, ORB \{16, 20, 25\}, FAST \{16, 20, 25\}. Оптимальное значение порога $M_1$: SURF – 1\%, SIFT – 2\%, ORB – 2\%, FAST – 5\%. Рассмотренные значения порога: SURF \{0.5\%, 1\%, 2\%\}, SIFT \{1\%, 2\%, 4\%\}, ORB \{10\%, 20\%, 25\%\}, FAST \{1\%, 5\%, 7\%\}. При оптимальных значениях параметров были получены результаты, представленные в Таблице ~\ref{Tab1}.

\begin{table}[t]\label{tabtex}
\caption{Результаты работы алгоритма локальных дескрипторов}
\label{Tab1}
\begin{center}
\begin{tabular}{ccccc}
\hline\noalign{\smallskip}
Значения & {SURF}
	     & {SIFT}
	     & {ORB}
	     & {FAST} \\
\noalign{\smallskip}
\hline
\noalign{\smallskip}
Порог совпадений дескрипторов $M_0$& $25$ & $19$ & $40$ & $30$\\
\hline
Порог кадров с обнаруженным объектом $M_1$, \%& $1$ & $2$ & $20$ & $5$\\
FRR, \% & $0$ & $65$ & $87$ & $75$\\
FAR, \% & $64$ & $53$ & $0$ & $13$\\
Время обработки кадра, мс & $75.1$ & $188.8$ & $35.5$ & $44.5$\\
\hline
\end{tabular}
\end{center}
\end{table}

Как видно, значения FRR и FAR велики даже при оптимальном подборе значении параметров. Это в первую очередь связано с тем, что пустые вилы на выбранных видео практически не выделяются из фона (из-за схожей цветовой насыщенности). Очевидно, низкое качество обнаружения и вычислительная эффективность традиционного подхода не являются удовлетворительными для его практического применения.

Во второй части эксперимента протестирована реализация морфологического алгоритма на качество обнаружения. Была выявлена зависимость точности алгоритма от условий отбора ограничивающих прямоугольников для контуров вил. Были рассмотрены следующие значения параметров: тип фильтрации предварительной обработки – медианная, гауссова, оконный фильтр и нормализованный оконный фильтр \cite{shapiro, sonka}; размеры ядра фильтра – от 1 до 9; минимальный размер движущейся области кадра – 0.3 и 0.5. Экспериментально были определены значения параметров, при которых алгоритм показывает наибольшую точность обнаружения при неизменных критериях отбора прямоугольников: медианная фильтрация в окрестности $5 \times 5$, при размере движущейся области в 0.5 кадра. Наилучшее качество детектирования было получено для следующих значений параметров критериев отбора прямоугольников: $H_1 = 150$(длина), $W_1 = 35$(ширина), $D = 150$, $A = 1500$, $R_1 = 150, R_2 = 80$, $W = 20$.
В результате проведения эксперимента было выявлено, что все названные критерии, за исключением максимальной разности площадей прямоугольников, при добавлении их как условий в процесс отбора существенно понижают FRR поиска пустых вил, лишь незначительно повышая значение FAR. Наименьшее FRR~-- 16\% и 5\%~-- FAR достигается при совместном использовании пяти критериев. Кроме того, разработанный алгоритм очень быстро обрабатывает каждый кадр - порядка 5 миллисекунд, что позволяет получать результаты в реальном времени. Зависимость морфологического алгоритма от критериев отбора ограничивающих прямоугольников контуров вил представлена в Таблице~\ref{Tab2}.

\begin{table}[t]\label{tabmorph}
\caption{Зависимость точности морфологического алгоритма от критериев проверки}
\label{Tab2}
\begin{center}
\begin{tabular}{cccccc}
\hline\noalign{\smallskip}
\parbox{2cm}{Критерии проверки} & \parbox{2.5cm}{Минимальная длина и ширина}
	     & \parbox{2cm}{Разность площадей}
	     & \parbox{2.5cm}{Максимальное удаление друг от друга}
	     & \parbox{2.5cm}{Максимальная ширина}
	     & \parbox{2.5cm}{Максимальная разность длин}\\
\noalign{\smallskip}
\hline
\noalign{\smallskip}
\parbox{2cm}{FRR, \%}  & $0$ & $0$  & $7.5$ & $11.8$ & $16.3$\\
\parbox{2cm}{FAR, \%}  & $78.9$ & $78.9$  & $34.1$ & $15.5$ & $5$\\
\parbox{2cm}{Время обработки кадра, мс} & $4.8$ & $4.9$ & $4.9$ & $5.1$ & $5.2$\\
\hline
\end{tabular}
\end{center}
\end{table}

В третьей части эксперимента проводится тестирование реализованных алгоритмов на устойчивость к шумам различного типа. Всего рассматривалось три типа помех, являющихся типичными для условий поставленной задачи: аддитивный белый гауссов шум, случайный импульсный шум и частичное осветление/затемнение кадра. Так, импульсные помехи могут возникать от тиристорных регуляторов и ламп дневного света или из-за токов питания устройств, участвующих в обработке сигнала (синхронные с сетью помехи). Белый гауссов шум может возникать при плохих условиях приема сигнала с камеры. Перепады освещения типичны при движении по неравномерно освещенным помещениям или, когда источники света расположены не на потолке, а на стенах и освещают помещение под разными углами.
Для получения гауссова шума генерируется нормально-распределенная случайная величина с нулевым средним и переменной дисперсией (параметр, характеризующий уровень шума), прибавляющаяся к каждому пикселю каждого кадра, затем значение итогового пикселя устанавливается в пределах [0, ..., 255]. Зависимость качества рассматриваемых алгоритмов (значения FRR и FAR) от дисперсии шума показана на рис.~\ref{fg:Fig6} и ~\ref{fg:Fig7}.

\begin{figure}[t]
\center{\includegraphics[width=0.9\textwidth]{{GaussDiagFirstErr}}}
\caption{Зависимость значения FRR от дисперсии аддитивного белого шума}
\label{fg:Fig6}
\end{figure}

\begin{figure}[t]
\center{\includegraphics[width=0.9\textwidth]{{GaussDiagSecondErr}}}
\caption{Зависимость значения FAR от дисперсии аддитивного белого шума}
\label{fg:Fig7}
\end{figure}

При использовании случайного импульсного шума (рис.~\ref{fg:Fig10}), фиксируется один числовой параметр - количество модифицируемых пикселей изображения по отношению к общему числу пикселей одного кадра. Далее случайным образом выбирается координата модифицируемого пикселя и новое значение его яркости. Соответственно, чем больше количество изменяемых точек, тем сильнее помехи. Зависимость качества детектирования алгоритмов от этого параметра показана на рис.~\ref{fg:Fig11} (для значения FRR) и на рис.~\ref{fg:Fig12}(FAR).

\begin{figure}[t]
	\center{\includegraphics[width=0.9\textwidth]{ImpulseGraphFirstErr}}
\caption{Зависимость значения FRR количества пикселей с импульсным шумом}
\label{fg:Fig11}
\end{figure}

\begin{figure}[t]
	\center{\includegraphics[width=0.9\textwidth]{{ImpulseGraphSecondErr}}}
\caption{Зависимость значения FAR от количества пикселей с импульсным шумом}
\label{fg:Fig12}
\end{figure}

Для добавления перепадов освящения на видео использовалось динамическое увеличение яркости пикселей одной половины и ее понижение на другой половине кадра на фиксированную величину (интенсивность) которая и служит параметром этого шума. Динамика изменения значений FAR и FRR показана на рис.~\ref{fg:Fig8} (FRR) и на рис.~\ref{fg:Fig9}(FAR).

\begin{figure}[t]
	\center{\includegraphics[width=0.9\textwidth]{LightGraphFirstErr}}
\caption{Зависимость значения FRR от интенсивности яркости/затенения}
\label{fg:Fig8}
\end{figure}

\begin{figure}[t]
	\center{\includegraphics[width=0.9\textwidth]{LightGraphSecondErr}}
\caption{Зависимость значения FAR от интенсивности яркости/затенения}
\label{fg:Fig9}
\end{figure}

Результаты этого эксперимента подтверждают предположение о большей устойчивости к помехам предложенного алгоритма. Заметим, что при очень высоком уровне шума точность разработанного алгоритма (алг.~\ref{alg:morph}) становится близкой к точности традиционного подхода (алг.~\ref{alg:loc_descr}), что означает неудовлетворительное качество решения задачи при значительных помехах.

\begin{figure}[t]
	\center{\includegraphics[width=0.8\textwidth]{Noise}}
\caption{Пример изображения погрузчика со случайным импульсным шумом}
\label{fg:Fig10}
\end{figure}

\section{Заключение}
В результате проведения исследования был разработан морфологический алгоритм обнаружения движущегося объекта на видео, который обеспечивает на 40\% и 27\% (разница между усредненными значениями FRR и FAR ($\frac{FAR+FRR}{2}$) текстурных алгоритмов и морфологического алгоритма при обнаружении пустых вил) более точный результат и в 7 раз (5мс против 35мс у ORB) более быструю обработку кадра \cite{savchenko3}, нежели традиционный метод, основанный на сравнении локальных дескрипторов ключевых точек. Экспериментально подтвержден факт сильного влияния помех вида игры света и тени, а также разного рода случайных помех на точность работы текстурных алгоритмов \cite {lowe, bay, ethan, rosten}(рис.~\ref{fg:Fig6} и \ref{fg:Fig11}). Также было отмечено, что методы локальных дескрипторов не эффективны в плане скорости работы, когда изображение имеет много потенциальных ключевых точек и их приходится вычислять для каждого кадра. Оба недостатка были устранены в предложенном алгоритме, где игра света и тени обрабатывается оператором Кэнни \cite{canny}, случайный шум удаляется фильтрацией и морфологическими преобразованиями. Производительность алгоритма повышена за счет использования только простых преобразований изображения.

	Разработанный метод, однако, имеет существенный недостаток, т.к. во многом полагается на априорную информацию о специфике поставленной задачи (размеры движущегося объекта, наличие других объектов на видео и т.д.). Следовательно, его нельзя будет применить для обнаружения других типов объектов без внесения дополнительной логики работы в механизм распознавания. С точки зрения развития данной темы, следующим шагом, на наш взгляд, может стать дальнейшее повышение точности алгоритма (с использованием комбинирования рассмотренных методов), а также его адаптация для других практически важных задач распознавания движущихся объектов в зашумленной среде.

\section{Литература}
\renewcommand{\bibname}{}
\begin{thebibliography}{16}
\bibitem{lowe}
    \BibAuthor{Lowe\;D.}
    \BibTitle{Distinctive Image Features From Scale-Invariant Keypoints}~//
    \BibJournal{International Journal of Computer Vision}. 60(2), 91--110, 2014

\bibitem{bay}
    \BibAuthor{Bay\;H., Ess\;A., Tuytelaars\;T., Van Gool\;L.,}
    \BibTitle{SURF: Speeded Up Robust Features}~//
    \BibJournal{Computer Vision and Image Understanding}, 110(3), 346--359, 2008

\bibitem{ethan}
    \BibAuthor{Rublee\;E., Rabaud\;V., Konolige\;K., Bradski\;G.,}
    \BibTitle{ORB: an efficient alternative to SIFT or SURF}~//
    \BibJournal{Computer Vision (ICCV)}, IEEE International Conference, 2011

\bibitem{rosten}
    \BibAuthor{Rosten\;E., Drummond\;T.,}
    \BibTitle{Machine learning for high-speed corner detection}~//
    \BibJournal{European Conference on Computer Vision},1 430--443, 2006

\bibitem{savchenko1}
    \BibAuthor{Savchenko\;A.\;V.,}
    \BibTitle{Probabilistic Neural Network with Homogeneity Testing in Recognition of Discrete Patterns Set}~//
     \BibJournal{Neural Networks}, 46 227--241, 2013

\bibitem{savchenko2}
    \BibAuthor{Savchenko\;A.\;V.,}
    \BibTitle{Adaptive Video Image Recognition System Using a Committee Machine, Optical Memory and Neural Networks}~//
     \BibJournal{Optical Memory and Neural Networks (Information Optics)}, 21(4), 219--226, 2012

\bibitem{chien}
    \BibAuthor{Chien\;S.\;-Y., Ma\;S.\;-Y., Chen\;L.\;-G.,}
    \BibTitle{Efficient moving object segmentation algorithm using background registration technique}~//
     \BibJournal{IEEE Transactions on Circuits and Systems for Video Technology}, 12(7), 577--586, 2002

\bibitem{ahad}
   \BibAuthor{Ahad\;Md., Atiqur Rahman, Tan\;J.\;K., Kim\;H., Ishikawa\;S.,}
   \BibTitle{Motion history image: its variants and applications}~//
   \BibJournal{Machine Vision and Applications}, 23(2), 255--281, 2012

\bibitem{shapiro}
    \BibAuthor{Shapiro\;L.\;G, Stockman\;G.\;C.,}
    \BibTitle{Computer Vision}~//
	Prentice Hall, 2001

\bibitem{najman}
   \BibAuthor{Najman\;L., Talbot\;H. (Eds),}
   \BibTitle{Mathematical morphology: from theory to applications}~//
   \BibJournal{Wiley- ISTE}, 2010

\bibitem{iss1}
   ISS (Intelligence Secure Systems),
  \BibUrl{http://www.iss.ru/}

\bibitem{canny}
   \BibAuthor{Canny\;J.\;A.,}
   \BibTitle{Computational Approach to Edge Detection}~//
   \BibJournal{IEEE Computer Society}, 679--698, 1986

\bibitem{opencv}
   OpenCV library,
  \BibUrl{http://opencv.willowgarage.com/wiki/}

\bibitem{iss2}
   ISS video dataset,
  \BibUrl{ftp://isstemp:isstemp@ftpsupport.iss.ru/Loaders/Video/}

\bibitem{sonka}
    \BibAuthor{Sonka\;M., Hlavac\;V., Boyle\;R.,}
    \BibTitle{Image Processing, Analysis, and Machine Vision}~//
	4th edition,
	\BibJournal{Cengage Learning}. 2014

\bibitem{savchenko3}
   \BibAuthor{Savchenko\;A.\;V.,}
  \BibTitle{Directed Enumeration Method in Image Recognition}~//
   \BibJournal{Pattern Recognition}, 45(8), 2952--2961, 2012
%
%\bibitem{skel}
%    \BibTitle{Skeleton-Based Morphological Shape Comparison}~/
%    \BibAuthor{Vizilter\;Y.\;V., Sidyakin\;S.\;V., Rubis\;A.\;Y., Gorbatsevich\;V.}~//
%    \BibJournal{Pattern Recognition and Image Analysis (Advances in Mathematical Theory and Applications)}.– 2011.– Vol. 21, № 2.– P. 357-360.
%
%\bibitem{neria}
%   \BibAuthor{Neria\;A., Colonnese\;S., Russo\;G., Talone\;P.,}
%   \BibTitle{Automatic moving object and background separation}~//
%   \BibJournal{Signal Processing}, 66(2), 219--232, 1998

\end{thebibliography}
\end{document}
